{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-ynKsNOrfdi"
      },
      "source": [
        "# T5 Fine-tuned model inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6zIwhgKUdqiE"
      },
      "outputs": [],
      "source": [
        "pip -qqq install --upgrade accelerate transformers auto-gptq optimum rouge_score bert-score datasets torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "azK0QW5Adt-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "739214d1-6cd7-4349-9abe-9e0cefb4b618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# General libraries\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "\n",
        "# Data handling libraries\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "\n",
        "# Transformers libraries\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# NLP and evaluation libraries\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import single_meteor_score\n",
        "from bert_score import BERTScorer\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Logging for the pipeline\n",
        "import logging\n",
        "\n",
        "# Google drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Language libraries\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NZCN9A5igNv"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ts5_uNSuY3j"
      },
      "source": [
        "Connect to google drive to access kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "eoKve5OMgNuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5163d8ec-bcdd-4467-be22-e23b377d722a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# change this to your own kaggle.json path\n",
        "kaggle_file_path = '/content/drive/My Drive/kaggle.json'\n",
        "\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "shutil.copy(kaggle_file_path, '/root/.kaggle/kaggle.json')\n",
        "os.chmod('/root/.kaggle/kaggle.json', 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "cymtXvx4gbaz"
      },
      "outputs": [],
      "source": [
        "def download_dataset(dataset_name):\n",
        "    command = f\"kaggle datasets download -d bruncikristian/{dataset_name}-preprocessed-dataset\"\n",
        "    os.system(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_ekRTs-ggerU"
      },
      "outputs": [],
      "source": [
        "def load_dataset_from_zip(dataset_name):\n",
        "    dataset_dict = load_dataset(\n",
        "        \"csv\",\n",
        "        data_files=f\"{dataset_name}-preprocessed-dataset.zip\"\n",
        "    )\n",
        "\n",
        "    dataset = dataset_dict['train']\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "0aLs0MfpIucy"
      },
      "outputs": [],
      "source": [
        "def split_dataset(dataset, test_size=0.1, validation_size=0.1, seed=42):\n",
        "    datasets_train_test = dataset.train_test_split(test_size=test_size)\n",
        "    datasets_train_validation = datasets_train_test[\"train\"].train_test_split(test_size=validation_size)\n",
        "    dataset_split = DatasetDict({\n",
        "        \"train\": datasets_train_validation[\"train\"],\n",
        "        \"validation\": datasets_train_validation[\"test\"],\n",
        "        \"test\": datasets_train_test[\"test\"]\n",
        "    })\n",
        "\n",
        "    return dataset_split[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "JXE_MKlZ1Y9H"
      },
      "outputs": [],
      "source": [
        "def add_prompt_to_dataset(dataset, prompt_template=\"summarize: {article}\"):\n",
        "    def add_summarization_prompt(example):\n",
        "        example['article'] = prompt_template.format(article=example['article'])\n",
        "        return example\n",
        "\n",
        "    dataset = dataset.map(add_summarization_prompt)\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyASGcy6iwn2"
      },
      "source": [
        "# Load the tokenizer and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "B56nfiN3dvhb"
      },
      "outputs": [],
      "source": [
        "def load_model_and_tokenizer(model_checkpoint, device=\"cpu\", hf_token=None):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, trust_remote_code=True, use_auth_token=hf_token)\n",
        "\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        model_checkpoint,\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=torch.float32,\n",
        "        device_map=None if device == \"cpu\" else \"auto\",\n",
        "        use_auth_token=hf_token\n",
        "    )\n",
        "\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    return tokenizer, model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAK4XxO5i7fp"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Lw5Has16dxMA"
      },
      "outputs": [],
      "source": [
        "def summarize_text(prompt, tokenizer, model, device=\"cpu\", max_new_tokens=200, temperature=0.7, top_p=0.9):\n",
        "    print(prompt)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        do_sample=True,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        no_repeat_ngram_size=3,\n",
        "        repetition_penalty=1.5,\n",
        "        min_length=30,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "11ZPxqvDXQA0"
      },
      "outputs": [],
      "source": [
        "def smart_trim(summary):\n",
        "    sentences = sent_tokenize(summary.strip())\n",
        "\n",
        "    clean_sents = [s.strip() for s in sentences if s.strip().endswith(('.', '!', '?'))]\n",
        "\n",
        "    if clean_sents:\n",
        "        return \" \".join(clean_sents)\n",
        "\n",
        "    match = re.search(r\"(.*?[\\.!?])\\s\", summary)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "\n",
        "    return summary.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29KZyrjFjQHm"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Cfzzbi1QjyTR"
      },
      "outputs": [],
      "source": [
        "def rouge_score(response, summary):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(response, summary)\n",
        "    f1_scores = [score.fmeasure for score in scores.values()]\n",
        "    return f1_scores[0], f1_scores[1], f1_scores[2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "bN7GfROlky-q"
      },
      "outputs": [],
      "source": [
        "def bleu_score(response, summary):\n",
        "    doc_abstract = nlp(summary)\n",
        "    doc_summary = nlp(response)\n",
        "\n",
        "    sentences_abstract = [sent.text.split() for sent in doc_abstract.sents]\n",
        "    sentences_summary = [token.text for token in doc_summary]\n",
        "\n",
        "    weights = (0.5, 0.5, 0.25, 0.25)\n",
        "\n",
        "    score = sentence_bleu(sentences_abstract, sentences_summary, weights=weights)\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Co0wbCscmQ4F"
      },
      "outputs": [],
      "source": [
        "def meteor_score(response, summary):\n",
        "    summary_tokens = summary.split()\n",
        "    response_tokens = response.split()\n",
        "\n",
        "    score = round(single_meteor_score(response_tokens, summary_tokens), 4)\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "IWarf1NfqMj4"
      },
      "outputs": [],
      "source": [
        "def bert_score(response, summary):\n",
        "    scorer = BERTScorer(model_type='bert-base-uncased')\n",
        "    P, R, F1 = scorer.score([response], [summary])\n",
        "    return F1.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "jYxahLJerFII"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(response, summary):\n",
        "  rouge1, rouge2, rougel = rouge_score(response, summary)\n",
        "  bleu = bleu_score(response, summary)\n",
        "  meteor = meteor_score(response, summary)\n",
        "  bert = bert_score(response, summary)\n",
        "\n",
        "  return {\n",
        "      \"rouge1\": rouge1,\n",
        "      \"rouge2\": rouge2,\n",
        "      \"rougel\": rougel,\n",
        "      \"bleu\": bleu,\n",
        "      \"meteor\": meteor,\n",
        "      \"bert\": bert\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "woHU-CKuKYBT"
      },
      "outputs": [],
      "source": [
        "def save_metrics_to_csv(metrics_list, output_folder, dataset_name, model_checkpoint):\n",
        "    metrics_df = pd.DataFrame(metrics_list, columns=[\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"BLEU\", \"METEOR\", \"BERT\", \"time\"])\n",
        "    metrics_df.to_csv(f\"{output_folder}/{dataset_name}_google-t5-small_fine_tuned_metrics.csv\", index=False)\n",
        "    # metrics_df.to_csv(f\"{output_folder}/{dataset_name}_{model_checkpoint}_metrics.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "tM7iLOuJyH6-"
      },
      "outputs": [],
      "source": [
        "def pipeline(dataset_name, model_checkpoint, output_folder, num_samples=100):\n",
        "    download_dataset(dataset_name)\n",
        "    dataset = load_dataset_from_zip(dataset_name)\n",
        "    dataset_split = split_dataset(dataset)\n",
        "\n",
        "    dataset = add_prompt_to_dataset(dataset)\n",
        "    tokenizer, model = load_model_and_tokenizer(model_checkpoint)\n",
        "\n",
        "    test_samples_list = list(dataset)\n",
        "\n",
        "    random.seed(42)\n",
        "    test_samples = random.sample(test_samples_list, num_samples)\n",
        "\n",
        "    metrics_list = []\n",
        "    for sample in test_samples:\n",
        "        text = sample[\"article\"]\n",
        "        summary = sample[\"summary\"]\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        response = summarize_text(text, tokenizer, model)\n",
        "\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "\n",
        "        response = smart_trim(response)\n",
        "        print(\"response: \", response)\n",
        "\n",
        "        metrics = compute_metrics(response, summary)\n",
        "        metrics_list.append([\n",
        "            metrics[\"rouge1\"],\n",
        "            metrics[\"rouge2\"],\n",
        "            metrics[\"rougel\"],\n",
        "            metrics[\"bleu\"],\n",
        "            metrics[\"meteor\"],\n",
        "            metrics[\"bert\"],\n",
        "            elapsed_time\n",
        "        ])\n",
        "\n",
        "    save_metrics_to_csv(metrics_list, output_folder, dataset_name, model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "1QY3b4CBzJVI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6c15d377dd51462d93805b07b38414de",
            "ec56780d1c9749fdb2c1a695b3a20a74",
            "2bf75273e06344d7af2854b970afe7f1",
            "074f5e661f234f4c82f6da4619019001",
            "7aea7fad0c644abd8cf128ea471b407d",
            "509123df7fee453b937d60f84e14d464",
            "d90066050e6247ca98e9fc44512aa2aa",
            "78c2dc9c6b424b0e963e559c3d987b8a",
            "6d36171ff2e643928bd53a12fe08c407",
            "bd24e78897414bd4b1710bd3f3cf8969",
            "bb0d6ba0b5ff4785ac5c52f9c81fd8bc",
            "8193ded5c2d5430dbb9a92a584ab7365",
            "b57032b192ea400abb9604dd432486d3",
            "feb20961e5e5405c89f9da39a15754dd",
            "8f89e24de6ae487aa1a1149cfe9eef59",
            "920b244dbb35404bb4cad0d98e014c44",
            "23a703c735b648c68909473c83b56c83",
            "a8599431e7834444a9b5d70c7d3b2941",
            "900a15cc696346cdad0e908a0f18ab18",
            "9f97f444fdca413cae0ff997782d91d5",
            "f64b0aaaa3674841a6855921ec5cfa33",
            "75181905355f480c9e46b22827c19ab0",
            "def061b4f17c433f832db9e571a16139",
            "8030ae3c29ff4f3bb0235ee0d52c68b3",
            "32b5f132a7a24140a7c53f8e6fc3be71",
            "62a49c0c8b98490285cfff6a5afb5171",
            "117308ded2de44c79eeaae30ffb08cc4",
            "48937d2d4e7046fd82b6d73fc5945774",
            "7900087760e042f0b56d32d280bf4aa1",
            "32c0d64e28e34741a9d50455680fe4e2",
            "0029bd37144e4047bd83eaf2ded63a6d",
            "2dce71be6de34db8929250e86b197d97",
            "1402d4f93e1f44b3b4db0cf98d3b4996",
            "17725729e83f41bc8171f30312594b7e",
            "3781deb069af4a78ad2ae5c2f7af43a6",
            "31f1fda4634348f6b991efbf7069a1e5",
            "662dea080606487dac69dae37bcff5d6",
            "b56f674776824be9a392ac33ee782693",
            "76d7cb9cb8b34f0cbfdd354e4bd54aee",
            "9c27caf7c8a94b3380934a432583d4c3",
            "b88456b3078b46d1b8b61fd3da409ae5",
            "554369e081f8409e838acd1c2b5e738b",
            "dbf177b495f0411f8f60b5954209090a",
            "feddb3adebc14ac8b8a7c0918c1c50a4",
            "5b83fceae68a4e5b916b2b5f7fc364a4",
            "e4510d7d889b4b3abf64cba28cf30873",
            "04ba6eca698c4876a906b7159d7c740d",
            "b7b62c22a124493997231036c1018733",
            "a0f9d4ffd2144ff0a8e34cd32841a036",
            "14e7bfe848094ba4bcf0096ce195d36e",
            "6fe0c866e72f4540a5f7b77cd33e63f4",
            "acf5332cced64e749cedfbd89fb28615",
            "de62bbcd145b4d8fba2d68836574685e",
            "e214f3a0a7154776a66ac20d382052d3",
            "13b040ce64ae4a0dba28435db5a6e84c",
            "dd213ab0d9ef4d46b294129992cf912d",
            "23ae4720ae2c408885aba9dc70c7f117",
            "a495a8f7419347038ddca7071b5bd6dc",
            "89870275efad462b8f0d534ff7671075",
            "634846dce23e4112bab02267314bf6b7",
            "1003c0efe38241b89479f58336efd212",
            "3ef1bd158d9c402fb4f82573bcc04ae5",
            "d88bbbdb693f45129d2dcae570c1bddf",
            "44eb2f6afded4c0b99fd980b49738c04",
            "a0a946bf95024a13bb97dde9105c5f3a",
            "d8dff022b8e24158860afb4896a0a2e3",
            "bffb7c9910434bcdbd019d2554150749",
            "84469a2835cd48d9a57506ba22f689bd",
            "a4decae302814634a34df7f77f05e62d",
            "b9f1907951094ab39c6b22d932c4ed30",
            "a6f53db3c6714df9bcc0e2a9ff6298d7",
            "028e23a997214a0da6c04bcbc617ab08",
            "6f0d21e5c3c843ca9bffb5b9a49e5901",
            "9e8d15b3cef245678e5e0de9af4b90fb",
            "e2e7919d8755445a9e2e44bf5738c159",
            "99627cbd6aa9428c94c8ad4d1f1d6a15",
            "49adac48a08e47679246ccb6cde07914",
            "d2f377c0231f4df684bb4be5f0f16895",
            "3328e6581dbc4663b37c63cbd15a0787",
            "bde0e44422df4bef8e2693b9353f90d9",
            "5f9a1ec5711143bba4919d195ead5f8c",
            "061629aa029e4b1faab80e1fa40c9243",
            "d68e008cac1048d6a62421aedc96e08b",
            "f1fa3913b22d40659375d4bf2db010ca",
            "9a002d90e2664aec9c7b90333e01cb25",
            "3a5ba4b91ad44813bf590fc383dfa150",
            "3de5a59095db4c1789b8d2ab542265dd",
            "b83f0b2a1ff348768a7b07e2736f79e7",
            "ec94ebb55556459e89047ed12aa9965a",
            "e1e8fb4de97245879c2231d30e470710",
            "e3b99af5cccb4f73a264229ff5e41280",
            "f1b2807ba285498dad0a63cd21eed915",
            "24e4f0e803084575ad88630d7a3fb975",
            "9d6705e85a674e9ea19712b5ca258696",
            "78421d081a5740bca2e2af76ff2d4065",
            "77aa40828d784149a6608f5a29de7463",
            "98deffb4a89b4bc0b1afd7385a612a36",
            "7ca548c05092425a87d07944127b2f78",
            "03c9a76c414a4d70a95925694d40cd00",
            "06044ea8d4a1487082692d13af984158",
            "01b53f31a4c1472083e46a43cf20de62",
            "2952d54c633c4f22819e381fe92a48ca",
            "fc66b84df7e842fb91ab03332f8f04a8",
            "5096b751bca34f28b8067124697278ef",
            "f00952815e2a44f98278bd79cb3f78f7",
            "95e051958a6441ab8750bff2f2d6f8d8",
            "aecdaab354b74f70b176bd8132a8071d",
            "33c29ca41d2d4e55bf358a32a9a4a233",
            "41ca488ec88f49b9a288f9349f95dd78",
            "870fd948575e4cb3b314a362bd936167",
            "8c26827811d44f6e8109c1d2344e9dd7",
            "a8c06a406ba9455bb54c079626bd3090",
            "99f2d1daa461416382158bfdcd1530c3",
            "755b93908ea247f889ee87ba4879d527",
            "5f3bb7ddaf0844929dc1da443e5e2949",
            "f6ec3d4fc14948539dbdad9711367aa5",
            "ecdaf94e11d548049fc9ba9ba86006ba",
            "eaee300bf115459996315c4efbb4f800",
            "dd504c15a6cd4793b0c3198632d3fdcc",
            "04abd9468cd64857a62f1ef7805dcc4a",
            "fc13b4b82ab744d69af0cf8483999d15",
            "772fd270212446629dbb17ce52968536",
            "566e2b486b094d1f8f004b6cd1d85885",
            "87eee05c2aea43059060d689cfb0fd2f",
            "b94bd4ca4b8c4bdf8fa4c162a8b5ceab",
            "9368889088e7468a8eea11fd8825bde2",
            "25a99698734f4584b79a58bcb515c14d",
            "e7402133c74b44eeb00023a79c06ad13",
            "3c14400d1b0b4096a000747d9d136672",
            "fd9201cedab549d788b226d1664189d9",
            "8a944cd86b5c490584c8dddb63d0656d",
            "ff1b484053b24675a756ca840e678f02",
            "dd5fed5e08fa4360953153489d78a7d0",
            "b1fb31da4eb64f1d80cd694a15f8e375",
            "91c76d47ab5245149da7b136d14bbe01",
            "b614699245cd4b60bdf2c744fcebd696",
            "89fa20ad628649309c8805a57f848100",
            "13b2f31f422041f1a77c6e78760c9bb5",
            "340ebf70fa2e49a6bf28b0bff6f84794",
            "1076f7acb73a44bd8aba606c27f7934c",
            "537aa59abded4bca9067167e019388e8",
            "86d0252735a24a269ab9957b5310da0d",
            "824c122570a34af9ad21b29d716a7765",
            "85563ccbbbb4475c8e441443658bd98d",
            "b99dec78f60f4964a345ce89d9e38c3a",
            "4299173a80e44fc88ce097b809ae5bae",
            "2821a2bf26744a0588b9abbff9981186",
            "0611dfba4b4049688624d9a9a64ad0f3",
            "111beb6d395f45fca0cd7f06f8aea4a2",
            "010b7f5c0d56478899213a0438de045f",
            "61560a8072c345f29400533235469c85",
            "4055e79093274dde82195aca992aa46b",
            "375f7fecaf6142d88d8a8906eb834353",
            "4b2b2777bde74953b0e3af553129ad1f",
            "a64cc5ef24144a6d902ded3c0fe15fce",
            "3081ca9a45a64b9895feef8029b174d7",
            "b6155cf86c1f401b9f54d1404faccf5f",
            "7c99082ca80f47efb14fb7bcfee9e0b4",
            "5d94e1a06c684474a8aa83bdfc892a26",
            "6e0dff563dcb49b89b970f52d5935eb7",
            "cb88677e88cb448b8a43a5342276f8a6",
            "025d76aa71a9413c9f4a45c97df9e24b",
            "035fab4a87594202886b486adf131e84",
            "9d8143b4de3c4a3ab26771d0a90511f2",
            "f30df2df5a9548c983305086d595f9bd",
            "e4265356a87e43b4bf614d631ec48115",
            "80e7280eca9242908fd88edf79cf1297",
            "ebc2ac680c694cf1a21f52e400aeb37b",
            "39a677f9e398421289c1f9d2c0dca2db",
            "dc688c6ee7164e45a19c120ff1688931",
            "3873184f9a4f404989c2e8e100e70390",
            "1ffaf6d941c54d5987fe044f46621462",
            "516494e9ace34f08acb7a28cc7a117a4",
            "d2393421b4ae41669717aaf1f7a6bfa5",
            "d3c5381c6edd41f5afc9dc72f621d716",
            "ed7ed724421447f0b01229f2d6c8d08a",
            "b9486c4887dc4269949a34b3bbbdd499",
            "58459e624338496a97adb626f443a050",
            "4d9739d852894fb893a9545b50d825b0",
            "50eca99b79224f2b86b4412125d3fd3e",
            "836c237ed39c487a8418a16876d8aa2d",
            "e9b7e317b6554a6e826ed6b06591b603",
            "944ed4dd1b2147ccaa44171d224148b0",
            "329e5178f64b43e0a36d4a6b9b92820c",
            "34ef59e0d4294ccba4f4975822f7d360",
            "77e0033412a7480aad8c3c85d72940ce",
            "6dcd4f42f967444997e9dcf1c0d9373b",
            "fbae3f52a82c4f12b39d050afb0bb861",
            "15a51422c8e74f75aebbecfc6ff32bbe",
            "d91f542393494669954a658803b1d73b",
            "a4c4c39c4b324e559936131aad3c13f6",
            "78fd9638a4cf4e99bb718577bc719662",
            "0630c6ff8ad7461f9ad8ac423ee815ff",
            "cdf2174f0883444aa3391d2cf4e40397",
            "d90b42ef14b04e07b2c3394490965570",
            "e3c4e01d216440898307a6d2787c82f8",
            "93a9573ea7d644f38640d7661855af8d",
            "e0af26f744f5488288de26c5c0b98865",
            "8676e7bfd0f24f0482a69c1b6fedfaf5",
            "318d65ac17a944919c7e6482cfbe7f45",
            "3298493cadc54b2aad0a5da66a602241",
            "61de28c6e48f4efba6a5071dda0ce30e",
            "5c34a7985ed34b8899e86b728ff2ed2d",
            "edeb20751de84f02bf3079bfb13af40e",
            "9ed4ba57ed7542ee8e30a6011ce7b4a0",
            "e33f60da891c40e69771da5e790541a4",
            "20c8467ec491410cbbcd7976455da0d5",
            "25a5821c8f104e5796f7b2272e389c94",
            "ad8b26a5ac104bd18f911676ab195044",
            "1948d6cf1b4f4797bfdcbe2f0e119516",
            "5865bc38ffa84c41bd159d64a03cb4e3",
            "70774acaae7a4ce599ae60df1ff76333",
            "369dd74edc6740bdacc670898bc67c0a",
            "0f9c4817a40047d49afc8bf985ff4818",
            "479ba1d47aa64eeba4822bcb05f91ccc",
            "42a32fb10d134d5c88c86f9834ea4324",
            "e34d7ab40e3a4418af146f6efcb289cb",
            "f91db839ac7c4e7b8172e38f276210a7",
            "ec546ca01c4549619dbc3e6ec9dc3bc1",
            "aeb2d967cacc4af29ef89adf945ae98d",
            "b6df6139daee41cba97780d543420c12",
            "11276920acfa4dd8a6321008cf3e97bb",
            "b2ce369c0b1d4efe81fde9414f9f609e",
            "4561e6b802554fc5a4f9670e6e33704f",
            "9ada9844667441e6b30affcae5a93dd5",
            "6b03789a44a44e9097e30926e5577e75",
            "ea2f826716b44ffdba0bdee173d90b6e",
            "1df53a7fdf84401086d8b6a03326d7ac",
            "edfc9e9c4e8b42c390e6b23943cf8d8b",
            "ccda76881eb34f40b2327c9ffc7a821a",
            "55a9d5a5d7d84f6bbaea37b12050bfa7",
            "8d8d6d860877484d9341fda449c30dea",
            "00b72acf538f4c55b0dee2d4022602a2",
            "3a51b4025ff24718a39281751a5e8fe7",
            "cac56d86f7e34be98fa0fec9e78fed9e",
            "9b9e75f609c84e4985f03b9b4eee109d",
            "fee0a80af6914852ae2aabd2baa726c5",
            "e12e526a149548298a12f17400ab0aec",
            "a818a608030141889c00f9b42cea2387",
            "9da1b1ddf529447d97c4930318ed8160",
            "20db8dc217f147e6b26072897cd12275",
            "268534ca03fa4acdbdb580ec1e9eef58",
            "a071a80907a3420086bd31ac864fcd03",
            "86e7edaa1a7941cbab0188ca378b6798",
            "43da5a26180d4d57b672c10918a4dd1c",
            "c2b5e90190f44d7d9a2af1584cfc3170",
            "8b1fe41bb7094ece8a57217775020f0a",
            "a6a58fcc7c9644f291e5854ed16d5701",
            "06d3dd9ba82b460d82a39ecfe8541a42",
            "53bf10394df44a99b85e4b2b79d5981b",
            "5d65527f2454417680158adc121d61e0",
            "05457dcf6546483d8e379e1bac4d21a0",
            "a225bfd8428840c1941d585d0ee6e658",
            "82e15f6100264c129d89faeeb6b43698",
            "b00f713c382d4192970f87f7778e48ff",
            "f4f1475679f74adf8ee5e1e71531d37f",
            "b53d0c8276f247d5906fbb01eb85a84c",
            "a7babedf17d8410391a5afaa7eb0e68c",
            "b5ccd0e13c6c424e954be4a343e2fba5",
            "61e2b42840e64b75a7bba4471af05ed2",
            "015b4dad1b2f48f18fa0ba0865d38c44",
            "d755dddad2c14faaacc634d1e427ef0f",
            "c55f97bbaaab4884b2cb88973331b856",
            "d880673208be4e78afb189acea0c586e",
            "93e6fa18147e4c7aba223366acee6ea9",
            "e6627f03469748e4b363f2bfa2dc5640",
            "b12e57f76a8345c38e1c14a10b549e7d",
            "d56d0c13ce2a4d13a835c8f56991a827",
            "9005ce45fc1f4293a0656e65bb3d6b80",
            "2490f3e7f95f47718e688c49b94b9ab7",
            "2367186ceae4483fafcabe4aea9ca250",
            "7f9a979a17ff4a5eb02ce8d3b0f6be77",
            "b3a56442c3a848898c95b6635ce243e5",
            "7d92c8926d73486bae3b1f4de16884d7",
            "e475b75615894a5f8fb3b2b8e84be352",
            "3200823534f64b92be8d3fb7302dffca",
            "8f32e19c672a445887231625e5da4bf9",
            "42f300d17f9b48a9968ac4f344c1096c",
            "e64bf9bdfc5e49ea931ddea59c6981e4",
            "3f5b2023b4974f7fa03cddc1e8d64ac1",
            "bd295cc9e32c4c88b453648819d58ed3",
            "12043c9d084a46879b0cbab058f468dd",
            "4f06bd3966164d109a8f1f4a37c901ab",
            "2e91f2cae8f244c0a4e8d2f9b3ad606b",
            "51f943b8c31049ad9ab0bac4edc14e55",
            "7bf35621e7ae4d0ea6f2b4f6bf349673",
            "4e296be589d34f558feb697aae81529d",
            "e0b88684b7ff4ad2ba8a7e731bb2a5cd",
            "d2aa7bf3c1b44981a5dd44b47db53d41",
            "dc7ed93e1f9b4857b02764003c09f591",
            "4a4ddc572ad94fe5b4b43b174c4da5dc",
            "d952a82192264e4b8f8ce726946e3c2d",
            "465a5f7781df4c4a8c29118b88f844c8",
            "38ea6aa19ca64182bc27ec4cfcabd166",
            "37a366bf95e147fd88d124d2254f6f39",
            "fd77380f79014db79a2a2b584b51294d",
            "739ab0fd5c26446fa0b79872dbdf9153"
          ]
        },
        "outputId": "2fda5019-389f-47b7-e25c-ed58c7e77c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summarize: Citizenship ceremonies could be introduced for people celebrating their ##th birthday Charles Clarke has said. The idea will be tried as part of an overhaul of the way government approaches \"inclusive citizenship\" particularly for ethnic minorities. A pilot scheme based on ceremonies in Australia will start in October. Mr Clarke said it would be a way of recognising young people reaching their voting age when they also gain greater independence from parents. Britain's young black and Asian people are to be encouraged to learn about the nation's heritage as part of the government's new race strategy which will also target specific issues within different ethnic minority groups. Officials say the home secretary wants young people to feel they belong and to understand their \"other cultural identities\" alongside being British. The launch follows a row about the role of faith schools in Britain. On Monday school inspection chief David Bell accused some Islamic schools of failing to teach pupils about their obligations to British society. The Muslim Council of Britain said Ofsted boss Mr Bell's comments were \"highly irresponsible\". The Home Office started work on its Community Cohesion and Race Equality Strategy last year and the outcome launched on Wednesday is called 'Improving Opportunity Strengthening Society'. It is aimed at tackling racism exclusion segregation and the rise in political and religious extremism. \"It represents a move away from the one-size-fits-all approach to focus on specifics within cultural groups \" said a Home Office spokesman. \"It is not right to say that if you are from a black or ethnic minority group you must be disadvantaged.\" The spokesman highlighted specific issues that affect particular communities - for example people of south Asian origin tend to suffer from a high incidence of heart disease. \"It is about drilling down and focusing on these sorts of problems \" the spokesman added. Launching the initiative Mr Clarke said enormous progress had been made on race issues in recent years. He added: \"But while many members of black and minority ethnic communities are thriving some may still find it harder to succeed in employment or gain access to healthcare education or housing. \"This strategy sets out the government's commitment to doing more to identify and respond to the specific needs of minorities in our society.\" Some #% of the UK population described themselves as coming from a non-white ethnic minority in the #### Census. The Downing Street Strategy Unit in #### said people from Indian and Chinese backgrounds were doing well on average often outperforming white people in education and earnings. But those of Pakistani Bangladeshi and black Caribbean origin were significantly more likely to be unemployed and earn less than whites it said. The Home Office wants more initiatives which try to promote a sense of belonging by encouraging young people to take part in voluntary work. The programmes are designed to support the citizenship lessons already taking place in schools.\n",
            "response:  The idea will be tried as part of an overhaul of the way government approaches \"inclusive citizenship\" particularly for ethnic minorities.It represents a move away from the one-size-fits-all approach to focus on specifics within cultural groups \" said a Home Office spokesman.IT represents...\n",
            "summarize: Church ministers are trying to prevent rapper Nelly performing in Arkansas saying they do not want his \"vile and filthy lyrics\" in their town. More than ## Jonesboro ministers urged music fans to boycott Nelly's ## March concert at Arkansas State University in a bid to have it cancelled. \"Jonesboro is a wonderful city because of what does not come here \" said the Reverend Adrian Rodgers. But a venue spokesman said more than # ### tickets had been sold so far. Mr Rodgers of the Fullness of Joy Church said he was concerned about the rapper's lyrics that include references to drugs sex and violence and songs that the minister said were demeaning to women. Ministers were worried that bringing such acts to Jonesboro would lead to problems. \"Tear the tickets up \" Mr Rodgers said. \"Do not go and do not allow your children to go.\" Tim Dean director of the Arkansas State University venue said ticket sales had been brisk. \"It would appear that with ticket sales over # ### many others have expressed their right to find Nelly's music entertaining and worth spending their time and money on \" he said. Nelly has sold more than ## million singles and albums worldwide and in September #### simultaneously occupied the number one and two positions in the US albums chart. He has had ## UK hit singles including Hot in Herre Dilemma and recent number one Over and Over.\n",
            "response:  More than ## Jonesboro ministers urged music fans to boycott Nelly's ## March concert at Arkansas State University in a bid to have it cancelled.Mr Rodgers of the Fullness of Joy Church said he was concerned about the rapper's lyrics that include references to drugs sex and violence and songs that the minister said were demeaning to women.\n",
            "summarize: Sky has signed a major new deal to broadcast this year's Academy Awards taking over from three years of live Oscar coverage on the BBC. Sky said it was \"honoured to have won exclusive broadcasting rights\" and promised to cover the event \"in a way no other broadcaster could\". The BBC denied it had lost a bidding war saying it had \"decided to pass the mantle to another broadcaster\". The ceremony hosted by newcomer Chris Rock takes place on ## February ####. Sky's coverage will launch with the nominations on ## January and will include themed programming across Sky channels including Sky News Sky Travel and the Biography Channel. There will also be a month-long season of Oscar-winning films on Sky Movies in the run up to the event and live uninterrupted coverage on the night. \"We are honoured to have won the live and exclusive broadcasting rights for The Academy Awards \" said Sky Networks' Sophie Turner Laing. \"Sky is the natural place to see the biggest and most prestigious film event of the year and will cover the event in a way that no other broadcaster could.\" Sky first scooped Oscar rights from the BBC in #### but the BBC won them back in #### when Sky was forced to pull out of a bidding war due to financial constraints. \"BBC viewers will of course be able to watch quality coverage of the #### Academy Awards on the BBC's bulletins and news programmes \" a spokesman said. Among the films tipped to do well at this year's Academy Awards are Martin Scorsese's The Aviator Jean-Pierre Jeunet's A Very Long Engagement and the Ray Charles biopic Ray.\n",
            "response:  Sky has signed a major new deal to broadcast this year's Academy Awards taking over from three years of live Oscar coverage on the BBC.The BBC denied it had lost a bidding war saying it had \"decided to pass the mantle to another broadcaster\".Sky is the natural place to see the biggest and most prestigious film event of the year and will cover the event in a way that no other broadcaster could.\n",
            "summarize: Owners of some Nokia smartphones are being warned to watch out for malicious wallpaper. Those downloading the software could find all the icons on their #### phone swapped for images of skulls. When installed the malicious program also locks many of the ####'s functions making it hard to use and harder to repair. The program is only the latest in a series of viruses produced to attack mobile phones. The file nicknamed Skulls is thought to have surfaced on shareware sites where people can pick up free add-ons such as wallpaper games and ringtones for their phones Symbian said that it was not sure if the damage Skulls does was intentional or simply a result of bad programming. Soon after being discovered the file is thought to have been removed from the sites that were unwittingly harbouring it. The program is masquerading as software that creates new background images and themes for the main screen of the #### phone. The Skulls program is labelled as a file called: ####.extended.theme.manager.zip. Once installed the program replaces all the icons on the main page with skulls and replaces all the working applications such as contacts calendar notebook etc with non-working versions so the phone becomes almost useless. The only thing the phone can do is make and take calls. A statement by Symbian played down the significance of the malicious program and said few people would fall victim to it as users have to go through several steps to install it one of which includes ignoring a security warning. Symbian said that the spread of the Skulls program was likely to be limited as the program cannot travel from one phone to another by itself. Despite this Finnish anti-virus lab F-Secure said it had sporadic reports of #### owners being caught out by it. The firm has produced guidance for users caught out to help them remove the program and get their phone working again. The Skulls program is thought to have been written by a malicious hacker using the alias Tee-###. Symbian phones produced by Sony Ericsson Motorola BenQ Arima and Fujitsu are unaffected by the Skulls program.\n",
            "response:  Owners of some Nokia smartphones are being warned to watch out for malicious wallpaper. Those downloading the software could find all the icons on their #### phone swapped for images of skulls.When installed the malicious program also locks many of the ###'s functions making it hard to use and harder to repair.The Skulls program is thought to have surfaced on shareware sites where people can pick up free add-ons such as wallpaper games and ringtones for their phones Symbian said that it was not sure if the damage Skelells does was intentional or simply a result of bad programming.\n",
            "summarize: Marks & Spencer has cut prices in London and the regions by an average of ##% according to research from a City investment bank. Dresdner Kleinwort Wasserstein said: \"In spite of the snow in the UK it still feels very early to be cutting prices of spring merchandise.\" Stuart Rose head of M&S said last year its prices were too high. \"We are bringing in ranges at new price points to compete against mid-market retailers like Next \" said M&S. Next is one of M&S's biggest competitors and the move may force it to lower prices. DrKW said the cuts are either to clear stock or could indicate a longer term \"step change in pricing in certain areas\" at M&S. \"Either way this cannot be good news for M&S' margin \" it added. \"We have brought in quite a lot of new clothing at new price points as part of Stuart Rose's strategy of quality style -and price \" said the M&S spokesman. Many analysts believe February is proving to be a difficult month for retailers and British Retail Consortium figures due in a few weeks are expected to reflect the tough trading environment. Separately investment bank Goldman Sachs produced reseach showing that a basket of ## M&S goods is now ##% above the high-street average compared with ##% higher last year. It has been a strange week for M&S which on Tuesday received a statement from Philip Green the billionaire Bhs owner confirming he was not rebidding for the company. This was followed the same day by Mark Paulsmeier a South African financier issuing a press release saying his Paulsmeier Group was interested in M&S. A sudden spike in M&S's share price followed. However an M&S spokesman said on Sunday it had no evidence that Mr Paulsmeier had lined up sufficient finance for a bid. He also said the Takeover Panel and the UK's financial watchdog the Financial Services Authority had been in touch with M&S at the beginning of the week to find out what it knew about the Paulsmeier developments.\n",
            "response:  Marks & Spencer has cut prices in London and the regions by an average of ##% according to research from a City investment bank.In spite of the snow in the UK it still feels very early to be cutting prices of spring merchandise.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summarize: The world's biggest confectionery firm Cadbury Schweppes has reported a modest rise in profits after the weak dollar took a bite out of its results. Underlying pre-tax profits rose #% to £###m ($#.##bn) in #### but would have been #% higher if currency movements were stripped out. The owner of brands such as Dairy Milk Dr Pepper and Snapple generates more than ##% of its sales outside the UK. Cadbury said it was confident it would hit its targets for ####. \"While the external commercial environment remains competitive we are confident that we have the strategy brands and people to deliver within our goal ranges in #### \" said chief executive Todd Stitzer. The modest profit rise had been expected by analysts after the company said in December that the poor summer weather had hit soft drink sales in Europe. Cadbury said its underlying sales were up by #% in ####. Growth was helped by its confectionery brands - including Cadbury Trident and Halls - which enjoyed a \"successful\" year with like-for-like sales up #%. Drinks sales were up #% with strong growth in US carbonated soft drinks led by Dr Pepper and diet drinks offset by the weaker sales in Europe. Cadbury added that its Fuel for Growth cost-cutting programme had saved £##m in #### bringing total cost savings to £###m since the scheme began in mid-####. The programme is set to close ##% of the group's factories and shed ##% of the workforce. Cadbury Schweppes employs more than ## ### people worldwide with about # ### in the UK.\n",
            "response:  Cadbury said it was confident it would hit its targets for ####.The modest profit rise had been expected by analysts after the company said in December that the poor summer weather had hit soft drink sales in Europe.\n",
            "summarize: Standard Life Europe's largest mutual life insurer has cut bonuses for with-profit policyholders. Annual bonus rates on its with-profits life policies were cut from #.#% to #% while bonuses on pension policies were reduced from #.##% to #.#%. It is the sixth time in three years Standard Life has made cuts to bonus rates despite an #.#% rise in the value of the with-profits fund in ####. The insurer blamed the cuts on poor share returns and low interest rates. With-profits policies are designed to smooth out the peaks and troughs of stock market volatility. Profits made in good years are kept in reserve to pay investors an annual bonus even when the stock market performs badly. Slumping share prices throughout #### and #### forced most firms to trim bonus rates on their policies. Standard Life came in for criticism for sticking with stock market investments during #### and ####. The insurer argued that shares outperformed other investments over the long term and that policyholders would feel the benefit when the stock market recovered. Recently Norwich Union and Axa Sun Life both cut their with-profit bonus rates. John Gill managing director of the insurer's life and pensions division said that a strong stock market recovery in the past two years had only \"partly compensated for losses during #### and ####\". In addition low interest rates meant that \"long-term investment returns are well below historic levels\" Mr Gill added. However Mr Gill maintained that with-profits continued to perform well over the long term. \"Our payouts continue to stand up well against other types of long-term investments over similar periods \" he said. Standard Life has an estimated #.# million with-profits policyholders. Last year the company announced that it was looking to float on the stock market in ####.\n",
            "response:  Annual bonus rates on its with-profits life policies were cut from #.#% to #% while bonuses on pension policies were reduced from # ####% to #1.#0%.The insurer blamed the cuts on poor share returns and low interest rates.Slumping share prices throughout ##*** and ##** forced most firms to trim bonus rates upon their policies.Standard Life Europe's largest mutual life insurer has cut bonuses for with-loss policyholders.The insurance argued that shares outperformed other investments over the long term and\n",
            "summarize: Russian drama The Return (Vozvrashchenie) has been named winner of the BBC Four World Cinema Award. The film tells the story of two adolescent boys who are subjected to a harsh regime when their strict father returns after a ##-year absence. Directed by Andrey Zvyagintsev The Return previously won the #### Golden Lion award at the Venice Film Festival. The prize was presented at an awards ceremony held in London on Thursday and hosted by Jonathan Ross. The winner was chosen by a panel which included X Files actress Gillian Anderson critic Roger Clarke and Touching the Void director Kevin McDonald. Ross who is the presenter of BBC One's Film #### was also involved in the deliberations. A shortlist of six films from around the world had been drawn up from which the panel chose. Other nominees included the Motorcycle Diaries Zatoichi and Hero. A viewer poll saw director Zhang Yimou's martial arts epic Hero emerge as the favourite with ##% of votes cast. Tragedy struck the production of The Return when one of the young stars ##-year-old Vladimir Girin drowned in a lake where some of the film's scenes were set. The winner of the World Cinema Award last year was the French animated feature Belleville Rendezvous\n",
            "response:  Russian drama The Return (Vozvrashchenie) has been named winner of the BBC Four World Cinema Award. The film tells the story of two adolescent boys who are subjected to a harsh regime when their strict father returns after a ##-year absence.The prize was presented at an awards ceremony held in London on Thursday and hosted by Jonathan Ross.The winning was chosen by a panel which included X Files actress Gillian Anderson critic Roger Clarke and Touching the Void director Kevin McDonald.\n",
            "summarize: The proportion of surfers using Microsoft's Internet Explorer (IE) has dropped to below ##% say web analysts. Net traffic monitor OneStat.com has reported that the open-source browser Firefox #.# released on # November seems to be drawing users away from IE. While IE's market share has dropped #% since May to ##.#% Mozilla browsers - including Firefox - have grown by #%. Firefox is made by the Mozilla Foundation which was set up by former browser maker Netscape in ####. Although there have been other preview versions of Firefox version #.# was the first complete official program. \"It seems that people are switching from Microsoft's Internet Explorer to Mozilla's new Firefox browser \" said Niels Brinkman co-founder of Amsterdam-based OneStat.com. Mozilla browsers - including Firefox #.# - now have #.#% of the market share the figures suggest. Mozilla said that more than five million have downloaded the free software since its official release. Supporters of the open-source software in the US managed to raise $### ### (£### ###) to advertise the release of Firefox #.# in The New York Times and support the Mozilla Foundation. There was a flurry of downloads on its first day of release. The figures echo similar research from net analyst WebSideStory which suggested that IE had ##.#% of users in October compared to ##.#% in June. Microsoft IE has dominated the browser market for some time after taking the crown from Netscape and its share of users has always stayed at around the ##% mark. Firefox is attractive to many because it is open-source. That means people are free to adapt the software's core code to create other innovative features like add-ons or extensions to the program. Fewer security holes have also been discovered so far in Firefox than in IE. Paul Randle Microsoft Windows Client product manager responded to the figures: \"We certainly respect that some customers will choose alternative browsers and that choosing a browser is about more than a handful of features. \"Microsoft continues to make significant investments in IE including Service Pack # with advanced security technologies and continues to encourage a vibrant ecosystem of third party add-ons for Internet Explorer.\" Firefox wants to capture ##% of the market by the end of ####. Other browser software like Opera and Apple's Safari are also challenging Microsoft's grip on the browser market. Opera is set to release its version #.## by the end of the year. OneStat.com compiled the statistical measurements from two million net users in ### countries.\n",
            "response:  Net traffic monitor OneStat.com has reported that the open-source browser Firefox #.# released on # November seems to be drawing users away from IE.\n",
            "summarize: A documentary which takes a candid look at the life of chart-topping singer George Michael will be shown at this year's Berlin Film Festival. A Different Story will screen in the Panorama section of the festival which runs from ##-## February. It features the singer talking about both his career and his personal life from his days in Wham! through to more recent events. Michael will attend the festival to introduce the screening on ## February. Director Southan Morris and executive producer Andy Stephens will also attend the festival. The ## minute film will see Michael discussing his early days in Wham! along with his later career including his legal battles with record label Sony and his stance against the Iraq war and American politics. It will also touch upon his turbulent personal life including his arrest in a Beverly Hills park toilet in #### for \"lewd behaviour\" and the death of his boyfriend Anselmo Feleppa from Aids. The film which includes previously unseen footage of the singer also features contributions from Michael's former Wham! partner Andrew Ridgeley as well as ex-Wham! backing singers Pepsi and Shirlie. Other contributors include Sting Mariah Carey Elton John Noel Gallagher Geri Halliwell and Simon Cowell. This year's festival will open with Man To Man a historical epic starring Joseph Fiennes and Kristin Scott-Thomas. It will be one of ## films competing for the festival's top prize the Golden Bear. Other films in competition will include The Life Aquatic a quirky comedy starring Bill Murray and the biopic Kinsey which features Liam Neeson. The full programme will be announced on # February.\n",
            "response:  A documentary which takes a candid look at the life of chart-topping singer George Michael will be shown at this year's Berlin Film Festival. It features the singer talking about both his career and his personal life from his days in Wham! partner Andrew Ridgeley as well as ex-Wham! backing singers Pepsi and Shirlie.The full programme will be announced on # February.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c15d377dd51462d93805b07b38414de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6864 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8193ded5c2d5430dbb9a92a584ab7365"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "def061b4f17c433f832db9e571a16139"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17725729e83f41bc8171f30312594b7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b83fceae68a4e5b916b2b5f7fc364a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd213ab0d9ef4d46b294129992cf912d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bffb7c9910434bcdbd019d2554150749"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2f377c0231f4df684bb4be5f0f16895"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec94ebb55556459e89047ed12aa9965a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summarize: Former us president bill clinton announced on monday that his foundation will provide ## million us dollars for aids treatment for ## ### children in ## developing countries in ####.\n",
            "response:  Clinton foundation to provide ## ### aids treatment for children.-# #### charitable foundation to help ## indiana kids in developing countries.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summarize: Macau s monetary authority on tuesday denied a news report that several north korean bank accounts in the territory had been unfrozen after being put on hold over united states allegations of financial irregularities.\n",
            "response:  Macau monetary authority denies north korean bank accounts unfrozen.-)T Preparatory financial information from the company is contained in a report.\n",
            "summarize: The leaders of jordan egypt and the palestinians today reiterated the necessity of promoting arab efforts aiming at maintaining the peace process and ensuring the implementation of the agreements which have been signed.\n",
            "response:  Egypt palestinians reiterate importance of promoting arab efforts.----sunteti Forum urges more effort on peace process with arabs to ensure implementation of agreements signed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summarize: United states senate candidate rand paul is stirring up controversy again this time by saying he opposes citizenship for children born in the united states to parents who are illegal immigrants.\n",
            "response:  Senate candidate senate candidates raise controversy over children born in us.-#.dx.de Pageant criticizes paul on immigration reform.\n",
            "summarize: A list of some ### alleged homosexuals which has been circulating on the internet has sparked panic among gays in predominantly catholic croatia an activist said monday.\n",
            "response:  ### alleged homosexuals circulate on internet.dh.-dhoaning list sparks panic among gay people in predominantly catholic croatia.\n",
            "summarize: Serbia-montenegro s army friday opened up its top secret underground shelter in belgrade for years rumored to be a hideout for war crimes suspects state television said.\n",
            "response:  Englishsunteti German army offers free standing for war crimes suspects spy hideout claims defense agency.\n",
            "summarize: City officials and the owners of a philippine disco that burned down three years ago killing ### people have been acquitted on corruption charges a court officer said wednesday.\n",
            "response:  City officials owners acquitted in philippine disco burned down.----- ### people appointed on corruption charges.\n",
            "summarize: Steven spielberg serves up one of the most complicated history lessons in the annals of modern hollywood with `` amistad.\n",
            "response:  Spielberg takes up complex history lesson. English writer amistad s journey to hollywood.-.\n",
            "summarize: Romania s social democrat prime minister adrian nastase took some ## percent of votes in sunday s presidential vote exit polls showed and is to face centre-right rival traian basescu in a second round on december ##.\n",
            "response:  Social democrat prime minister takes ## percent of vote.s.nastases to face basescu in second round.-#.»«’s nastase wins presidential polls and faces bascu in britain s governing body.\n",
            "summarize: Despite the shock of failing to beat lowly scotland dutch manager guus hiddink is still confident of going home with the european championship trophy.\n",
            "response:  Hiddendink confident of going home with european championship trophy. ##.-Blatt scotland s-# champions.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06044ea8d4a1487082692d13af984158"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5102 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c26827811d44f6e8109c1d2344e9dd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "772fd270212446629dbb17ce52968536"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd5fed5e08fa4360953153489d78a7d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85563ccbbbb4475c8e441443658bd98d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a64cc5ef24144a6d902ded3c0fe15fce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4265356a87e43b4bf614d631ec48115"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9486c4887dc4269949a34b3bbbdd499"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbae3f52a82c4f12b39d050afb0bb861"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summarize: An ideal observer model for identifying the reference frame of objects Joseph L. Austerweil Department of Psychology University of California Berkeley Berkeley CA ##### Department of Computer Science and Engineering Abram L. Friesen University of Washington Seattle WA ##### Joseph.Austerweil@gmail.com afriesen@cs.washington.edu Thomas L. Grifﬁths Department of Psychology University of California Berkeley Berkeley CA ##### Tom Griffiths@berkeley.edu Abstract The object people perceive in an image can depend on its orientation relative to the scene it is in (its reference frame). For example the images of the symbols × and + differ by a ## degree rotation. Although real scenes have multiple im- ages and reference frames psychologists have focused on scenes with only one reference frame. We propose an ideal observer model based on nonparametric Bayesian statistics for inferring the number of reference frames in a scene and their parameters. When an ambiguous image could be assigned to two conﬂicting reference frames the model predicts two factors should inﬂuence the reference frame inferred for the image: The image should be more likely to share the refer- ence frame of the closer object (proximity) and it should be more likely to share the reference frame containing the most objects (alignment). We conﬁrm people use both cues using a novel methodology that allows for easy testing of human reference frame inference. # Introduction When are the objects in two images the same?# Although people recognize and categorize objects successfully and effortlessly object recognition in machine learning is an incredibly difﬁcult prob- lem and people’s success is a puzzle to cognitive scientists. To solve this problem object recognition techniques typically generate a set of features using a predeﬁned procedure (e.g. SIFT descriptors [#] or textons [#]) or learn features (e.g. deep belief networks [#]) from the images. The general goal of these methods is to extract features from images that are useful for identifying the objects that generated the images after whatever transformations occurred while producing them (e.g. view- point changes). This is a sensible strategy given that people typically perceive the same object even when it is transformed in its image (e.g. translations). However not all transformations should be ignored: The perceived identity of some objects depends on the orientation of its features with respect to the scene it is in (e.g. × vs. + differ only in orientation) but for other objects it does #In this paper we use the following terminology for scene image and object. The entire visual input of an observer is a scene. A scene contains a set of images. An image is a part of the visual input that is generated by a single object which is ambiguous as two or more objects could generate the same image. An object is the item in the world that generates an image in the visual input. # not. Developing proper object recognition and fully understanding how people do it depends on explaining how people determine the orientation of objects with respect to the scene they are in. The importance of orientation for object recognition leads us to the following question: If two ob- jects project to the same image under different viewing conditions (e.g. + and × after ## degree rotations) how do people infer which object is in the image? In psychology there are two main theories for how people solve this problem: the invariant feature hypothesis [#] which is essentially the strategy taken by current object recognition techniques (use features that preserve object identity over the possible transformations that generate images of the object) and the reference frame hy- pothesis which posits that objects are embedded in coordinate axes [#]. The coordinate axes set the orientation and scale of the objects and thus + and × can be identiﬁed as different objects. Though they may produce the same image they will have different coordinate axes. In some situations the orientation of an image’s reference frame is simply the orientation of the retina; however this is not the case when we rotate our heads (as our retinal image rotates) or look at a rotated object (e.g. a person lying on a bench or a document rotated on a desk). Thus the reference frame of an image is ambiguous without additional information. However if there is another object in the scene whose orientation is unambiguous (like a #) then the orientation of the ambiguous image can be inferred.# We demonstrate that people use the orientation of other images in the scene to determine the orientation of an ambiguous image by asking participants to solve arithmetic problems where the operator image is ambiguous and the two numbers ﬂanking the operator are either oriented upright or rotated ## degrees. The solution people adopt is indicative of the reference frame they inferred for the operator (multiplication implies an upright reference frame and addition implies a diagonal reference frame). This is a novel experimental method that allows us to explore reference frame inference in a wide range of contexts. In real life we typically view scenes with multiple reference frames. For example some books on a bookshelf might be upright other books could be tilted diagonally (for support) while other books might lie ﬂat. Yet there has been little work investigating how people infer the number of reference frames their orientations and which images belong to each reference frame. To solve this problem we note that each image in a scene belongs to a single reference frame and thus reference frames form a partition of the images in a scene (where each block in the partition corresponds to a reference frame). Using a standard nonparametric Bayesian model for partitions we formulate an ideal observer model to infer multiple reference frames and their parameters. The model predicts that people should be sensitive to two cues when inferring the reference frames of a scene: the proximity of the ambiguous image to two unambiguous ﬂanking images in conﬂicting orientations and the difference in the number of objects aligned in the competing reference frames. We conﬁrm people are sensitive to both cues using the novel method described above. The summary of the article is as follows. First Section # summarizes relevant psychological research on how orientation affects the objects perceived in ambiguous images. Next Section # develops a novel method for online testing of the reference frame people infer for an image and establishes its efﬁcacy. Section # presents an ideal observer model for reference frame inference in scenes with multiple reference frames. The model predicts that the ambiguous image’s proximity to other reference frames should affect the inferred reference frame and Section # conﬁrms that people act in accordance with this prediction in a behavioral experiment. The model also predicts that the number of aligned objects in a reference frame should affect the reference frame inferred for an ambiguous image. Section # conﬁrms this prediction in a behavioral experiment. Section # concludes the paper and highlights some directions for future research. # Orientation in psychological theories of object representation Though the perceived object of some images does not depend on its orientation (like a #) there are many examples where the perceived object does depend on its orientation [# #] including + vs. × or a square vs. a diamond and other effects of orientation on object recognition [# ##]. This has led psychologists to believe that people represent objects within a reference frame (a set of coordinate axes).# Figure # (a) shows that reference frames predict the image + is interpreted as a + when #We view the ambiguity of a reference frame as essentially the same as the strength of the intrinsic axes [#]. #Though coordinate axes have other properties (e.g. scale) we focus on orientation in this article. # (a) (b) # # (c) # + + + + # (d) + ++ + ++ Figure #: Reference frames. (a) The ambiguity of the + image can be resolved using reference frames: a + with horizontal orientation (solid axes) or a × rotated ## degrees (dashed axes). (b) Other images are unambiguous like a #. (c) The reference frame of ambiguous objects is inﬂuenced by objects with unambiguous reference frames. (d) The group of objects is seen as either all + or all × but not some + and some ×. This establishes one reference frame per group. the coordinate axes are aligned with the document’s axes and as × when the coordinate axes are diagonal to the document’s axes. For objects that are rotationally invariant there is only one object that generates the observed image and so it is identiﬁable in any orientation (see Figure # (b)). The dependence of object perception on orientation is a well established norm and has been demonstrated with novel and familiar #-D objects faces handwriting [# #] and #-D objects [## ##]. Central to the reference frame hypothesis is the ability of our perceptual system to infer a reference frame for a given image. As more than one reference frame may be consistent with an observed image psychologists have explored how people infer the appropriate reference frame for an image. Though reference frame inference is strongly inﬂuenced by the top-down axis of the retinal image and by the axis of gravity (given by our proprioceptive and vestibular senses) [#] the scene itself can inﬂuence the inferred reference frame. Objects grouped together in the world tend to be affected by the same transformation when they generate images (e.g. the text on a poster as the poster is rotated) and so it is sensible that the inferred reference frame for an ambiguous image is inﬂuenced by the orientations of the images surrounding it. Figures # (c) and (d) are phenomenological demon- strations of how the alignment of the orientations of other objects in a scene can bias the inferred reference frame for an image whose reference frame is ambiguous (and there is strong corroborating empirical evidence for this principle [## ##]).# Figure # (c) is biased towards being interpreted as × based on the surrounding context and the images in Figure # (d) are interpreted as either all + or all tilted × but it is difﬁcult to interpret some as + and others as tilted × simultaneously [##]. Thus there is one reference frame shared by all the objects in a group. Although there is a wealth of research into reference frame inference for scenes containing a single reference frame to the best of our knowledge there has not been any research into how people de- termine the reference frame of ambiguously oriented images when there is more than one reference frame in the scene (and both are consistent with the images). Before exploring what cues inﬂu- ence human reference frame inference in scenes with multiple reference frames we develop a novel method for testing human reference frame inference. # Testing reference frame inference using arithmetic To test how different factors inﬂuence the reference frame people infer for an image we ask people to solve an arithmetic problem without specifying the appropriate operation. If people view × and their response is the multiplication answer then their reference frame for × is aligned with the horizontal and vertical axes of the page. Alternatively if people view the same × but their response is the addition answer then their reference frame for × is aligned with the axes diagonal to the page (and thus relative to its own reference frame it is treated as +).# We use this new method instead of previous techniques (e.g. explicitly asking the image’s orientation and recording the frequency each orientation is chosen that is either compatible or conﬂicting to the tested hypothesis [##]) due to its ability to be used in a wide range of contexts and to demonstrate the robust importance of reference #We use slightly different terminology than previous work has done and refer to this principle as alignment rather then symmetry to avoid the ambiguity in the word symmetry (which symmetry we are referring to). #Although we use + and × as the ambiguous images this method works with any ambiguous images by teaching the participant to use addition in one orientation of the image and multiplication in the other. # (a) (b) (c) (d) Axis Oriented Diagonal Oriented Axis Oriented Diagonal Oriented ## # # + + # # ## y c n e u q e r F # # y c n e u q e r F # # ## ## Response ## ## Response Figure #: Effect of the orientations of other objects in the same reference frame. (a) #s aligned with axes implies that the operator is ×. (b) #s aligned with diagonal implies the operator is + at a diagonal orientation. (c) Frequency of answers to (a) given by participants. Most participants respond with ## the solution to the product of # and # meaning their reference frame is aligned with the axes of the page. (d) Frequency of answers to (b) given by participants. Most participants respond with ## meaning their reference frame is aligned with the diagonals of the page. frame inference on a seemingly unrelated cognitive behavior (solving an arithmetic problem). We conﬁrm its validity by reproducing a previously found effect – the inﬂuence of orientation on other images in the scene [##]. When the reference frame for an image is ambiguous one factor that inﬂuences the inferred refer- ence frame is the orientation of other images it is grouped with especially when those images are identiﬁable in any orientation. Thus if we ask people to solve an arithmetic problem where the operator × is paired with the numbers # aligned with the top-down axes of the page (Figure # (a)) they should respond ## the result of multiplication. Alternatively if people solve the same problem except the numbers # are aligned diagonally they should infer the diagonal axes to be the reference frame and respond ## the result of addition (Figure # (b)). To test this method we recruited ## participants online who answered one arithmetic problem in exchange for a small monetary reward. The participants were counterbalanced over the axis or diagonally oriented conditions (Figures # (a) and (b) respectively) and all participants gave either the addition (##) or multiplication (##) solution. By changing the orientation of the numbers the solutions to the arithmetic problems given by participants in Figures # (a) and (b) are different despite having identical numbers and the identical operator image. Figures # (c) and (d) show that the responses of two groups of participants who answered the arithmetic problem in (a) and (b) differed as predicted (χ#(#) = #.### p < #.## using Yates’ chi-square correction). Thus asking participants to solve arithmetic problems is an effective method for testing reference frame inference and perceived orientations can inﬂuence higher level cognition. # Modeling reference frame inference Before describing our model of reference frame inference with multiple reference frames we ﬁrst present a probabilistic model for scenes of multiple images with only a single reference frame. #.# Reference frame inference for scenes with one reference frame We assume that a vocabulary of possible objects is known ahead of time of size V and that there are R possible rotations. Each scene (e.g. Figure # (a) is one scene) consists of a set of images (e.g. # × and # are the images of Figure # (a)). For each image i in a scene the model is given its visual properties yi and its spatial location xi = (xi# xi#) The visual properties of the image yi are generated by an unknown object vi rotated by r the orientation of the scene’s reference frame. A V × R binary image-object alignment matrix A(i) encodes the object-rotation pairs consistent with the observed image yi such that A(i)(v r) = # if the image of object v rotated r degrees is consistent with yi. The model assumes that the spatial locations of the images are independent identically distributed draws from a Gaussian distribution with shared parameters µ the center point for the reference frame and Σ the spread of objects around its center point. The unobserved objects and the orientation of the reference frame r are drawn from independent discrete distributions # with parameters φ and θ the prior over objects and reference frame orientations respectively. The following generative model deﬁnes our statistical model: r|θ ∼ Discrete(θ) xi|µ Σ ∼ Gaussian (µ Σ) iid∼ Discrete(φ) vi|φ P (yi|vi r) = A(i)(vi r) If the model assumes there are three types of objects (# + and ×) and two possible rotations (# and ## degrees) the model captures the sensitivity of participants in the demonstration (Figure #). In Figure # (a) the #s are oriented at # degrees. A(# r) is only non-zero when r = # because no other object can produce an image consistent with the observed image of the #. r = # implies that the operator is × which is consistent with participant responses (Figure # (c)). When the #s are oriented at ## degrees (Figure # (b)) A(# r) is only non-zero when r = ## for the same reason as before. r = ## implies that the operator is + which is consistent with participant responses (Figure # (d)). #.# Extending the model for scenes with multiple reference frames Although the model deﬁned in the previous section succeeds in inferring the reference frame of an ambiguous image using other images it is grouped with it cannot handle scenes containing multiple reference frames such as the scenes in Figure #. We extend the model by partitioning the images of a scene into reference frames where each image of the scene belongs to exactly one reference frame and a reference frame is a block of the partition. From this perspective inferring multiple reference frames for a scene of images is equivalent to partitioning the scene or clustering the images. With the insight that grouping images into reference frames is like ﬁnding a partition of a scene we can extend our model to select the reference frames of a scene (with an unknown number of reference frames). First we generate a partition of the images in the scene from the Chinese restaurant process (CRP) [##] with parameter α an exchangeable distribution over partitions. The CRP is deﬁned through the following sequential construction: P (ci = k|c# . . . ci−#) = (cid:##) nk α α+i−# α+i−# k ≤ K k = K + # where K is the current number of reference frames and nk is the number of objects assigned to reference frame k. ci denotes the reference frame that object i is assigned to and if ci = K + # it is assigned a new reference frame containing none of the previous objects and K increments by one (to initialize the ﬁrst object starts its own reference frame and K = #). This gives us an assignment vector c where ci = j denotes reference frame j contains image i. Each block in the partition (reference frame) j is associated with a rotation rj and is embedded in the spatial layout of the scene with a center position µj and spread Σj (each of which is generated from a Gaussian-Inverse Wishart distribution with shared parameters). Thus we have deﬁned the following generative model for a set of images in a scene: c|α ∼ CRP(α) rj|θ iid∼ Discrete(θ) xi|ci µci Σci ∼ Gaussian (µci Σci ) iid∼ GIW (µ# Σ# k# ν#) µj Σj|µ# Σ# k# ν# iid∼ Discrete(φ) vi|φ P (yi|vi rci ci) = A(i)(vi rci ) where GIW signiﬁes the Gaussian-Inverse-Wishart distribution and α µ# Σ# k# ν# θ and φ are hyperparameters of our model. We use Gibbs sampling for inference [##] which gives us the cluster assignments for each image and the updated parameters ψj = (µj Σj rj) for each cluster j. We begin by assigning each image to its own reference frame and then iterating. For each observed image we resample ci from the set of existing clusters and m = # newly drawn clusters. After all ci values have been resampled we discard any empty clusters and update the parameters of the remaining clusters by drawing them from their posterior distribution given the objects assigned to that reference frame p(ψj|{xi yi : ci = j}) where {xi yi : ci = j} is the set of images and their locations in reference frame j. #.# Predictions for human reference frame inference What factors inﬂuence the reference frame assigned to an ambiguous image according to our ideal observer model? Two factors it predicts should inﬂuence the image’s inferred reference frame are # Operator Position -# Operator Position -# Operator Position # Operator Position # # # # + # + + # + # # # Figure #: Trials from Experiment # showing the possible positions of the operators for the main factor of the experiment. Other factors randomized over trials are the numbers in the problem (always single digits) which of the two numbers was rotated the diagonal that the numbers and operator are aligned on (positive diagonal shown in the ﬁgure but numbers and operator aligned on the negative diagonal as well) and the rotation of the operator. (a) Participant responses for proximity experiment (b) Model predictions for proximity experiment t f e l d e p u o r g t n e c r e P #.# #.# #.# #.# # −# −# # Operator Position # t f e l d e p u o r g t n e c r e P #.# #.# #.# #.# # −# −# # Operator Position # Figure #: Proximity effects: (a) Human results and (b) Model results. The closer the operator is to the left number the more likely it is to take the left number’s orientation. proximity or how close the image is to unambiguous images (as images in the same reference frame are coupled in spatial location) and alignment or the difference in the number of images assigned to each reference frame. The general paradigm we use to test the predictions is to have the + or × operator ﬂanked by a number with different orientations on each side (see examples in Figure #). It is clear that the two numbers should have their own reference frame but it is ambiguous which reference frame the operator should be assigned to. We compare how each of these factors inﬂuences the reference frames inferred in the scene by people and our model in two behavioral experiments. # Experiment #: Proximity effects on reference frame inference When the reference frame for an image is ambiguous and there are two conﬂicting neighboring reference frames our model predicts that proximity or the distance of the ambiguous image to the two conﬂicting reference frames should affect the reference frame adopted by the ambiguous image. We explore this question using the method presented above where participants are asked to solve an arithmetic problem where the operator is ambiguous between + or × and the two numbers have conﬂicting reference frames (orientations). This allows us to deduce the reference frame inferred for the operator image from the answer given by participants. We manipulate proximity by changing the location of the operator such that it is closer to one of the two numbers as shown in Figure #. #.# Methods A total of ### participants completed the experiment online through Amazon Mechanical Turk in exchange for $#.## USD. Four participants did not give a correct solution to the arithmetic problem (neither the addition nor multiplication solution) leaving ### participants for analysis. Participants were asked to maximize their window before answering the arithmetic problem. All factors were manipulated between subjects as preliminary testing demonstrated a strong effect of trial order on the selected reference frame (probably because reference frames rarely change in the world). # The primary factor of interest of the experiment was the position of the operator scored from -# (far to the left) to # (far to the right) which was counterbalanced over participants (without the # position). The problem was viewed through a simulated aperture (to minimize the effect of the monitor’s reference frame). See Figure # for example trials with the operator in each position. There were several other factors that were randomized over participants: the numbers in the problem (randomly chosen single digit numbers) which number was rotated (left or right) the diagonal that the numbers and operator were aligned on (positive diagonal as shown in Figure # or negative diagonal) and the rotation of the operator (+ or ×). #.# Results and Discussion Figure # (a) shows that participants are more likely to infer the orientation of the left number for the operator the closer it is to the left number. The results conﬁrm our hypothesis: the closer the operator is to an image with an unambiguous reference frame the more likely participants are to infer that reference frame for the operator (χ#(#) = #.## p < #.## for -# vs. #). A probit regression analysis corroborates this result as the regression coefﬁcient is signiﬁcantly different from zero (p < #.##). The model results were generated using Gibbs sampling (as previously described) and shown in Figure # (b). For each trial we ran the sampler for ## burn-in iterations recorded ### samples and then thinned the samples by selecting every # samples. This left ### samples that formed our estimate for the proportion of times the operator grouped with the left reference frame. The parameters were initialized to: α = #.### µ# = [###.# ###.##] Σ# = ####I (scenes are ###×### pixels with the bottom-left corner as origin) where I is the identity matrix k# = #.# and ν# = ###. The discrete distributions encoding the priors on objects and orientations θ and φ were uniform over all V and R possibilities. The model and human results clearly exhibit the same qualitative behavior: As the distance between the operator and the left number decreased the probability the operator took the orientation of the left number increased. # Experiment #: Alignment effects on reference frame inference Our model also predicts that the difference in the number of unambiguous images assigned to the conﬂicting reference frames should affect the reference frame adopted by the operator image. In this experiment we test the prediction using the same method as above but manipulate the number of extra oriented unambiguous objects in each of the competing reference frames (see Figure # (a)). #.# Methods A total of ## people participated online through Amazon Mechanical Turk in exchange for $#.## USD. There were ## participants who gave an incorrect answer leaving ## participants for analysis. The instructions and design were identical to the previous experiment except that there were two extra factors manipulating the context of the left and right number (# on the left and # on the right or vice versa) and there were only two operator positions (-# and #). Figure # (a) illustrates example trials of the context manipulations for the operator in position -#. #.# Results and Discussion Figure # (b) shows that participants were more likely to infer the operator’s orientation to be the ori- entation of whichever side had more objects and it was closer to replicating the effect of Experiment # (χ#(#) = ##.#### p < #.#### ). Model results were generated using the same procedure and pa- rameter values as Experiment # (except ν# = ## to account for the increased number of objects) and Figure # (c) shows its similarity to participant results. # Conclusions and future directions In this paper we introduced the ﬁrst study of how people infer the reference frame of images in scenes with multiple reference frames. We presented an implicit method for testing reference frame inference an ideal observer model that predicts people should be sensitive to two scene cues and # Alignment effects on participant responses #L#R #L#R −# Operator Position # Alignment effects on model responses #L#R #L#R (a) (b) #L#R #L#R # # + # + # (c) # #.# #.# #.# #.# t f e l d e p u o r g t n e c r e P # # #.# #.# #.# #.# # t f e l d e p u o r g t n e c r e P Figure #: Alignment effects. The operator is more likely to take the orientation of the side with more objects. #L#R denotes ﬁve objects in the left reference frame and one object in the right and #L#R indicates the opposite arrangement. (a) Example stimuli (b) Human results and (c) Model results. −# Operator Position # behavioral evidence supporting its predictions. Because the objects people perceive depend on the orientation of their images in the scene these results improve our understanding of how the conﬁg- uration of objects in scenes affects object perception. We plan to extend our model to capture other cues identiﬁed by perceptual psychologists. A ﬁrst step is to include the bias towards using the up-down axis of the input image [#] by using a non- uniform distribution over rotations (estimating θ). We can capture the elongation cue (that the orientation of the spread of images in a scene biases the orientation of the reference frame of the images in the scene [#]) by coupling the covariance matrix (Σ) and rotation (r) of a reference frame. Currently our model assumes the positions of images in a reference frame are Gaussian distributed; however people have strong expectations about the arrangement of images in a scene [##]. We plan to compare people’s bias to a sophisticated scene segmentation model [##]. We are also interested in cues that depend on the structure of the images or the orientation of the agent in the world like axes of symmetry [#] or gravitational axes [#]. Another direction for future work is to address an assumption of the model: How do people learn the set of objects and whether or not those objects are orientation-invariant? A potential solution is to combine our model with previous work that presented a nonparametric Bayesian model for learning features and the transformations they are allowed to undergo [##]. Hopefully incorporating our model into this feature learning method will yield better inferred features and in turn will help create better feature generation and object recognition techniques by providing better understanding of how people perceive objects from ambiguous image data. Finally we plan to explore how the presented principles scale to more realistic scenes with objects more complex than + and × and more orientations. Our paradigm provides a principled starting point for investigating how reference frames are identiﬁed in scenes with multiple reference frames. It is easily extended to more complex scenes by associating different orientations (or rotations in depth) of an ambiguous image with different arithmetic operators. Our hope is that this leads to a better understanding of object identiﬁcation and reference frame identiﬁcation. Acknowledgements We thank Karen Schloss Stephen Palmer Anna Rafferty David Whitney and the Compu- tational Cognitive Science Lab at Berkeley for discussions and AFOSR grant FA-####-##-#-#### for support. # References [#] D. G. Lowe. Object recognition from local scale-invariant features. In Proceedings of the International Conference on Computer Vision volume # pages ####–#### ####. [#] D. R. Martin C. C. Fowlkes and J. Malik. Learning to detect natural image boundaries using local brightness color and texture cues. IEEE Transactions on Pattern Analysis and Machine Intelligence ##(#):###–### ####. [#] G. E. Hinton and R. R. Salakhutdinov. Reducing the dimensionality of data with neural net- works. Science ###:###–### ####. [#] O. G. Selfridge and U. Neisser. Pattern recognition by machine. In Computers and thought pages ###–###. McGraw-Hill New York ####. [#] S. E. Palmer. Reference frames in the perception of shape and orientation. In Object per- ception: Structure and Process pages ###–###. Lawrence Erlbaum Associates Hillsdale NJ ####. [#] M. Wiser. The role of intrinsic axes in shape recognition. In Proceedings of the Third Annual Meeting of the Cognitive Science Society pages ###–### San Mateo CA ####. Morgan Kaufman. [#] E. Mach. The analysis of sensations. Open Court Chicago ####/####. [#] I. Rock. Orientation and form. Academic Press New York ####. [#] P. Jolicoeur. The time to name disoriented natural objects. Memory & Cognition ##:###–### ####. [##] M. J. Tarr P. Williams W. G. Hayward and I. Gauthier. Three-dimensional object recognition is viewpoint dependent. Nature Neuroscience #(#):###–### ####. [##] I. Rock J. DiVita and R. Barbeito. The effect on form perception of change of orientation in the third dimension. Journal of Experimental Psychology: Human Perception and Perfor- mance #:###–### ####. [##] S. E. Palmer. What makes triangles point: Local and global effects in conﬁgurations of am- biguous triangles. Cognitive Psychology ##:###–### ####. [##] S. E. Palmer. The role of symmetry in shape perception. Acta Psychologica ##:##–## ####. [##] F. Attneave. Triangles as ambiguous ﬁgures. American Journal of Psychology ##:###–### ####. [##] S. E. Palmer and N. M. Bucher. Conﬁgural effects in perceived pointing of ambiguous trian- gles. Journal of Experimental Psychology: Human Perception and Performance #(#):##–### ####. [##] J. Pitman. Combinatorial Stochastic Processes. ####. Notes for Saint Flour Summer School. [##] R. M. Neal. Markov chain sampling methods for Dirichlet process mixture models. Journal of Computational and Graphical Statistics #:###–### ####. [##] S. E. Palmer. Vision Science. MIT Press Cambridge MA ####. [##] E. Sudderth and M. I. Jordan. Shared segmentation of natural scenes using dependent Pitman- Yor processes. In D. Koller D. Schuurmans Y. Bengio and L. Bottou editors Advances in Neural Information Processing Systems ## pages ####–####. ####. [##] J. L. Austerweil and T. L. Grifﬁths. Learning invariant features using the transformed Indian buffet process. In J. Lafferty C. K. I. Williams J. Shawe-Taylor R.S. Zemel and A. Culotta editors Advances in Neural Information Processing Systems ## pages ##–##. ####. #\n",
            "response:  The object people perceive in an image can depend on its orientation relative to the scene it is in (its reference frame). For example the images of the symbols $epsilon$ and $no+$ differ by a $##$ degree rotation. Although real scenes have multiple transformations and reference frames psychologists have focused on scenes with only one reference frame. We propose an ideal observer model based on nonparametric Bayesian statistics for inferring the number of reference frames in a scene and their parameters.\n",
            "summarize: Supervised Dictionary Learning Julien Mairal INRIA-Willow project Francis Bach INRIA-Willow project julien.mairal@inria.fr francis.bach@inria.fr Jean Ponce Ecole Normale Sup´erieure jean.ponce@ens.fr Guillermo Sapiro University of Minnesota Andrew Zisserman University of Oxford guille@ece.umn.edu az@robots.ox.ac.uk Abstract It is now well established that sparse signal models are well suited for restora- tion tasks and can be effectively learned from audio image and video data. Re- cent research has been aimed at learning discriminative sparse models instead of purely reconstructive ones. This paper proposes a new step in that direction with a novel sparse representation for signals belonging to different classes in terms of a shared dictionary and discriminative class models. The linear version of the pro- posed model admits a simple probabilistic interpretation while its most general variant admits an interpretation in terms of kernels. An optimization framework for learning all the components of the proposed model is presented along with experimental results on standard handwritten digit and texture classiﬁcation tasks. # Introduction Sparse and overcomplete image models were ﬁrst introduced in [#] for modeling the spatial recep- tive ﬁelds of simple cells in the human visual system. The linear decomposition of a signal using a few atoms of a learned dictionary instead of predeﬁned ones–such as wavelets–has recently led to state-of-the-art results for numerous low-level image processing tasks such as denoising [#] show- ing that sparse models are well adapted to natural images. Unlike principal component analysis decompositions these models are in general overcomplete with a number of basis elements greater than the dimension of the data. Recent research has shown that sparsity helps to capture higher-order correlation in data. In [# #] sparse decompositions are used with predeﬁned dictionaries for face and signal recognition. In [#] dictionaries are learned for a reconstruction task and the correspond- ing sparse models are used as features in an SVM. In [#] a discriminative method is introduced for various classiﬁcation tasks learning one dictionary per class; the classiﬁcation process itself is based on the corresponding reconstruction error and does not exploit the actual decomposition co- efﬁcients. In [#] a generative model for documents is learned at the same time as the parameters of a deep network structure. In [#] multi-task learning is performed by learning features and tasks are selected using a sparsity criterion. The framework we present in this paper extends these approaches by learning simultaneously a single shared dictionary as well as models for different signal classes in a mixed generative and discriminative formulation (see also [#] where a different discriminative term is added to the classical reconstructive one). Similar joint generative/discriminative frame- works have started to appear in probabilistic approaches to learning e.g. [## ## ## ## ##] and in neural networks [##] but not to the best of our knowledge in the sparse dictionary learning framework. Section # presents a formulation for learning a dictionary tuned for a classiﬁcation task which we call supervised dictionary learning and Section # its interpretation in term of probabil- ity and kernel frameworks. The optimization procedure is detailed in Section # and experimental results are presented in Section #. # Supervised dictionary learning We present in this section the core of the proposed model. In classical sparse coding tasks one con- siders a signal x in Rn and a ﬁxed dictionary D = [d# . . . dk] in Rn×k (allowing k > n making the dictionary overcomplete). In this setting sparse coding with an ℓ# regularization# amounts to computing R⋆(x D) = min α∈Rk ||x − Dα||# # + λ#||α||#. (#) It is well known in the statistics optimization and compressed sensing communities that the ℓ# penalty yields a sparse solution very few non-zero coefﬁcients in α although there is no explicit analytic link between the value of λ# and the effective sparsity that this model yields. Other sparsity penalties using the ℓ# regularization# can be used as well. Since it uses a proper norm the ℓ# formulation of sparse coding is a convex problem which makes the optimization tractable with algorithms such as those introduced in [## ##] and has proven in practice to be more stable than its ℓ# counterpart in the sense that the resulting decompositions are less sensitive to small perturbations of the input signal x. Note that sparse coding with an ℓ# penalty is an NP-hard problem and is often approximated using greedy algorithms. In this paper we consider a setting where the signal may belong to any of p different classes. We ﬁrst consider the case of p = # classes and later discuss the multiclass extension. We consider a training set of m labeled signals (xi)m i=#. Our goal is to learn jointly a single dictionary D adapted to the classiﬁcation task and a function f which should be positive for any signal in class +# and negative otherwise. We consider in this paper two different models to use the sparse code α for the classiﬁcation task: (i) linear in α: f (x α θ) = wT α + b where θ = {w ∈ Rk b ∈ R} parametrizes the model. (ii) bilinear in x and α: f (x α θ) = xT Wα + b where θ = {W ∈ Rn×k b ∈ R}. In this case the model is bilinear and f acts on both x and its sparse code α. i=# in Rn associated with binary labels (yi ∈ {−# +#})m The number of parameters in (ii) is greater than in (i) which allows for richer models. Note that one can interpret W as a linear ﬁlter encoding the input signal x into a model for the coefﬁcients α which has a role similar to the encoder in [##] but for a discriminative task. A classical approach to obtain α for (i) or (ii) is to ﬁrst adapt D to the data solving m ||xi − Dαi||# # + λ#||αi||# (#) Note also that since the reconstruction errors ||xi − Dαi||# # are invariant to scaling simultaneously D by a scalar and αi by its inverse we need to constrain the ℓ# norm of the columns of D. Such a constraint is classical in sparse coding [#]. This reconstructive approach (dubbed REC in this paper) provides sparse codes αi for each signal xi which can be used a posteriori in a regular classiﬁer such as logistic regression which would require to solve min D α Xi=# min θ m Xi=# C(cid:#)yif (xi αi θ)(cid:#) + λ#||θ||# # where C is the logistic loss function (C(x) = log(# + e−x)) which enjoys properties similar to that of the hinge loss from the SVM literature while being differentiable and λ# is a regularization parameter which prevents overﬁtting. This is the approach chosen in [#] (with SVMs). However our goal is to learn jointly D and the model parameters θ. To that effect we propose the formulation where λ# controls the importance of the reconstruction term and the loss for a pair (xi yi) is C(cid:#)yif (xi αi θ)(cid:#) + λ#||xi − Dαi||# # + λ#||αi||#(cid:##) + λ#||θ||# # min D θ α(cid:##) m Xi=# S ⋆(xi D θ yi) = min α S(α xi D θ yi) where S(α xi D θ yi) = C(cid:#)yif (xi αi θ)(cid:#) + λ#||xi − Dαi||# In this setting the classiﬁcation procedure of a new signal x with an unknown label y given a learned dictionary D and parameters θ involves supervised sparse coding: # + λ#||αi||#. min y∈{−#;+#} S ⋆(x D θ y) (#) The learning procedure of Eq. (#) minimizes the sum of the costs for the pairs (xi yi)m i=# and cor- responds to a generative model. We will refer later to this model as SDL-G (supervised dictionary #The ℓ# norm of a vector x of size n is deﬁned as ||x||# = Pn #The ℓ# pseudo-norm of a vector x is the number of nonzeros coefﬁcients of x. Note that it is not a norm. i=# |x[i]|. (#) (#) (#) D i = # . . . m αi w xi yi Figure #: Graphical model for the proposed generative/discriminative learning framework. learning generative). Note the explicit incorporation of the reconstructive and discriminative com- ponent into sparse coding in addition to the classical reconstructive term (see [#] for a different classiﬁcation component). However since the classiﬁcation procedure from Eq. (#) compares the different costs S ⋆(x D θ y) of a given signal for each class y = −# +# a more discriminative approach is to not only make the costs S ⋆(xi D θ yi) small as in (#) but also make the value of S ⋆(xi D θ −yi) greater than S ⋆(xi D θ yi) which is the purpose of the logistic loss function C. This leads to: min D θ (cid:##) m Xi=# C(S ⋆(xi D θ −yi) − S ⋆(xi D θ yi))(cid:##) + λ#||θ||# #. As detailed below this problem is more difﬁcult to solve than (#) and therefore we adopt instead a mixed formulation between the minimization of the generative Eq. (#) and its discriminative version (#) (see also [##])—that is (#) (#) m Xi=# (cid:##) µC(S ⋆(xi D θ −yi) − S ⋆(xi D θ yi)) + (# − µ)S ⋆(xi D θ yi)(cid:##) + λ#||θ||# # where µ controls the trade-off between the reconstruction from Eq. (#) and the discrimination from Eq. (#). This is the proposed generative/discriminative model for sparse signal representation and classiﬁcation from learned dictionary D and model θ. We will refer to this mixed model as SDL-D (supervised dictionary learning discriminative). Note also that again we constrain the norm of the columns of D to be less than or equal to one. cost functions Ci(x# . xp) = log(Pp All of these formulations admit a straightforward multiclass extension using softmax discriminative j=# exj −xi) which are multiclass versions of the logistic function and learning one model θi per class. Other possible approaches such as one-vs-all or one-vs-one are of course possible and the question of choosing the best approach among these possibilities is still open. Compared with earlier work using one dictionary per class [#] our model has the advantage of letting multiple classes share some features and uses the coefﬁcients α of the sparse representations as part of the classiﬁcation procedure thereby following the works from [# # #] but with learned representations optimized for the classiﬁcation task similar to [# ##]. Before presenting the optimization procedure we provide below two interpretations of the linear and bilinear versions of our formulation in terms of a probabilistic graphical model and a kernel. # Interpreting the model #.# A probabilistic interpretation of the linear model Let us ﬁrst construct a graphical model which gives a probabilistic interpretation to the training and classiﬁcation criteria given above when using a linear model with zero bias (no constant term) on the coefﬁcients—that is f (x α θ) = wT α. It consists of the following components (Figure #): # and a constraint on the columns of D–that is ||dj||# • The matrices D and the vector w are parameters of the problem with a Gaussian prior on w p(w) ∝ e−λ#||w||# # = # for all j. All the dj ’s are considered independent of each other. • The coefﬁcients αi are latent variables with a Laplace prior p(αi) ∝ e−λ#||αi||# . • The signals xi are generated according to a Gaussian probability distribution conditioned on D and αi p(xi|αi D) ∝ e−λ#||xi−Dαi||# # . All the xi’s are considered independent from each other. • The labels yi are generated according to a probability distribution conditioned on w and αi and given by p(yi = ǫ|αi W) = e−ǫwT αi/(cid:#)e−WT αi + eWT αi(cid:#). Given D and w all the triplets (αi xi yi) are independent. What is commonly called “generative training” in the literature (e.g. [## ##]) amounts to ﬁnding the maximum likelihood estimates for D and w according to the joint distribution p({xi yi}m i=# D W) where the xi’s and the yi’s are the training signals and their labels respec- tively. It can easily be shown (details omitted due to space limitations) that there is an equiva- lence between this generative training and our formulation in Eq. (#) under MAP approximations.# Although joint generative modeling of x and y through a shared representation has shown great promise [##] we show in this paper that a more discriminative approach is desirable. “Discrim- inative training” is slightly different and amounts to maximizing p({yi}m i=#) with respect to D and w: Given some input data one ﬁnds the best parameters that will predict the labels of the data. The same kind of MAP approximation relates this discriminative training formulation to the discriminative model of Eq. (#) (again details omitted due to space limitations). The mixed approach from Eq. (#) is a classical trade-off between generative and discriminative (e.g. [## ##]) where generative components are often added to discriminative frameworks to add robustness e.g. to noise and occlusions (see examples of this for the model in [#]). i=# D w|{xi}m #.# A kernel interpretation of the bilinear model Our bilinear model with f (x α θ) = xT Wα + b does not admit a straightforward probabilistic interpretation. On the other hand it can easily be interpreted in terms of kernels: Given two signals x# and x# with coefﬁcients α# and α# using the kernel K(x# x#) = αT x# in a logistic # regression classiﬁer amounts to ﬁnding a decision function of the same form as f . It is a product of two linear kernels one on the α’s and one on the input signals x. Interestingly Raina et al. [#] learn a dictionary adapted to reconstruction on a training set then train an SVM a posteriori on the decomposition coefﬁcients α. They derive and use a Fisher kernel which can be written as K ′(x# x#) = αT r# in this setting where the r’s are the residuals of the decompositions. In # simple experiments which are not reported in this paper we have observed that the kernel K where the signals x replace the residuals r generally yields a level of performance similar to K ′ and often actually does better when the number of training samples is small or the data are noisy. α#xT # α#rT # # Optimization procedure Classical dictionary learning techniques (e.g. [# # ##]) address the problem of learning a recon- structive dictionary D in Rn×k well adapted to a training set which is presented in Eq. (#). It can be seen as an optimization problem with respect to the dictionary D and the coefﬁcients α. Altough not jointly convex in (D α) it is convex with respect to each unknown when the other one is ﬁxed. This is why block coordinate descent on D and α performs reasonably well [# # ##] although not necessarily providing the global optimum. Training when µ = # (generative case) i.e. from Eq. (#) enjoys similar properties and can be addressed with the same optimization procedure. Equation (#) can be rewritten as: min D θ α(cid:##) m Xi=# S(xj αj D θ yi)(cid:##) + λ#||θ||# # s.t. ∀ j = # . . . k ||dj||# ≤ #. (#) Block coordinate descent consists therefore of iterating between supervised sparse coding where D and θ are ﬁxed and one optimizes with respect to the α’s and supervised dictionary update where the coefﬁcients αi’s are ﬁxed but D and θ are updated. Details on how to solve these two problems are given in sections #.# and #.#. The discriminative version SDL-D from Eq. (#) is more problematic. To reach a local minimum for this difﬁcult non-convex optimization problem we have chosen a continuation method starting from the generative case and ending with the discriminative one as in [#]. The algorithm is presented in Figure # and details on the hyperparameters’ settings are given in Section #. #.# Supervised sparse coding The supervised sparse coding problem from Eq. (#) (D and θ are ﬁxed in this step) amounts to minimizing a convex function under an ℓ# penalty. The ﬁxed-point continuation method (FPC) from #We are also investigating how to properly estimate D by marginalizing over α instead of maximizing with respect to α. Input: n (signal dimensions); (xi yi)m (parameters); # ≤ µ# ≤ µ# ≤ . . . ≤ µm ≤ # (increasing sequence). Output: D ∈ Rn×k (dictionary); θ (parameters). Initialization: Set D to a random Gaussian matrix with normalized columns. Set θ to zero. Loop: For µ = µ# . . . µm i=# (training signals); k (size of the dictionary); λ# λ# λ# Loop: Repeat until convergence (or a ﬁxed number of iterations) • Supervised sparse coding: Solve for all i = # . . . m (cid:##) α⋆ α⋆ i − = arg minα S(α xi D θ −#) i + = arg minα S(α xi D θ +#) . (##) • Dictionary and parameters update: Solve min D θ (cid:##) m Xi=# µC(cid:#)(S(α⋆ i − xi D θ −yi) − S(α⋆ i + xj D θ yi))(cid:#)+ (# − µ)S(α⋆ i yi xi D θ yi) + λ#||θ||# #(cid:##) s.t. ∀j ||dj||# ≤ #. (##) Figure #: SDL: Supervised dictionary learning algorithm. [##] achieves good results in terms of convergence speed for this class of problems. For our speciﬁc problem denoting by g the convex function to minimize this method only requires ∇g and a bound on the spectral norm of its Hessian Hg. Since the we have chosen models g which are both linear in α there exists for each supervised sparse coding problem a vector a in Rk and a scalar c in R such that ( g(α) = C(aT α + c) + λ#||x − Dα||# # ∇g(α) = ∇C(aT α + c)a − #λ#DT (x − Dα) and it can be shown that if ||U||# denotes the spectral norm of a matrix U (which is the magnitude of its largest eigenvalue) then we can obtain the following bound ||Hg(α)||# ≤ |HC(aT α+c)|||a||# # + #λ#||DT D||#. #.# Dictionary update The problem of updating D and θ in Eq. (##) is not convex in general (except when µ is close to #) but a local minimum can be obtained using projected gradient descent (as in the general literature on dictionary learning this local minimum has experimentally been found to be good enough in terms of classiﬁcation performance). ). Denoting E(D θ) the function we want to minimize in Eq. (##) we just need the partial derivatives of E with respect to D and the parameters θ. When considering the linear model for the α’s f (x α θ) = wT α + b and θ = {w ∈ Rk b ∈ R} we obtain ωi z(xi − Dα⋆ i z)α⋆T i z(cid:#) ωi zz∇C(wT α⋆ i z + b)α⋆ i z (##) = −#λ#(cid:#) m m Xi=# Xz={−# +#} Xi=# Xz={−# +#} m ∂E ∂D ∂E ∂w ∂E ∂b   = = Xi=# Xz={−# +#} ωi zz∇C(wT α⋆ i z + b) where ωi z = −µz∇C(cid:#)S(α⋆ Partial derivatives when using our model with multiple classes or with the bilinear models f (x α θ) = xT Wα + b are not presented in this paper due to space limitations. i + xi D θ yi)(cid:#) + (# − µ)#z=yi. i − xi D θ −yi) − S(α⋆ # Experimental validation We compare in this section the reconstructive approach dubbed REC which consists of learning a reconstructive dictionary D as in [#] and then learning the parameters θ a posteriori; SDL with generative training (dubbed SDL-G); and SDL with discriminative learning (dubbed SDL-D). We also compare the performance of the linear (L) and bilinear (BL) models. REC L SDL-G L SDL-D L REC BL k-NN ℓ# SVM-Gauss MNIST USPS #.## #.## #.## #.## #.## #.## #.## #.## #.# #.# #.# #.# Table #: Error rates on the MNIST and USPS datasets in percents for the REC SDL-G L and SDL-D L approaches compared with k-nearest neighbor and SVM with a Gaussian kernel [##]. Before presenting experimental results let us brieﬂy discuss the choice of the ﬁve model parameters λ# λ# λ# µ and k (size of the dictionary). Tuning all of them using cross-validation is cumbersome and unnecessary since some simple choices can be made some of which can be made sequentially. We deﬁne ﬁrst the sparsity parameter κ = λ# which dictates how sparse the decompositions are. λ# When the input data points have unit ℓ# norm choosing κ = #.## was empirically found to be a good choice. For reconstructive tasks a typical value often used in the literature (e.g. [##]) is k = ### for m = ### ### signals. Nevertheless for discriminative tasks increasing the number of parameters is likely to lead to overﬁtting and smaller values like k = ## or k = ## are preferred. The scalar λ# is a regularization parameter for preventing the model to overﬁt the input data. As in logistic regression or support vector machines this parameter is crucial when the number of training samples is small. Performing cross validation with the fast method REC quickly provides a reasonable value for this parameter which can be used afterward for SDL-G or SDL-D. S ⋆ one can compute a scale factor γ⋆ such that γ⋆ = arg minγPm Once κ k and λ# are chosen let us see how to ﬁnd λ# which plays the important role of controlling the trade-off between reconstruction and discrimination. First we perform cross-validation for a few iterations with µ = # to ﬁnd a good value for SDL-G. Then a scale factor making the costs S ⋆ dis- criminative for µ > # can be chosen during the optimization process: Given a set of computed costs i=# C({γ(S ⋆(xi D θ −yi) − S ⋆(xi D θ yi)). We therefore propose the following strategy which has proven to be effective in our experiments: Starting from small values for λ# and a ﬁxed κ we apply the algorithm in Figure # and after a supervised sparse coding step we compute the best scale factor γ⋆ and replace λ# and λ# by γ⋆λ# and γλ#. Typically applying this procedure during the ﬁrst ## iterations has proven to lead to reasonable values for these parameters. Since we are following a continuation path from µ = # to µ = # the optimal value of µ is found along the path by measuring the classiﬁcation performance of the model on a validation set during the optimization. #.# Digits recognition In this section we present experiments on the popular MNIST [##] and USPS handwritten digit datasets. MNIST is composed of ## ### ## × ## images ## ### for training ## ### for testing each of them containing one handwritten digit. USPS is composed of #### training images and #### test images of size ## × ##. As is often done in classiﬁcation we have chosen to learn pairwise binary classiﬁers one for each pair of digits. Although our framework extends to a multiclass formulation pairwise binary classiﬁers have resulted in slightly better performance in practice. Five-fold cross validation is performed to ﬁnd the best pair (k κ). The tested values for k are {## ## ## ## ##} and for κ {#.## #.## #.## #.## #.##}. We keep the three best pairs of parameters and use them to train three sets of pairwise classiﬁers. For a given image x the test procedure consists of selecting the class which receives the most votes from the pairwise classiﬁers. All the other parameters are obtained using the procedure explained above. Classiﬁcation results are presented on Table # using the linear model. We see that for the linear model L SDL-D L performs the best. REC BL offers a larger feature space and performs better than REC L but we have observed no gain by using SDL-G BL or SDL-D BL instead of REC BL (this results are not reported in this table). Since the linear model is already performing very well one side effect of using BL instead of L is to increase the number of free parameters and thus to cause overﬁtting. Note that our method is competitive since the best error rates published on these datasets (without any modiﬁcation of the training set) are #.##% [##] for MNIST and #.#% [##] for USPS using methods tailored to these tasks whereas ours is generic and has not been tuned for the handwritten digit classiﬁcation domain. The purpose of our second experiment is not to measure the raw performance of our algorithm but to answer the question “are the obtained dictionaries D discriminative per se?”. To do so we have trained on the USPS dataset ## binary classiﬁers one per digit in a one vs all fashion on the training set. For a given value of µ we obtain ## dictionaries D and ## sets of parameters θ learned by the SDL-D L model. To evaluate the discriminative power of the dictionaries D we discard the learned parameters θ and use the dictionaries as if they had been learned in a reconstructive REC model: For each dictionary #.# #.# #.# #.# #.# # # #.# #.# #.# #.# #.# (a) REC MNIST (b) SDL-D MNIST Figure #: On the left a reconstructive and a discriminative dictionary. On the right average error rate in percents obtained by our dictionaries learned in a discriminative framework (SDL-D L) for various values of µ when used at test time in a reconstructive framework (REC-L). m ### # ### # ### # ### ## ### ## ### REC L ##.## ##.# ##.## ##.## ##.## ##.## SDL-G L SDL-D L REC BL SDL-G BL ##.## ##.# ##.# ##.## ##.## ##.# ##.## ## ##.# ##.## ##.## ##.# ##.## ##.# ##.## ##.## ##.# ##.## ##.## ##.# ##.## ##.## ##.## ##.## SDL-D BL Gain #% #% #% #% ##% ##% ##.## ##.# ##.## ##.## ##.## ##.## Table #: Error rates for the texture classiﬁcation task using various methods and sizes m of the training set. The last column indicates the gain between the error rate of REC BL and SDL-D BL. we decompose each image from the training set by solving the simple sparse reconstruction problem from Eq. (#) instead of using supervised sparse coding. This provides us with some coefﬁcients α which we use as features in a linear SVM. Repeating the sparse decomposition procedure on the test set permits us to evaluate the performance of these learned linear SVMs. We plot the average error rate of these classiﬁers on Figure # for each value of µ. We see that using the dictionaries obtained with discrimative learning (µ > # SDL-D L) dramatically improves the performance of the basic linear classiﬁer learned a posteriori on the α’s showing that our learned dictionaries are discriminative per se. Figure # also shows a dictionary adapted to the reconstruction of the MNIST dataset and a discriminative one adapted to “# vs all”. #.# Texture classiﬁcation In the digit recognition task our bilinear framework did not perform better than the linear one L. We believe that one of the main reasons is due to the simplicity of the task where a linear model is rich enough. The purpose of our next experiment is to answer the question “When is BL worth using?”. We have chosen to consider two texture images from the Brodatz dataset presented in Figure # and to build two classes composed of ## × ## patches taken from these two textures. We have compared the classiﬁcation performance of all our methods including BL for a dictionary of size k = ## and κ = #.##. The training set was composed of patches from the left half of each texture and the test sets of patches from the right half so that there is no overlap between them in the training and test set. Error rates are reported in Table # for varying sizes of the training set. This experiment shows that in some cases the linear model performs very poorly where BL does better. Discrimination helps especially when the size of the training set is large. Note that we did not perform any cross- validation to optimize the parameters k and κ for this experiment. Dictionaries obtained with REC and SDL-D BL are presented in Figure #. Note that though they are visually quite similar they lead to very different performances. # Conclusion we have introduced in this paper a discriminative approach to supervised dictionary learning that effectively exploits the corresponding sparse signal decompositions in image classiﬁcation tasks and have proposed an effective method for learning a shared dictionary and multiple (linear or bilinear) models. Future work will be devoted to adapting the proposed framework to shift-invariant models that are standard in image processing tasks but not readily generalized to the sparse dictionary learning setting. We are also investigating extensions to unsupervised and semi-supervised learning and applications to natural image classiﬁcation. (a) Texture # (b) Texture # (c) REC (d) SDL-D BL Figure #: Left: test textures. Right: reconstructive and discriminative dictionaries Acknowledgments This paper was supported in part by ANR under grant MGA. Guillermo Sapiro would like to thank Fernando Rodriguez for insights into the learning of discriminatory sparsity patterns. His work is partially supported by NSF NGA ONR ARO and DARPA. References [#] B. A. Olshausen and D. J. Field. Sparse coding with an overcomplete basis set: A strategy employed by v#? Vision Research ## ####. [#] M. Elad and M. Aharon. Image denoising via sparse and redundant representations over learned dictio- naries. IEEE Trans. IP ##(##) ####. [#] K. Huang and S. Aviyente. Sparse representation for signal classiﬁcation. In NIPS ####. [#] J. Wright A. Y. Yang A. Ganesh S. Sastry and Y. Ma. Robust face recognition via sparse representation. In PAMI ####. to appear. [#] R. Raina A. Battle H. Lee B. Packer and A. Y. Ng. Self-taught learning: transfer learning from unla- beled data. In ICML ####. [#] J. Mairal F. Bach J. Ponce G. Sapiro and A. Zisserman. Learning discriminative dictionaries for local image analysis. In CVPR ####. [#] M. Ranzato and M. Szummer. Semi-supervised learning of compact document representations with deep networks. In ICML ####. [#] A. Argyriou and T. Evgeniou and M. Pontil Multi-Task Feature Learning. In NIPS ####. [#] F. Rodriguez and G. Sapiro. Sparse representations for image classiﬁcation: Learning discriminative and reconstructive non-parametric dictionaries. IMA Preprint #### ####. [##] D. Blei and J. McAuliffe. Supervised topic models. In NIPS ####. [##] A. Holub and P. Perona. A discriminative framework for modeling object classes. In CVPR ####. [##] J.A. Lasserre C.M. Bishop and T.P. Minka. Principled hybrids of generative and discriminative models. In CVPR ####. [##] R. Raina Y. Shen A. Y. Ng and A. McCallum. Classiﬁcation with hybrid generative/discriminative models. In NIPS ####. [##] R. R. Salakhutdinov and G. E. Hinton. Learning a non-linear embedding by preserving class neighbour- hood structure. In AI and Statistics ####. [##] H. Larochelle and Y. Bengio. Classiﬁcation using discriminative restricted boltzmann machines. in ICML ####. [##] B. Efron T. Hastie I. Johnstone and R. Tibshirani. Least angle regression. Ann. Stat. ##(#) ####. [##] E. T. Hale W. Yin and Y. Zhang. A ﬁxed-point continuation method for l#-regularized minimization with applications to compressed sensing. CAAM Tech Report TR##-## ####. [##] M. Ranzato C. Poultney S. Chopra and Y. LeCun. Efﬁcient learning of sparse representations with an energy-based model. In NIPS ####. [##] M. Aharon M. Elad and A. M. Bruckstein. The K-SVD: An algorithm for designing of overcomplete dictionaries for sparse representations. IEEE Trans. SP ##(##) ####. [##] Y. LeCun L. Bottou Y. Bengio and P. Haffner. Gradient-based learning applied to document recognition. Proc. of the IEEE ##(##) ####. [##] B. Haasdonk and D. Keysers. Tangent distant kernels for support vector machines. In ICPR ####.\n",
            "response:  It is now well established that sparse signal models are well suited for reconstruction tasks and can be effectively learned from audio image and video data. Research has been aimed at learning discriminative sparsen models instead of purely reconstructive ones. This paper proposes a new step in that direction with a novel sparsing representation for signals belonging to different classes in terms of a shared dictionary and discriminative class models.\n",
            "summarize: Learning Structured Sparsity in Deep Neural Networks Wei Wen University of Pittsburgh wew##@pitt.edu Chunpeng Wu University of Pittsburgh chw###@pitt.edu Yandan Wang University of Pittsburgh yaw##@pitt.edu Yiran Chen University of Pittsburgh yic##@pitt.edu Hai Li University of Pittsburgh hal##@pitt.edu Abstract High demand for computation resources severely hinders deployment of large-scale Deep Neural Networks (DNN) in resource constrained devices. In this work we propose a Structured Sparsity Learning (SSL) method to regularize the structures (i.e. ﬁlters channels ﬁlter shapes and layer depth) of DNNs. SSL can: (#) learn a compact structure from a bigger DNN to reduce computation cost; (#) obtain a hardware-friendly structured sparsity of DNN to efﬁciently accelerate the DNN’s evaluation. Experimental results show that SSL achieves on average #.#× and #.#× speedups of convolutional layer computation of AlexNet against CPU and GPU respectively with off-the-shelf libraries. These speedups are about twice speedups of non-structured sparsity; (#) regularize the DNN structure to improve classiﬁcation accuracy. The results show that for CIFAR-## regularization on layer depth reduces a ##-layer Deep Residual Network (ResNet) to ## layers while improves the accuracy from ##.##% to ##.##% which is still higher than that of original ResNet with ## layers. For AlexNet SSL reduces the error by ∼ #%. # Introduction Deep neural networks (DNN) especially deep Convolutional Neural Networks (CNN) made re- markable success in visual tasks [#][#][#][#][#] by leveraging large-scale networks learning from a huge volume of data. Deployment of such big models however is computation-intensive. To reduce computation many studies are performed to compress the scale of DNN including sparsity regu- larization [#] connection pruning [#][#] and low rank approximation [#][##][##][##][##]. Sparsity regularization and connection pruning however often produce non-structured random connectivity and thus irregular memory access that adversely impacts practical acceleration in hardware platforms. Figure # depicts practical layer-wise speedup of AlexNet which is non-structurally sparsiﬁed by (cid:##)#-norm. Compared to original model the accuracy loss of the sparsiﬁed model is controlled within #%. Because of the poor data locality associated with the scattered weight distribution the achieved speedups are either very limited or negative even the actual sparsity is high say >##%. We deﬁne sparsity as the ratio of zeros in this paper. In recently proposed low rank approximation approaches the DNN is trained ﬁrst and then each trained weight tensor is decomposed and approximated by a product of smaller factors. Finally ﬁne-tuning is performed to restore the model accuracy. Low rank approximation is able to achieve practical speedups because it coordinates model parameters in dense matrixes and avoids the locality problem of non-structured sparsity regularization. However low rank approximation can only obtain the compact structure within each layer and the structures of the layers are ﬁxed during ﬁne-tuning such that costly reiterations of decomposing and ﬁne-tuning are required to ﬁnd an optimal weight approximation for performance speedup and accuracy retaining. ##th Conference on Neural Information Processing Systems (NIPS ####) Barcelona Spain. Figure #: Evaluation speedups of AlexNet on GPU platforms and the sparsity. conv# refers to convolutional layer # and so forth. Baseline is proﬁled by GEMM of cuBLAS. The sparse matrixes are stored in the format of Compressed Sparse Row (CSR) and accelerated by cuSPARSE. Inspired by the facts that (#) there is redundancy across ﬁlters and channels [##]; (#) shapes of ﬁlters are usually ﬁxed as cuboid but enabling arbitrary shapes can potentially eliminate unnecessary computation imposed by this ﬁxation; and (#) depth of the network is critical for classiﬁcation but deeper layers cannot always guarantee a lower error because of the exploding gradients and degradation problem [#] we propose Structured Sparsity Learning (SSL) method to directly learn a compressed structure of deep CNNs by group Lasso regularization during the training. SSL is a generic regularization to adaptively adjust multiple structures in DNN including structures of ﬁlters channels ﬁlter shapes within each layer and structure of depth beyond the layers. SSL combines structure regularization (on DNN for classiﬁcation accuracy) with locality optimization (on memory access for computation efﬁciency) offering not only well-regularized big models with improved accuracy but greatly accelerated computation (e.g. #.#× on CPU and #.#× on GPU for AlexNet). Our source code can be found at # Related works Connection pruning and weight sparsifying. Han et al. [#][#] reduced parameters of AlexNet and VGG-## using connection pruning. Since most reduction is achieved on fully-connected layers no practical speedups of convolutional layers are observed for the similar issue shown in Figure #. However convolution is more costly and many new DNNs use fewer fully-connected layers e.g. only #.##% parameters of ResNet-### [#] are from fully-connected layers compression and acceleration on convolutional layers become essential. Liu et al. [#] achieved >##% sparsity of convolutional layers in AlexNet with #% accuracy loss and bypassed the issue of Figure # by hardcoding the sparse weights into program. In this work we also focus on convolutional layers. Compared to the previous techniques our method coordinates sparse weights in adjacent memory space and achieve higher speedups. Note that hardware and program optimizations based on our method can further boost the system performance which is not covered in this paper due to space limit. Low rank approximation. Denil et al. [#] predicted ##% parameters in a DNN by exploiting the redundancy across ﬁlters and channels. Inspired by it Jaderberg et al. [##] achieved #.#× speedup on CPUs for scene text character recognition and Denton et al. [##] achieved #× speedups for the ﬁrst two layers in a larger DNN. Both of the works used Low Rank Approximation (LRA) with ∼#% accuracy drop. [##][##] improved and extended LRA to larger DNNs. However the network structure compressed by LRA is ﬁxed; reiterations of decomposing training/ﬁne-tuning and cross-validating are still needed to ﬁnd an optimal structure for accuracy and speed trade-off. As the number of hyper-parameters in LRA method increases linearly with the layer depth [##][##] the search space increases linearly or even exponentially. Comparing to LRA our contributions are: (#) SSL can dynamically optimize the compactness of DNNs with only one hyper-parameter and no reiterations; (#) besides the redundancy within the layers SSL also exploits the necessity of deep layers and reduce them; (#) DNN ﬁlters regularized by SSL have lower rank approximation so it can work together with LRA for more efﬁcient model compression. Model structure learning. Group Lasso [##] is an efﬁcient regularization to learn sparse structures. Liu et al. [#] utilized group Lasso to constrain the structure scale of LRA. To adapt DNN structure to different databases Feng et al. [##] learned the appropriate number of ﬁlters in DNN. Different from prior arts we apply group Lasso to regularize multiple DNN structures (ﬁlters channels ﬁlter shapes and layer depth). A most related parallel work is Group-wise Brain Damage [##] which is a subset (i.e. learning ﬁlter shapes) of our work and further justiﬁes the effectiveness of our techniques. # # # # #.# # #.# conv# conv# conv# conv# conv# Quadro K### Tesla K##c GTX Titan Sparsity Speedup Sparsity Figure #: The proposed Structured Sparsity Learning (SSL) for DNNs. The weights in ﬁlters are split into multiple groups. Through group Lasso regularization a more compact DNN is obtained by removing some groups. The ﬁgure illustrates the ﬁlter-wise channel-wise shape-wise and depth-wise structured sparsity that are explored in the work. # Structured Sparsity Learning Method for DNNs We focus mainly on the Structured Sparsity Learning (SSL) on convolutional layers to regularize the structure of DNNs. We ﬁrst propose a generic method to regularize structures of DNN in Section #.# and then specify the method to structures of ﬁlters channels ﬁlter shapes and depth in Section #.#. Variants of formulations are also discussed from computational efﬁciency viewpoint in Section #.#. #.# Proposed structured sparsity learning for generic structures Suppose the weights of convolutional layers in a DNN form a sequence of #-D tensors W (l) ∈ RNl×Cl×Ml×Kl where Nl Cl Ml and Kl are the dimensions of the l-th (# ≤ l ≤ L) weight tensor along the axes of ﬁlter channel spatial height and spatial width respectively. L denotes the number of convolutional layers. Then the proposed generic optimization target of a DNN with structured sparsity regularization can be formulated as: E(W ) = ED(W ) + λ · R(W ) + λg · Rg . (#) (cid:##) W (l)(cid:##) L(cid:##) l=# w can be represented as Rg(w) =(cid:##)G Here W represents the collection of all weights in the DNN; ED(W ) is the loss on data; R(·) is non-structured regularization applying on every weight e.g. (cid:##)#-norm; and Rg(·) is the structured sparsity regularization on each layer. Because group Lasso can effectively zero out all weights in some groups [##][##] we adopt it in our SSL. The regularization of group Lasso on a set of weights g=# ||w(g)||g where w(g) is a group of partial weights in w and G is the total number of groups. Different groups may overlap. Here || · ||g is the group Lasso or ||w(g)||g = where |w(g)| is the number of weights in w(g). (cid:###)(cid:##)|w(g)| (cid:##)# w(g) i (cid:##) i=# #.# Structured sparsity learning for structures of ﬁlters channels ﬁlter shapes and depth In SSL the learned “structure” is decided by the way of splitting groups of w(g). We investigate and formulate the ﬁler-wise channel-wise shape-wise and depth-wise structured sparsity in Figure #. For simplicity the R(·) term of Eq. (#) is omitted in the following formulation expressions. Penalizing unimportant ﬁlers and channels. Suppose W (l) nl : : : is the nl-th ﬁlter and W (l) : cl : : is the cl-th channel of all ﬁlters in the l-th layer. The optimization target of learning the ﬁlter-wise and channel-wise structured sparsity can be deﬁned as  Nl(cid:##) L(cid:##) l=#  + λc · L(cid:##) l=#  Cl(cid:##)  . E(W ) = ED(W ) + λn · nl=#||W (l) nl : : :||g cl=#||W (l) : cl : :||g (#) As indicated in Eq. (#) our approach tends to remove less important ﬁlters and channels. Note that zeroing out a ﬁlter in the l-th layer results in a dummy zero output feature map which in turn makes a corresponding channel in the (l + #)-th layer useless. Hence we combine the ﬁlter-wise and channel-wise structured sparsity in the learning simultaneously. # shortcut depth-wise filter-wise channel-wise … shape-wise W(l)nl : : :(#)W(l): cl : :(#)W(l): cl ml kl(#)W(l)(#)#W(l)nl : : :(#)W(l): cl : :(#)W(l): cl ml kl(#)W(l)(#)#W(l)nl : : :(#)W(l): cl : :(#)W(l): cl ml kl(#)W(l)(#)#W(l)nl : : :(#)W(l): cl : :(#)W(l): cl ml kl(#)W(l)(#)# Learning arbitrary shapes of ﬁlers. As illustrated in Figure # W (l) : cl ml kl denotes the vector of all corresponding weights located at spatial position of (ml kl) in the #D ﬁlters across the cl-th channel. Thus we deﬁne W (l) : cl ml kl as the shape ﬁber related to learning arbitrary ﬁlter shape because a homogeneous non-cubic ﬁlter shape can be learned by zeroing out some shape ﬁbers. The optimization target of learning shapes of ﬁlers becomes: L(cid:##)  Cl(cid:##) Ml(cid:##) Kl(cid:##)  . E(W ) = ED(W ) + λs · l=# cl=# ml=# kl=# ||W (l) : cl ml kl||g (#) (cid:##)L Regularizing layer depth. We also explore the depth-wise sparsity to regularize the depth of DNNs in order to improve accuracy and reduce computation cost. The corresponding optimization target is l=# ||W (l)||g. Different from other discussed sparsiﬁcation techniques E(W ) = ED(W ) + λd · zeroing out all the ﬁlters in a layer will cut off the message propagation in the DNN so that the output neurons cannot perform any classiﬁcation. Inspired by the structure of highway networks [##] and deep residual networks [#] we propose to leverage the shortcuts across layers to solve this issue. As illustrated in Figure # even when SSL removes an entire unimportant layers feature maps will still be forwarded through the shortcut. #.# Structured sparsity learning for computationally efﬁcient structures All proposed schemes in section #.# can learn a compact DNN for computation cost reduction. Moreover some variants of the formulations of these schemes can directly learn structures that can be efﬁciently computed. #D-ﬁlter-wise sparsity for convolution. #D convolution in DNNs essentially is a composition of #D convolutions. To perform efﬁcient convolution we explored a ﬁne-grain variant of ﬁlter-wise sparsity namely #D-ﬁlter-wise sparsity to spatially enforce group Lasso on each #D ﬁlter of W (l) nl cl : :. The saved convolution is proportional to the percentage of the removed #D ﬁlters. The ﬁne-grain version of ﬁlter-wise sparsity can more efﬁciently reduce the computation associated with convolution: Because the distance of weights (in a smaller group) from the origin is shorter which makes group Lasso more easily to obtain a higher ratio of zero groups. Combination of ﬁlter-wise and shape-wise sparsity for GEMM. Convolutional computation in DNNs is commonly converted to modality of GEneral Matrix Multiplication (GEMM) by lowering weight tensors and feature tensors to matrices [##]. For example in Caffe [##] a #D ﬁlter W (l) nl : : : is reshaped to a row in the weight matrix where each column is the collection of weights W (l) : cl ml kl related to shape-wise sparsity. Combining ﬁlter-wise and shape-wise sparsity can directly reduce the dimension of weight matrix in GEMM by removing zero rows and columns. In this context we use row-wise and column-wise sparsity as the interchangeable terminology of ﬁlter-wise and shape-wise sparsity respectively. # Experiments We evaluate the effectiveness of our SSL using published models on three databases – MNIST CIFAR-## and ImageNet. Without explicit explanation SSL starts with the network whose weights are initialized by the baseline and speedups are measured in matrix-matrix multiplication by Caffe in a single-thread Intel Xeon E#-#### CPU. Hyper-parameters are selected by cross-validation. #.# LeNet and multilayer perceptron on MNIST In the experiment of MNIST we examine the effectiveness of SSL in two types of networks: LeNet [##] implemented by Caffe and a multilayer perceptron (MLP) network. Both networks were trained without data augmentation. LeNet: When applying SSL to LeNet we constrain the network with ﬁlter-wise and channel-wise sparsity in convolutional layers to penalize unimportant ﬁlters and channels. Table # summarizes the remained ﬁlters and channels ﬂoating-point operations (FLOP) and practical speedups. In the table LeNet # is the baseline and the others are the results after applying SSL in different strengths # Table #: Results after penalizing unimportant ﬁlters and channels in LeNet LeNet # Channel # § Speedup § FLOP § # (baseline) Filter # § Error #.#% ##—## #—## #.#% #.#% #—## §In the order of conv#—conv# # # #—## #—# #—# ###%—###% #.##×—#.##× ##%—#.#% #.##×—#.##× ##%—#.#% #.##×—#.##× LeNet # # (baseline) # # Channel # Table #: Results after learning ﬁlter shapes in LeNet Error #.#% #.#% #.#% Filter size § ##—### ##—## #—## #—## #—# #—# ###%—###% #.##×—#.##× #.#%—#.#% #.##×—#.##× #.#%—#.#% #.##×—##.##× Speedup FLOP § The sizes of ﬁlters after removing zero shape ﬁbers in the order of conv#—conv# of structured sparsity regularization. The results show that our method achieves the similar error (±#.#%) with much fewer ﬁlters and channels and saves signiﬁcant FLOP and computation time. To demonstrate the impact of SSL on the structures of ﬁlters we present all learned conv# ﬁlters in Figure #. It can be seen that most ﬁlters in LeNet # are entirely zeroed out except for ﬁve most important detectors of stroke patterns that are sufﬁcient for feature extraction. The accuracy of LeNet # (that further removes the weakest and redundant stroke detector) drops only #.#% from that of LeNet #. Compared to the random and blurry ﬁlter patterns in LeNet # which are resulted from the high freedom of parameter space the ﬁlters in LeNet # & # are regularized and converge to smoother and more natural patterns. This explains why our proposed SSL obtains the same-level accuracy but has much less ﬁlters. The smoothness of the ﬁlters are also observed in the deeper layers. The effectiveness of the shape-wise sparsity on LeNet is summarized in Table #. The baseline LeNet # has conv# ﬁlters with a regular # × # square (size = ##) while LeNet # reduces the dimension that can be constrained by a # × # rectangle (size = #). The #D shape of conv# ﬁlters in the baseline is also regularized to the #D shape in LeNet # within only one channel indicating that only one ﬁlter in conv# is needed. This fact signiﬁcantly saves FLOP and computation time. Figure #: Learned conv# ﬁlters in LeNet # (top) LeNet # (middle) and LeNet # (bottom) MLP: Besides convolutional layers our proposed SSL can be extended to learn the structure (i.e. the number of neurons) of fully-connected layers. We enforce the group Lasso regularization on all the input (or output) connections of each neuron. A neuron whose input connections are all zeroed out can degenerate to a bias neuron in the next layer; similarly a neuron can degenerate to a removable dummy neuron if all of its output connections are zeroed out. Figure #(a) summarizes the learned structure and FLOP of different MLP networks. The results show that SSL can not only remove hidden neurons but also discover the sparsity of images. For example Figure #(b) depicts the number of connections of each input neuron in MLP # where ##.##% of input neurons have zero connections and they concentrate at the boundary of the image. Such a distribution is consistent with our intuition: handwriting digits are usually written in the center and pixels close to the boundary contain little discriminative classiﬁcation information. #.# ConvNet and ResNet on CIFAR-## We implemented the ConvNet of [#] and deep residual networks (ResNet) [#] on CIFAR-##. When regularizing ﬁlters channels and ﬁlter shapes the results and observations of both networks are similar to that of the MNIST experiment. Moreover we simultaneously learn the ﬁlter-wise and shape-wise sparsity to reduce the dimension of weight matrix in GEMM by ConvNet. We also learn the depth-wise sparsity of ResNet to regularize the depth of the DNNs. # Figure #: (a) Results of learning the number of neurons in MLP. (b) the connection numbers of input neurons (i.e. pixels) in MLP # after SSL. (a) (b) Table #: Learning row-wise and column-wise sparsity of ConvNet on CIFAR-## ConvNet # # (baseline) Speedup § Row sparsity § Error #.##×–#.##×–#.##× ##.#% ##.#%–#%–#% ##.#% ##.#%–##.#%–#.#% #%–##.#%–##.#% #.##×–#.##×–#.##× ##.#% ##.#%–#%–#.#% #.##×–#.##×–#.##× # # Column sparsity § #%–#%–#% #%–##.#%–#.#% §in the order of conv#–conv#–conv# ConvNet: We use the network from Alex Krizhevsky et al. [#] as the baseline and implement it using Caffe. All the conﬁgurations remain the same as the original implementation except that we added a dropout layer with a ratio of #.# in the fully-connected layer to avoid over-ﬁtting. ConvNet is trained without data augmentation. Table # summarizes the results of three ConvNet networks. Here the row/column sparsity of a weight matrix is deﬁned as the percentage of all-zero rows/columns. Figure # shows their learned conv# ﬁlters. In Table # SSL can reduce the size of weight matrix in ConvNet # by ##% ##.#% and ##.#% for each convolutional layer and achieve good speedups without accuracy drop. Surprisingly without SSL four conv# ﬁlters of the baseline are actually all-zeros as shown in Figure # demonstrating the great potential of ﬁlter sparsity. When SSL is applied half of conv# ﬁlters in ConvNet # can be zeroed out without accuracy drop. On the other hand in ConvNet # SSL lowers #.#% (±#.##%) error with a model even smaller than the baseline. In this scenario SSL performs as a structure regularization to dynamically learn a better network structure (including the number of ﬁlters and ﬁler shapes) to reduce the error. ResNet: To investigate the necessary depth of DNNs by SSL we use a ##-layer deep residual networks (ResNet-##) [#] as the baseline. The network has ## convolutional layers and # fully-connected layer. Identity shortcuts are utilized to connect the feature maps with the same dimension while #×# convolutional layers are chosen as shortcuts between the feature maps with different dimensions. Batch normalization [##] is adopted after convolution and before activation. We use the same data augmentation and training hyper-parameters as that in [#]. The ﬁnal error of baseline is #.##%. In SSL the depth of ResNet-## is regularized by depth-wise sparsity. Group Lasso regularization is only enforced on the convolutional layers between each pair of shortcut endpoints excluding the ﬁrst convolutional layer and all convolutional shortcuts. After SSL converges layers with all zero weights are removed and the net is ﬁnally ﬁne-tuned with a base learning rate of #.## which is lower than that (i.e. #.#) in the baseline. Figure # plots the trend of the error vs. the number of layers under different strengths of depth regularizations. Compared with original ResNet in [#] SSL learns a ResNet with ## layers (SSL- ResNet-##) reaching a lower error than that of the baseline with ## layers (ResNet-##); SSL-ResNet-## and ResNet-## achieve an error of #.##% and #.##% respectively. This result implies that SSL can work as a depth regularization to improve classiﬁcation accuracy. Note that SSL can efﬁciently learn shallower DNNs without accuracy loss to reduce computation cost; however it does not mean the depth of the network is not important. The trend in Figure # shows that the test error generally declines as more layers are preserved. A slight error rise of SSL-ResNet-## from SSL-ResNet-## shows the suboptimal selection of the depth in the group of “##×##”. Figure #: Learned conv# ﬁlters in ConvNet # (top) ConvNet # (middle) and ConvNet # (bottom) # Table#:ResultsafterlearningﬁltershapesinLeNetLeNet#ErrorFiltersize§Channel#FLOPSpeedup#(baseline)#.#%##–####–#####%–###%#.##⇥–#.##⇥##.#%##–###–##.#%–#.#%#.##⇥–#.##⇥##.#%#–###–##.#%–#.#%#.##⇥–##.##⇥§Thesizesofﬁltersafterremovingzeroshapeﬁbers intheorderofconv#–conv##################% Reconstruction error conv#conv##################% ranks conv#conv#conv################## conv#conv#conv#conv#conv#Figure#:Thenormalizedreconstructureerrorofweightmatrixvs.thepercentofranks.PrincipalComponentAnalysis(PCA)isutilizedtoexploretheredundancyamongﬁlters.%ranksofeigenvec-torscorrespondingtothelargesteigenvaluesareselectedasbasistoperformlowrankapproximation.Left:LeNet#inTable#;middle:ConvNet#inTable#;right:AlexNet#inTable#.DashlinesindicatebaselinesandsolidlinesindicateresultsofSSL.detectorsofstrokepatternswhicharesufﬁcientforfeatureextraction.TheaccuracyofLeNet####(thatfurtherremovesoneweakestandoneredundantstrokedetector)comparedwithLeNet#drops###only#.#%.Althoughthetrainingprocessesofthreenetworksareindependent thecorresponding###regularizedﬁltersinLeNet#andLeNet#demonstrateveryhighsimilarityandrepresentcertainlevel###ofalikenesstothoseinLeNet#.ComparingwithrandomandblurryﬁlterpatternsinLeNet#resulted###fromthehighfreedomofparameterspace theﬁltersinLeNet#&#areregularizedthroughthe###ﬁlter-wiseandchannel-wisesparsityandthereforeconvergeatsmootherandmorenaturalpatterns.###ThisexplainswhyourproposedSSLobtainsthesame-levelaccuracybuthavingmuchlessﬁlters.###Theseregularityandsimilarityphenomenaarealsoobservedindeeperlayers.Differentfromlow###rankdecompositionwhichonlyexploretheredundancyanddoesnotchangetherank SSLcanreduce###theredundancyasshowninFigure#.###Wealsoexploretheeffectivenessoftheshape-wisesparsityonLeNetinTable#.ThebaselineLeNet####hasaregular#⇥#squaresizeofconv#ﬁlters whileLeNet#reducesthedimensiontolessthan####⇥#.Andthe#Dshapeofﬁltersinconv#ofLeNet#areregularizedto#DshapeofLeNet#with###onlyonechannel indicatingthatonlyoneﬁlterinconv#isneeded.ThissavessigniﬁcantFLOPand###computingtime.###MLP:Besidesconvolutionallayers ourproposedSSLcanbeextendedtolearnthestructure(i.e.###thenumberofneurons)infully-connectedlayers.Here thebaselineMLPnetworkcomposedof###twohiddenlayerswith###and###neuronsrespectivelyobtainsatesterrorof#.##%.Weenforced###thegroupLassoregularizationonalltheinput(oroutput)connectionsofeveryneuron including###thoseoftheinputlayer.Notethataneuronwithalltheinputconnectionszeroedoutdegenerate###toabiasneuroninthenextlayer;similarly aneurondegeneratestoaremovabledummyneuron###ifallofitsoutputconnectionsarezeroedout.Assuch thecomputationofGEneralMatrixVector###(GEMV)productinfully-connectedlayerscanbesigniﬁcantlyreduced.Table#summarizesthe###Table#:Learningthenumberofneuronsinmulti-layerperceptronMLP#ErrorNeuron#perlayer§FLOPperlayer§#(baseline)#.##%###–###–###–#####%–###%–###%##.##%###–###–###–####.##%–##.##%–##.##%##.##%###–###–##–####.##%–#.##%–##.##%§Intheorderofinputlayer–hiddenlayer#–hiddenlayer#–outputlayer# ########## Figure #: Error vs. layer number after depth regularization. # is the number of layers including the last fully-connected layer. ResNet-# is the ResNet in [#]. SSL-ResNet-# is the depth-regularized ResNet by SSL. ##×## indicates the convolutional layers with an output map size of ##×## etc. #.# AlexNet on ImageNet To show the generalization of our method to large scale DNNs we evaluate SSL using AlexNet with ILSVRC ####. CaffeNet [##] the replication of AlexNet [#] with mirror changes is used in our experiment. All training images are rescaled to the size of ###×###. A ###×### image is randomly cropped from each scaled image and mirrored for data augmentation and only the center crop is used for validation. The ﬁnal top-# validation error is ##.##%. In SSL AlexNet is ﬁrst trained with structure regularization; when it converges zero groups are removed to obtain a DNN with the new structure; ﬁnally the network is ﬁne-tuned without SSL to regain the accuracy. We ﬁrst study #D-ﬁlter-wise and shape-wise sparsity by exploring the trade-offs between computation complexity and classiﬁcation accuracy. Figure #(a) shows the #D-ﬁlter sparsity (the ratio between the removed #D ﬁlters and total #D ﬁlters) and the saved FLOP of #D convolutions vs. the validation error. In Figure #(a) deeper layers generally have higher sparsity as the group size shrinks and the number of #D ﬁlters grows. #D-ﬁlter sparsity regularization can reduce the total FLOP by ##%–##% without accuracy loss or reduce the error of AlexNet by ∼#% down to ##.##% by retaining the original number of parameters. Shape-wise sparsity also obtains similar results. In Table # for example AlexNet # achieves on average #.#× layer-wise speedup on both CPU and GPU without accuracy loss after shape regularization; The top-# error can also be reduced down to ##.##% if the parameters are retained. In Figure #(a) the obtained DNN with the lowest error has a very low sparsity indicating that the number of parameters in a DNN is still important to maintain learning capacity. In this case SSL works as a regularization to add restriction of smoothness to the model in order to avoid over- ﬁtting. Figure #(b) compares the results of dimensionality reduction of weight tensors in the baseline and our SSL-regularized AlexNet. The results show that the smoothness restriction enforces parameter searching in lower-dimensional space and enables lower rank approximation of the DNNs. Therefore SSL can work together with low rank approximation to achieve even higher model compression. Besides the above analyses the computation efﬁciencies of structured sparsity and non-structured sparsity are compared in Caffe using standard off-the-shelf libraries i.e. Intel Math Kernel Library (a) (b) (c) Figure #: (a) #D-ﬁlter-wise sparsity and FLOP reduction vs. top-# error. Vertical dash line shows the error of original AlexNet; (b) The reconstruction error of weight tensor vs. dimensionality. Principal Component Analysis (PCA) is utilized to perform dimensionality reduction. The eigenvectors corresponding to the largest eigenvalues are selected as basis of lower-dimensional space. Dash lines denote the results of the baselines and solid lines indicate the ones of the AlexNet # in Table #; (c) Speedups of (cid:##)#-norm and SSL on various CPUs and GPUs (In labels of x-axis T# is the number of maximum physical threads in CPUs). AlexNet # and AlexNet # in Table # are used as testbenches. # ###############SSL−ResNet−#% error SSLResNet−##ResNet−#############################SSL−ResNet−## conv layers ##×####×###×################SSL−ResNet−#% error SSLResNet−##ResNet−#############################SSL−ResNet−## conv layers ##×####×###×## ## ## ## ## ### # ## ## ## ## ### ##.# ## ##.# ## ##.# ## conv# conv# conv# conv# conv# FLOP % Sparsity % FLOP reduction % top-# error #################% dimensionality% Reconstruction error conv#conv#conv#conv#conv## # # # # # # Quadro Tesla Titan Black Xeon T# Xeon T# Xeon T# Xeon T# l# SSL speedup on CPU and CUDA cuBLAS and cuSPARSE on GPU. We use SSL to learn a AlexNet with high column-wise and row-wise sparsity as the representative of structured sparsity method. (cid:##)#-norm is selected as the representative of non-structured sparsity method instead of connection pruning [#] because (cid:##)#-norm get a higher sparsity on convolutional layers as the results of AlexNet # and AlexNet # depicted in Table #. Speedups achieved by SSL are measured by GEMM where all-zero rows (and columns) in each weight matrix are removed and the remaining ones are concatenated in consecutive memory space. Note that compared to GEMM the overhead of concatenation can be ignored. To measure the speedups of (cid:##)#-norm sparse weight matrices are stored in the format of Compressed Sparse Row (CSR) and computed by sparse-dense matrix multiplication subroutines. Table # compares the obtained sparsity and speedups of (cid:##)#-norm and SSL on CPU (Intel Xeon) and GPU (GeForce GTX TITAN Black) under approximately the same errors e.g. with acceptable or no accuracy loss. To make a fair comparison after (cid:##)#-norm regularization the DNN is also ﬁne-tuned by disconnecting all zero-weighted connections so that e.g. #.##% accuracy is recovered for the AlexNet #. Our experiments show that the DNNs require a very high non-structured sparsity to achieve a reasonable speedup (the speedups are even negative when the sparsity is low). SSL however can always achieve positive speedups. With an acceptable accuracy loss our SSL achieves on average #.#× and #.#× layer-wise acceleration on CPU and GPU respectively. Instead (cid:##)#-norm achieves on average only #.#× and #.#× layer-wise acceleration on CPU and GPU respectively. We note that at the same accuracy our average speedup is indeed higher than that of [#] which adopts heavy hardware customization to overcome the negative impact of non-structured sparsity. Figure #(c) shows the speedups of (cid:##)#-norm and SSL on various platforms including both GPU (Quadro Tesla and Titan) and CPU (Intel Xeon E#-####). SSL can achieve on average ∼ #× speedup on GPU while non-structured sparsity obtain no speedup on GPU platforms. On CPU platforms both methods can achieve good speedups and the beneﬁt grows as the processors become weaker. Nonetheless SSL can always achieve averagely ∼ #× speedup compared to non-structured sparsity. # Conclusion In this work we propose a Structured Sparsity Learning (SSL) method to regularize ﬁlter channel ﬁlter shape and depth structures in Deep Neural Networks (DNN). Our method can enforce the DNN to dynamically learn more compact structures without accuracy loss. The structured compactness of the DNN achieves signiﬁcant speedups for the DNN evaluation both on CPU and GPU with off-the-shelf libraries. Moreover a variant of SSL can be performed as structure regularization to improve classiﬁcation accuracy of state-of-the-art DNNs. Acknowledgments This work was supported in part by NSF XPS-####### and NSF CCF-#######. The authors thank Drs. Sheng Li and Jongsoo Park for valuable feedback on this work. Table #: Sparsity and speedup of AlexNet on ILSVRC #### # # # # # # Method Top# err. (cid:##)# ##.##% SSL ##.##% pruning [#] ##.##% (cid:##)# ##.##% SSL ##.##% Statistics sparsity CPU × GPU × row sparsity column sparsity CPU × GPU × sparsity sparsity CPU × GPU × CPU × GPU × column sparsity # #.## #.## #.## #.## #.## #.## conv# conv# conv# #.## #.## ##.#% ##.#% ##.#% ##.#% ##.#% ##.#% ##.#% #.#% #.## #.## #.## #.## conv# conv# ##.#% ##.#% ##.#% ##.#% ##.#% #.## #.## #.#% #.#% #.## #.## ##.#% ##.#% ##.#% ##.#% ##.#% ##.#% ##.#% ##.#% ##.#% ##.#% #.## #.## #.##% ##.#% ##.#% ##.#% ##.#% #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## References [#] Alex Krizhevsky Ilya Sutskever and Geoffrey E. Hinton. Imagenet classiﬁcation with deep convolutional neural networks. In Advances in Neural Information Processing Systems pages ####–####. ####. [#] Ross Girshick Jeff Donahue Trevor Darrell and Jitendra Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) ####. [#] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recogni- tion. arXiv preprint arXiv:####.#### ####. [#] Christian Szegedy Wei Liu Yangqing Jia Pierre Sermanet Scott Reed Dragomir Anguelov Dumitru Erhan Vincent Vanhoucke and Andrew Rabinovich. Going deeper with convolutions. arXiv preprint arXiv:####.#### ####. [#] Kaiming He Xiangyu Zhang Shaoqing Ren and Jian Sun. Deep residual learning for image recognition. arXiv preprint arXiv:####.##### ####. [#] Baoyuan Liu Min Wang Hassan Foroosh Marshall Tappen and Marianna Pensky. Sparse convolutional neural networks. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) ####. [#] Song Han Jeff Pool John Tran and William Dally. Learning both weights and connections for efﬁcient neural network. In Advances in Neural Information Processing Systems pages ####–####. ####. [#] Song Han Huizi Mao and William J. Dally. Deep compression: Compressing deep neural network with pruning trained quantization and huffman coding. arXiv preprint arXiv:####.##### ####. [#] Misha Denil Babak Shakibi Laurent Dinh Marc' Aurelio Ranzato and Nando de Freitas. Predicting parameters in deep learning. In Advances in Neural Information Processing Systems pages ####–####. ####. [##] Emily L Denton Wojciech Zaremba Joan Bruna Yann LeCun and Rob Fergus. Exploiting linear structure within convolutional networks for efﬁcient evaluation. In Advances in Neural Information Processing Systems pages ####–####. ####. [##] Max Jaderberg Andrea Vedaldi and Andrew Zisserman. Speeding up convolutional neural networks with low rank expansions. arXiv preprint arXiv:####.#### ####. [##] Yani Ioannou Duncan P. Robertson Jamie Shotton Roberto Cipolla and Antonio Criminisi. Training cnns with low-rank ﬁlters for efﬁcient image classiﬁcation. arXiv preprint arXiv:####.##### ####. [##] Cheng Tai Tong Xiao Xiaogang Wang and Weinan E. Convolutional neural networks with low-rank regularization. arXiv preprint arXiv:####.##### ####. [##] Ming Yuan and Yi Lin. Model selection and estimation in regression with grouped variables. Journal of the Royal Statistical Society. Series B (Statistical Methodology) ##(#):##–## ####. [##] Seyoung Kim and Eric P Xing. Tree-guided group lasso for multi-task regression with structured sparsity. In Proceedings of the ##th International Conference on Machine Learning ####. [##] Jiashi Feng and Trevor Darrell. Learning the structure of deep convolutional networks. In The IEEE International Conference on Computer Vision (ICCV) ####. [##] Vadim Lebedev and Victor Lempitsky. Fast convnets using group-wise brain damage. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) June ####. [##] Rupesh Kumar Srivastava Klaus Greff and Jürgen Schmidhuber. Highway networks. arXiv preprint arXiv:####.##### ####. [##] Sharan Chetlur Cliff Woolley Philippe Vandermersch Jonathan Cohen John Tran Bryan Catanzaro and Evan Shelhamer. cudnn: Efﬁcient primitives for deep learning. arXiv preprint arXiv:####.#### ####. [##] Yangqing Jia Evan Shelhamer Jeff Donahue Sergey Karayev Jonathan Long Ross Girshick Sergio Guadarrama and Trevor Darrell. Caffe: Convolutional architecture for fast feature embedding. arXiv preprint arXiv:####.#### ####. [##] Yann LeCun Léon Bottou Yoshua Bengio and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE ##(##):####–#### ####. [##] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:####.##### ####. #\n",
            "response:  High demand for computation resources severely hinders deployment of large-scale Deep Neural Networks (DNN) in resource constrained devices. In this work we propose a Structured Sparsity Learning (SSL) method to regularize the structures (i.e. filters channels filter shapes and layer depth) of DNNs. SSL can: (#) learn a compact structure from a bigger DNN to reduce computation cost; (#). obtain a hardware-friendly structured sparsity of DNR to efficiently accelerate the DNN's evaluation.\n",
            "summarize: Optimization Monte Carlo: Efﬁcient and Embarrassingly Parallel Likelihood-Free Inference Edward Meeds Informatics Institute University of Amsterdam tmeeds@gmail.com Max Welling∗ welling.max@gmail.com Informatics Institute University of Amsterdam Abstract We describe an embarrassingly parallel anytime Monte Carlo method for likelihood-free models. The algorithm starts with the view that the stochastic- ity of the pseudo-samples generated by the simulator can be controlled externally by a vector of random numbers u in such a way that the outcome knowing u is deterministic. For each instantiation of u we run an optimization procedure to minimize the distance between summary statistics of the simulator and the data. After reweighing these samples using the prior and the Jacobian (accounting for the change of volume in transforming from the space of summary statistics to the space of parameters) we show that this weighted ensemble represents a Monte Carlo estimate of the posterior distribution. The procedure can be run embar- rassingly parallel (each node handling one sample) and anytime (by allocating resources to the worst performing sample). The procedure is validated on six ex- periments. Introduction # Computationally demanding simulators are used across the full spectrum of scientiﬁc and industrial applications whether one studies embryonic morphogenesis in biology tumor growth in cancer research colliding galaxies in astronomy weather forecasting in meteorology climate changes in the environmental science earthquakes in seismology market movement in economics turbulence in physics brain functioning in neuroscience or fabrication processes in industry. Approximate Bayesian computation (ABC) forms a large class algorithms that aims to sample from the posterior distribution over parameters for these likelihood-free (a.k.a. simulator based) models. Likelihood- free inference however is notoriously inefﬁcient in terms of the number of simulation calls per independent sample. Further like regular Bayesian inference algorithms care must be taken so that posterior sampling targets the correct distribution. The simplest ABC algorithm ABC rejection sampling can be fully parallelized by running indepen- dent processes with no communication or synchronization requirements. I.e. it is an embarrassingly parallel algorithm. Unfortunately as the most inefﬁcient ABC algorithm the beneﬁts of this ti- tle are limited. There has been considerable progress in distributed MCMC algorithms aimed at large-scale data problems [# #]. Recently a sequential Monte Carlo (SMC) algorithm called “the particle cascade” was introduced that emits streams of samples asynchronously with minimal mem- ory management and communication [##]. In this paper we present an alternative embarrassingly parallel sampling approach: each processor works independently at full capacity and will indeﬁ- nitely emit independent samples. The main trick is to pull random number generation outside of the simulator and treat the simulator as a deterministic piece of code. We then minimize the difference ∗Donald Bren School of Information and Computer Sciences University of California Irvine and Canadian Institute for Advanced Research. # between observations and the simulator output over its input parameters and weight the ﬁnal (opti- mized) parameter value with the prior and the (inverse of the) Jacobian. We show that the resulting weighted ensemble represents a Monte Carlo estimate of the posterior. Moreover we argue that the error of this procedure is O(\u0001) if the optimization gets \u0001-close to the optimal value. This “Opti- mization Monte Carlo” (OMC) has several advantages: #) it can be run embarrassingly parallel #) the procedure generates independent samples and #) the core procedure is now optimization rather than MCMC. Indeed optimization as part of a likelihood-free inference procedure has recently been proposed [##]; using a probabilistic model of the mapping from parameters to differences between observations and simulator outputs they apply “Bayesian Optimization” (e.g. [## ##]) to efﬁciently perform posterior inference. Note also that since random numbers have been separated out from the simulator powerful tools such as “automatic differentiation” (e.g. [##]) are within reach to assist with the optimization. In practice we ﬁnd that OMC uses far fewer simulations per sample than alternative ABC algorithms. The approach of controlling randomness as part of an inference procedure is also found in a related class of parameter estimation algorithms called indirect inference [##]. Connections between ABC and indirect inference have been made previously by [#] as a novel way of creating summary statis- tics. An indirect inference perspective led to an independently developed version of OMC called the “reverse sampler” [# ##]. In Section # we brieﬂy introduce ABC and present it from a novel viewpoint in terms of random numbers. In Section # we derive ABC through optimization from a geometric point of view then proceed to generalize it to higher dimensions. We show in Section # extensive evidence of the correctness and efﬁciency of our approach. In Section # we describe the outlook for optimization- based ABC. # ABC Sampling Algorithms The primary interest in ABC is the posterior of simulator parameters θ given a vector of (statistics of) observations y p(θ|y). The likelihood p(y|θ) is generally not available in ABC. Instead we can use the simulator as a generator of pseudo-samples x that reside in the same space as y. By treating x as auxiliary variables we can continue with the Bayesian treatment: p(θ|y) = ≈ p(θ)(cid:##) p\u0001(y|x)p(x|θ) dx (cid:##) p(θ)(cid:##) p\u0001(y|x)p(x|θ) dx dθ p(θ)p(y|θ) p(y) (#) Of particular importance is the choice of kernel measuring the discrepancy between observations y and pseudo-data x. Popular choices for kernels are the Gaussian kernel and the uniform \u0001-tube/ball. The bandwidth parameter \u0001 (which may be a vector \u0001 accounting for relative importance of each statistic) plays critical role: small \u0001 produces more accurate posteriors but is more computationally demanding whereas large \u0001 induces larger error but is cheaper. We focus our attention on population-based ABC samplers which include rejection sampling im- portance sampling (IS) sequential Monte Carlo (SMC) [# ##] and population Monte Carlo [#]. In rejection sampling we draw parameters from the prior θ ∼ p(θ) then run a simulation at those parameters x ∼ p(x|θ); if the discrepancy ρ(x y) < \u0001 then the particle is accepted otherwise it is rejected. This is repeated until n particles are accepted. Importance sampling generalizes rejec- tion sampling using a proposal distribution qφ(θ) instead of the prior and produces samples with weights wi ∝ p(θ)/q(θ). SMC extends IS to multiple rounds with decreasing \u0001 adapting their par- ticles after each round such that each new population improves the approximation to the posterior. Our algorithm has similar qualities to SMC since we generate a population of n weighted particles but differs signiﬁcantly since our particles are produced by independent optimization procedures making it completely parallel. # A Parallel and Efﬁcient ABC Sampling Algorithm Inherent in our assumptions about the simulator is that internally there are calls to a random number generator which produces the stochasticity of the pseudo-samples. We will assume for the moment that this can be represented by a vector of uniform random numbers u which if known would make the simulator deterministic. More concretely we assume that any simulation output x can be represented as a deterministic function of parameters θ and a vector of random numbers u # (a) Dθ = Dy (b) Dθ < Dy Figure #: Illustration of OMC geometry. (a) Dashed lines indicate contours f (θ u) over θ for several u. For three values of u their initial and optimal θ positions are shown (solid blue/white circles). Within the grey acceptance region the Jacobian indicated by the blue diagonal line describes the relative change in volume induced in f (θ u) from a small change in θ. Corresponding weights ∝ #/|J| are shown as vertical stems. (b) When Dθ < Dy here # < # the change in volume is proportional to the length of the line segment inside the ellipsoid (|JT J|#/#). The orange line indicates the projection of the observation onto the contour of f (θ u) (in this case identical to the optimal). i.e. x = f (θ u). This assumption has been used previously in ABC ﬁrst in “coupled ABC” [##] and also in an application of Hamiltonian dynamics to ABC [##]. We do not make any further assumptions regarding u or p(u) though for some problems their dimension and distribution may be known a priori. In these cases it may be worth employing Sobol or other low-discrepancy sequences to further improve the accuracy of any Monte Carlo estimates. We will ﬁrst derive a dual representation for the ABC likelihood function p\u0001(y|θ) (see also [##]) p\u0001(y|θ) = = p\u0001(y|x)p(x|θ) dx = p\u0001(y|f (θ u))p(u) du p\u0001(y|x)I[x = f (θ u)]p(u) dxdu (#) (#) (cid:##) (cid:##) (cid:##) (cid:##) (cid:##) leading to the following Monte Carlo approximation of the ABC posterior p\u0001(θ|y) ∝ p(θ) p(u)p\u0001(y|f (u θ)) du ≈ # n p\u0001(y|f (ui θ))p(θ) ui ∼ p(u) (#) (cid:##) i i that results in y = f (θo Since p\u0001 is a kernel that only accepts arguments y and f (ui θ) that are \u0001 close to each other (for values of \u0001 that are as small as possible) Equation # tells us that we should ﬁrst sample values for u from p(u) and then for each such sample ﬁnd the value for θo i u). In practice we want to drive these values as close to each other as possible through optimization and accept an O(\u0001) error if the remaining distance is still O(\u0001). Note that apart from sampling the values for u this procedure is deterministic and can be executed completely in parallel i.e. without any communication. In the following we will assume a single observation vector y but the approach is equally applicable to a dataset of N cases. #.# The case Dθ = Dy We will ﬁrst study the case when the number of parameters θ is equal to the number of summary statistics y. To understand the derivation it helps to look at Figure #a which illustrates the derivation for the one dimensional case. In the following we use the following abbreviation: fi(θ) stands for f (θ ui). The general idea is that we want to write the approximation to the posterior as a mixture of small uniform balls (or delta peaks in the limit): wiU\u0001(θ|θ∗ i )p(θ) (#) (cid:##) i p(θ|y) ≈ # n (cid:##) i p\u0001(y|f (ui θ))p(θ) ≈ # n # with wi some weights that we will derive shortly. Then if we make \u0001 small enough we can replace any average of a sufﬁciently smooth function h(θ) w.r.t. this approximate posterior simply by eval- uating h(θ) at some arbitrarily chosen points inside these balls (for instance we can take the center of the ball θ∗ i ) (cid:##) h(θ)p(θ|y) dθ ≈ # n h(θ∗ i )wip(θ∗ i ) (#) (cid:##) i To derive this expression we ﬁrst assume that: (#) i.e. a ball of radius \u0001. C(\u0001) is the normalizer which is immaterial because it cancels in the posterior. For small enough \u0001 we claim that we can linearize fi(θ) around θo i : p\u0001(y|fi(θ)) = C(\u0001)I[||y − fi(θ)||# ≤ \u0001#] Ri = O(||θ − θo i ||#) (#) . We take θo i to be the end result of our i (θ − θo i ) + Jo ˆfi(θ) = fi(θo i ) + Ri i is the Jacobian matrix with columns ∂fi(θo i ) where Jo optimization procedure for sample ui. Using this we thus get i )) − Jo ∂θd ||y − fi(θ)||# ≈ ||(y − fi(θo i ) − Ri||# i (θ − θo (#) We ﬁrst note that since we assume that our optimization has ended up somewhere inside the ball i )|| = O(\u0001). Also since we only deﬁned by ||y − fi(θ)||# ≤ \u0001# we can assume that ||y − fi(θo consider values for θ that satisfy ||y − fi(θ)||# ≤ \u0001# and furthermore assume that the function i || = O(\u0001) as well. All of this implies fi(θ) is Lipschitz continuous in θ it follows that ||θ − θo that we can safely ignore the remaining term Ri (which is of order O(||θ − θo i ||#) = O(\u0001#)) if we restrict ourselves to the volume inside the ball. The next step is to view the term I[||y − fi(θ)||# ≤ \u0001#] as a distribution in θ. With the Taylor expansion this results in I[(θ − θo i − Jo −# i (y − fi(θo i )))T JoT i Jo This represents an ellipse in θ-space with a centroid θ∗ i (θ − θo (y − fi(θo i and volume Vi given by i i ))) ≤ \u0001#] θ∗ i = θo (y − fi(θo i )) i i + Jo −# (cid:##) i Jo i ) with γ a constant independent of i. We can approximate the posterior now as i )p(θ∗ i ) i Jo i ) U\u0001(θ|θ∗ det(JoT p(θ|y) ≈ # κ i )p(θ) i Jo i ) δ(θ − θ∗ ≈ # κ det(JoT det(JoT (cid:###) i i malization κ = (cid:##) i Jo i p(θ∗ i ) det(JoT where in the last step we have send \u0001 → #. Finally we can compute the constant κ through nor- i )−#/#. The whole procedure is accurate up to errors of the order O(\u0001#) and it is assumed that the optimization procedure delivers a solution that is located within the epsilon ball. If one of the optimizations for a certain sample ui did not end up within the epsilon ball there can be two reasons: #) the optimization did not converge to the optimal value for θ or #) for this value of u there is no solution for which f (θ|u) can get within a distance \u0001 from the observation y. If we interpret \u0001 as our uncertainty in the observation y and we assume that our optimization succeeded in ﬁnding the best possible value for θ then we should simply reject this sample θi. However it is hard to detect if our optimization succeeded and we may therefore sometimes reject samples that should not have been rejected. Thus one should be careful not to create a bias against samples ui for which the optimization is difﬁcult. This situation is similar to a sampler that will not mix to remote local optima in the posterior distribution. Vi = i − Jo −# γ(cid:###) (cid:###) (cid:##) (##) (##) (##) #.# The case Dθ < Dy This is the overdetermined case and here the situation as depicted in Figure #b is typical: the mani- fold that f (θ ui) traces out as we vary θ forms a lower dimensional surface in the Dy dimensional enveloping space. This manifold may or may not intersect with the sphere centered at the observa- tion y (or ellipsoid for the general case \u0001 instead of \u0001). Assume that the manifold does intersect the # i (y − fi(θo i )) epsilon ball but not y. Since we trust our observation up to distance \u0001 we may simple choose to pick the closest point θ∗ i to y on the manifold which is given by θ∗ i = θo i + Jo† (##) where Jo† is the pseudo-inverse. We can now deﬁne our ellipse around this point shifting the center of the ball from y to fi(θ∗ i ) (which do not coincide in this case). The uniform distribution on the ellipse in θ-space is now deﬁned in the Dθ dimensional manifold and has volume Vi = i )−#/#. So once again we arrive at almost the same equation as before (Eq. ##) but with γ det(JoT i )|| ≤ \u0001# the slightly different deﬁnition of the point θ∗ and if we assume that our optimization succeeded we will only make mistakes of order O(\u0001#). i given by Eq. ##. Crucially since ||y − fi(θ∗ Jo† i = (JoT i Jo i )−#JoT i i i Jo #.# The case Dθ > Dy This is the underdetermined case in which it is typical that entire manifolds (e.g. hyperplanes) may be a solution to ||y − fi(θ∗ In this case we can not approximate the posterior with a mixture of point masses and thus the procedure does not apply. However the case Dθ > Dy is less interesting than the other ones above as we expect to have more summary statistics than parameters for most problems. i )|| = #. # Experiments The goal of these experiments is to demonstrate #) the correctness of OMC and #) the relative efﬁciency of OMC in relation to two sequential MC algorithms SMC (aka population MC [#]) and adaptive weighted SMC [#]. To demonstrate correctness we show histograms of weighted samples along with the true posterior (when known) and for three experiments the exact OMC weighted samples (when the exact Jacobian and optimal θ is known). To demonstrate efﬁciency we compute the mean simulations per sample (SS)—the number of simulations required to reach an \u0001 threshold— and the effective sample size (ESS) deﬁned as #/wT w. Additionally we may measure ESS/n the fraction of effective samples in the population. ESS is a good way of detecting whether the posterior is dominated by a few particles and/or how many particles achieve discrepancy less than epsilon. There are several algorithmic options for OMC. The most obvious is to spawn independent pro- cesses draw u for each and optimize until \u0001 is reached (or a max nbr of simulations run) then compute Jacobians and particle weights. Variations could include keeping a sorted list of discrepan- cies and allocating computational resources to the worst particle. However to compare OMC with SMC in this paper we use a sequential version of OMC that mimics the epsilon rounds of SMC. Each simulator uses different optimization procedures including Newton’s method for smooth sim- ulators and random walk optimization for others; Jacobians were computed using one-sided ﬁnite differences. To limit computational expense we placed a max of #### simulations per sample per round for all algorithms. Unless otherwise noted we used n = #### and repeated runs # times; lack of error bars indicate very low deviations across runs. We also break some of the notational conven- tion used thus far so that we can specify exactly how the random numbers translate into pseudo-data and the pseudo-data into statistics. This is clariﬁed for each example. Results are explained in Figures # to #. #.# Normal with Unknown Mean and Known Variance √ The simplest example is the inference of the mean θ of a univariate normal distribution with known variance σ#. The prior distribution π(θ) is normal with mean θ# and variance kσ# where k > # is a factor relating the dispersions of θ and the data yn. The simulator can generate data according to the normal distribution or deterministically if the random effects rum are known: =⇒ xm = θ + rum (cid:##) m xm. Therefore we have f (θ u) = θ + R(u) where R(u) =(cid:##) rum /M π(xm|θ) = N (xm|θ σ#) (##) −#(#um− #) (using the inverse CDF). A sufﬁcient statistic for this problem is where rum = σ # erf the average s(x) = # M In our experiment we set M = # and y = #. The exact (the average of the random effects). Jacobian and θo i can be computed for this problem: for a draw ui Ji = #; if s(y) is the mean of the i = s(y) − R(ui). Therefore the exact observations y then by setting f (θo weights are wi ∝ π(θo i ) allowing us to compare directly with an exact posterior based on our dual representation by u (shown by orange circles in Figure # top-left). We used Newton’s method to optimize each particle. i ui) = s(y) we ﬁnd θo # Figure #: Left: Inference of unknown mean. For \u0001 #.# OMC uses #.# SS; AW/SMC uses ##/## SS; at \u0001 #.## OMC uses # SS (only #.# SS more) and SMC jumps to ### SS. For all algorithms and \u0001 values ESS/n=#. Right: Inference for mixture of normals. Similar results for OMC; at \u0001 #.### AW/SMC had ##/## SS and at \u0001 #.## has ###/### SS. The ESS/n remained at # for OMC but decreased to #.##/#.## (AW/SMC) at \u0001 #.### and #.## for both at \u0001 #.##. Not only does the ESS remain high for OMC but it also represents the tails of the distribution well even at low \u0001. #.# Normal Mixture A standard illustrative ABC problem is the inference of the mean θ of a mixture of two normals [## # #]: p(x|θ) = ρ N (θ σ# #) with π(θ) = U(θa θb) where hyperparameters # = #/### θa = −## θb = ## and a single observation scalar y = #. are ρ = #/# σ# For this problem M = # so we drop the subscript m. The true posterior is simply p(θ|y = #) ∝ ρ N (θ σ# #) θ ∈ {−## ##}. In this problem there are two random numbers u# and u# one for selecting the mixture component and the other for the random innovation; further the statistic is the identity i.e. s(x) = x: #) + (# − ρ) N (θ σ# #) + (#− ρ) N (θ σ# # = # σ# # erf(#u# − #)) + [u# ≥ ρ](θ + σ# # erf(#u# − #)) √ √ x = [u# < ρ](θ + σ# √ √ = θ + σ[u#≥ρ] # where R(u) = . As with the previous example the Jacobian is # i = y − R(ui) is known exactly. This problem is notable for causing performance issues in and θo ABC-MCMC [##] and its difﬁculty in targeting the tails of the posterior [#]; this is not the case for OMC. # erf(#u# − #)σ[u#<ρ] σ[u#≥ρ] # erf(#u# − #)σ[u#<ρ] = θ + R(u) # # # (##) (##) #.# Exponential with Unknown Rate In this example the goal is to infer the rate θ of an exponential distribution with a gamma prior p(θ) = Gamma(θ|α β) based on M draws from Exp(θ): p(xm|θ) = Exp(xm|θ) = θ exp(−θxm) =⇒ xm = − # θ problem is the average s(x) = (cid:##) (##) where rum = − ln(# − um) (the inverse CDF of the exponential). A sufﬁcient statistic for this m xm/M. Again we have exact expressions for the Jacobian i = R(ui)/s(y). We used M = # i using f (θ ui) = R(ui)/θ Ji = −R(ui)/θ# and θo ln(# − um) = rum # θ and θo s(y) = ## in our experiments. #.# Linked Mean and Variance of Normal In this example we link together the mean and variance of the data generating function as follows: (##) p(xm|θ) = N (xm|θ θ#) =⇒ xm = θ + θ −#(#um − #) = θrum # erf √ # Figure #: Left: Inference of rate of exponential. A similar result wrt SS occurs for this experiment: at \u0001 # OMC had ## v ##/## for AW/SMC; at \u0001 #.## SS was ## OMC v ### AW/SMC. ESS/n dropping with below #: OMC drops at \u0001 # to #.## v #.## for SMC; at \u0001 #.# ESS/n remains the same. Right: Inference of linked normal. ESS/n drops signiﬁcantly for OMC: at \u0001 #.## to #.## and at \u0001 #.# to #.## while it remains high for SMC (#.## to #.##). This is the result the inability of every ui to achieve ρ < \u0001 whereas for SMC the algorithm allows them to “drop” their random numbers and effectively switch to another. This was veriﬁed by running an expensive ﬁne-grained optimization resulting in ##.#% and ##.#% optimized particles having ρ under \u0001 #.##/#.#. Taking this inefﬁciency into account OMC still requires ### simulations per effective sample v ### for SMC (ie ##/#.## and ###/#.##). √ −#(#um − #). We put a positive constraint on θ: p(θ) = U(# ##). We used # erf where rum = # + # statistics the mean and variance of M draws from the simulator: =⇒ f#(θ u) = θR(u) =⇒ f#(θ u) = θ#V (u) (xm − s#(x))# s#(x) = xm # M # M (cid:##) where V (u) = (cid:##) s#(x) = m /M − R(u)# and R(u) = (cid:##) m r# um [R(u) #θV (u)]T . In our experiments M = ## s(y) = [#.# ##.#]. ∂f#(θ u) ∂θ ∂f#(θ u) ∂θ = R(u) = #θV (u) (##) (##) m rum /M; the exact Jacobian is therefore #.# Lotka-Volterra The simplest Lotka-Volterra model explains predator-prey populations over time controlled by a set of stochastic differential equations: = θ#x# − θ#x#x# + r# dx# dt dx# dt = −θ#x# − θ#x#x# + r# (##) where x# and x# are the prey and predator population sizes respectively. Gaussian noise r ∼ N (# ###) is added at each full time-step. Lognormal priors are placed over θ. The simulator runs for T = ## time steps with constant initial populations of ### for both prey and predator. There is therefore P = #T outputs (prey and predator populations concatenated) which we use as the statistics. To run a deterministic simulation we draw ui ∼ π(u) where the dimension of u is P . Half of the random variables are used for r# and the other half for r#. In other words −#(#ust − #) where s ∈ {# #} for the appropriate population. The Jacobian is a rust = ## ###×# matrix that can be computed using one-sided ﬁnite-differences using # forward simulations. # erf √ #.# Bayesian Inference of the M/G/# Queue Model Bayesian inference of the M/G/# queuing model is challenging requiring ABC algorithms [# #] or sophisticated MCMC-based procedures [##]. Though simple to simulate the output can be quite # Figure #: Top: Lotka-Volterra. Bottom: M/G/# Queue. The left plots shows the posterior mean ±# std errors of the posterior predictive distribution (sorted for M/G/#). Simulations per sample and the posterior of θ# are shown in the other plots. For L-V at \u0001 # the SS for OMC were ## v ###/### for AW/SMC and increased at \u0001 # to ## v ###/###. However the ESS/n was lower for OMC: at \u0001 # it was #.## and down to #.# at \u0001 # whereas ESS/n stayed around #.# for AW/SMC. This is again due to the optimal discrepancy for some u being greater than \u0001; however the samples that remain are independent samples. For M/G/# the results are similar but the ESS/n is lower than the number of discrepancies satisfying \u0001 # #% v ##% indicating that the volume of the Jacobians is having a large effect on the variance of the weights. Future work will explore this further. noisy. In the M/G/# queuing model a single server processes arriving customers which are then served within a random time. Customer m arrives at time wm ∼ Exp(θ#) after customer m− # and is served in sm ∼ U(θ# θ#) service time. Both wm and sm are unobserved; only the inter-departure times xm are observed. Following [##] we write the simulation algorithm in terms of arrival times vm. To simplify the updates we keep track of the departure times dm. Initially d# = # and v# = # followed by updates for m ≥ #: xm = sm + max(# vm − dm−#) dm = dm−# + xm vm = vm−# + wm (##) After trying several optimization procedures we found the most reliable optimizer was simply a random walk. The random sources in the problem used for Wm (there are M) and for Um (there are M) therefore u is dimension #M. Typical statistics for this problem are quantiles of x and/or the minimum and maximum values; in other words the vector x is sorted then evenly spaced values for the statistics functions f (we used # quantiles). The Jacobian is an M ×# matrix. In our experiments θ∗ = [#.# #.# #.#] # Conclusion We have presented Optimization Monte Carlo a likelihood-free algorithm that by controlling the simulator randomness transforms traditional ABC inference into a set of optimization procedures. By using OMC scientists can focus attention on ﬁnding a useful optimization procedure for their simulator and then use OMC in parallel to generate samples independently. We have shown that OMC can also be very efﬁcient though this will depend on the quality of the optimization pro- cedure applied to each problem. In our experiments the simulators were cheap to run allowing Jacobian computations using ﬁnite differences. We note that for high-dimensional input spaces and expensive simulators this may be infeasible solutions include randomized gradient estimates [##] or automatic differentiation (AD) libraries (e.g. [##]). Future work will include incorporating AD improving efﬁciency using Sobol numbers (when the size u is known) incorporating Bayesian opti- mization adding partial communication between processes and inference for expensive simulators using gradient-based optimization. Acknowledgments We thank the anonymous reviewers for the many useful comments that improved this manuscript. MW acknowledges support from Facebook Google and Yahoo. # References [#] Ahn S. Korattikara A. Liu N. Rajan S. and Welling M. (####). Large scale distributed Bayesian matrix factorization using stochastic gradient MCMC. In KDD. [#] Ahn S. Shahbaba B. and Welling M. (####). Distributed stochastic gradient MCMC. In Proceedings of the ##st International Conference on Machine Learning (ICML-##) pages ####–####. [#] Beaumont M. A. Cornuet J.-M. Marin J.-M. and Robert C. P. (####). Adaptive approximate Bayesian computation. Biometrika ##(#):###–###. [#] Blum M. G. and Franc¸ois O. (####). Non-linear regression models for approximate Bayesian computa- tion. Statistics and Computing ##(#):##–##. [#] Bonassi F. V. and West M. (####). Sequential Monte Carlo with adaptive weights for approximate Bayesian computation. Bayesian Analysis ##(#). [#] Del Moral P. Doucet A. and Jasra A. (####). Sequential Monte Carlo samplers. Journal of the Royal Statistical Society: Series B (Statistical Methodology) ##(#):###–###. [#] Drovandi C. C. Pettitt A. N. and Faddy M. J. (####). Approximate Bayesian computation using indirect inference. Journal of the Royal Statistical Society: Series C (Applied Statistics) ##(#):###–###. [#] Fearnhead P. and Prangle D. (####). Constructing summary statistics for approximate Bayesian compu- tation: semi-automatic approximate Bayesian computation. Journal of the Royal Statistical Society: Series B (Statistical Methodology) ##(#):###–###. [#] Forneron J.-J. and Ng S. (####a). The ABC of simulation estimation with auxiliary statistics. arXiv preprint arXiv:####.#####v#. [##] Forneron J.-J. and Ng S. (####b). A likelihood-free reverse sampler of the posterior distribution. arXiv preprint arXiv:####.#####v#. [##] Gourieroux C. Monfort A. and Renault E. (####). Indirect inference. Journal of applied econometrics #(S#):S##–S###. [##] Gutmann M. U. and Corander J. (####). Bayesian optimization for likelihood-free inference of simulator-based statistical models. Journal of Machine Learning Research preprint arXiv:####.#####. In press. [##] Jones D. R. Schonlau M. and Welch W. J. (####). Efﬁcient global optimization of expensive black-box functions. Journal of Global optimization ##(#):###–###. [##] Maclaurin D. and Duvenaud D. (####). Autograd. github.com/HIPS/autograd. [##] Meeds E. Leenders R. and Welling M. (####). Hamiltonian ABC. Uncertainty in AI ##. [##] Neal P. (####). Efﬁcient likelihood-free Bayesian computation for household epidemics. Statistical Computing ##:####–####. [##] Paige B. Wood F. Doucet A. and Teh Y. W. (####). Asynchronous anytime Sequential Monte Carlo. In Advances in Neural Information Processing Systems pages ####–####. [##] Shestopaloff A. Y. and Neal R. M. (####). On Bayesian inference for the M/G/# queue with efﬁcient MCMC sampling. Technical Report Dept. of Statistics University of Toronto. [##] Sisson S. Fan Y. and Tanaka M. M. (####). Sequential Monte Carlo without likelihoods. Proceedings of the National Academy of Sciences ###(#). [##] Sisson S. Fan Y. and Tanaka M. M. (####). Sequential Monte Carlo without likelihoods: Errata. Proceedings of the National Academy of Sciences ###(##). [##] Snoek J. Larochelle H. and Adams R. P. (####). Practical Bayesian optimization of machine learning algorithms. Advances in Neural Information Processing Systems ##. [##] Spall J. C. (####). Multivariate stochastic approximation using a simultaneous perturbation gradient approximation. Automatic Control IEEE Transactions on ##(#):###–###. #\n",
            "response:  We describe an embarrassingly parallel anytime Monte Carlo method for likelihood-free models. The algorithm starts with the view that the stochasticity of the pseudo-samples generated by the simulator can be controlled externally by a vector of random numbers $u$ in such a way that the outcome knowing $u is deterministic. For each instantiation of $u$ we run an optimization procedure to minimize the distance between summary statistics of the simulator and the data.\n",
            "summarize: Efﬁcient and Robust Automated Machine Learning Matthias Feurer Jost Tobias Springenberg Aaron Klein Manuel Blum Katharina Eggensperger Frank Hutter Department of Computer Science University of Freiburg Germany {feurerm kleinaa eggenspk springj mblum fh}@cs.uni-freiburg.de Abstract The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning (AutoML) problem with the help of efﬁcient Bayesian optimization methods. Building on this we introduce a robust new AutoML system based on scikit-learn (using ## classiﬁers ## feature preprocessing methods and # data preprocessing methods giving rise to a structured hypothesis space with ### hyperparameters). This system which we dub AUTO-SKLEARN improves on existing AutoML methods by automatically taking into account past performance on similar datasets and by constructing ensembles from the models evaluated during the optimization. Our system won the ﬁrst phase of the ongoing ChaLearn AutoML challenge and our comprehensive analysis on over ### diverse datasets shows that it substantially outperforms the previous state of the art in AutoML. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of AUTO-SKLEARN. # Introduction Machine learning has recently made great strides in many application areas fueling a growing demand for machine learning systems that can be used effectively by novices in machine learning. Correspondingly a growing number of commercial enterprises aim to satisfy this demand (e.g. BigML.com Wise.io SkyTree.com RapidMiner.com Dato.com Prediction.io DataRobot.com Microsoft’s Azure Machine Learning Google’s Prediction API and Amazon Machine Learning). At its core every effective machine learning service needs to solve the fundamental problems of deciding which machine learning algorithm to use on a given dataset whether and how to preprocess its features and how to set all hyperparameters. This is the problem we address in this work. More speciﬁcally we investigate automated machine learning (AutoML) the problem of automatically (without human input) producing test set predictions for a new dataset within a ﬁxed computational budget. Formally this AutoML problem can be stated as follows: Deﬁnition # (AutoML problem). For i = # . . . n+m let xi ∈ Rd denote a feature vector and yi ∈ Y the corresponding target value. Given a training dataset Dtrain = {(x# y#) . . . (xn yn)} and the feature vectors xn+# . . . xn+m of a test dataset Dtest = {(xn+# yn+#) . . . (xn+m yn+m)} drawn from the same underlying data distribution as well as a resource budget b and a loss metric L(· ·) the AutoML problem is to (automatically) produce test set predictions ˆyn+# . . . ˆyn+m. The loss of a solution ˆyn+# . . . ˆyn+m to the AutoML problem is given by # m (cid:##)m j=# L(ˆyn+j yn+j). # In practice the budget b would comprise computational resources such as CPU and/or wallclock time and memory usage. This problem deﬁnition reﬂects the setting of the ongoing ChaLearn AutoML challenge [#]. The AutoML system we describe here won the ﬁrst phase of that challenge. Here we follow and extend the AutoML approach ﬁrst introduced by AUTO-WEKA [#] (see At its core this approach combines a highly parametric machine learning framework F with a Bayesian optimization [#] method for instantiating F well for a given dataset. The contribution of this paper is to extend this AutoML approach in various ways that considerably improve its efﬁciency and robustness based on principles that apply to a wide range of machine learning frameworks (such as those used by the machine learning service providers mentioned above). First following successful previous work for low dimensional optimization problems [# # #] we reason across datasets to identify instantiations of machine learning frameworks that perform well on a new dataset and warmstart Bayesian optimization with them (Section #.#). Second we automatically construct ensembles of the models considered by Bayesian optimization (Section #.#). Third we carefully design a highly parameterized machine learning framework from high-performing classiﬁers and preprocessors implemented in the popular machine learning framework scikit-learn [#] (Section #). Finally we perform an extensive empirical analysis using a diverse collection of datasets to demonstrate that the resulting AUTO-SKLEARN system outperforms previous state-of-the-art AutoML methods (Section #) to show that each of our contributions leads to substantial performance improvements (Section #) and to gain insights into the performance of the individual classiﬁers and preprocessors used in AUTO-SKLEARN (Section #). # AutoML as a CASH problem We ﬁrst review the formalization of AutoML as a Combined Algorithm Selection and Hyperparameter optimization (CASH) problem used by AUTO-WEKA’s AutoML approach. Two important problems in AutoML are that (#) no single machine learning method performs best on all datasets and (#) some machine learning methods (e.g. non-linear SVMs) crucially rely on hyperparameter optimization. The latter problem has been successfully attacked using Bayesian optimization [#] which nowadays forms a core component of an AutoML system. The former problem is intertwined with the latter since the rankings of algorithms depend on whether their hyperparameters are tuned properly. Fortunately the two problems can efﬁciently be tackled as a single structured joint optimization problem: Deﬁnition # (CASH). Let A = {A(#) . . . A(R)} be a set of algorithms and let the hyperparameters of each algorithm A(j) have domain Λ(j). Further let Dtrain = {(x# y#) . . . (xn yn)} be a train- ing set which is split into K cross-validation folds {D(#) train} such that D(i) valid) denote the loss that algorithm A(j) achieves on D(i) train with hyperparameters λ. Then the Combined Algorithm Selection and Hyperparameter optimization (CASH) problem is to ﬁnd the joint algorithm and hyperparameter setting that minimizes this loss: valid . . . D(K) valid for i = # . . . K. Finally let L(A(j) train = Dtrain\\D(i) valid} and {D(#) train D(i) λ D(i) valid when trained on D(i) train . . . D(K) K(cid:##) i=# A(cid:##) λ(cid:##) ∈ argmin A(j)∈A λ∈Λ(j) # K L(A(j) λ D(i) train D(i) valid). (#) This CASH problem was ﬁrst tackled by Thornton et al. [#] in the AUTO-WEKA system using the machine learning framework WEKA [#] and tree-based Bayesian optimization methods [# ##]. In a nutshell Bayesian optimization [#] ﬁts a probabilistic model to capture the relationship between hyperparameter settings and their measured performance; it then uses this model to select the most promising hyperparameter setting (trading off exploration of new parts of the space vs. exploitation in known good regions) evaluates that hyperparameter setting updates the model with the result and iterates. While Bayesian optimization based on Gaussian process models (e.g. Snoek et al. [##]) performs best in low-dimensional problems with numerical hyperparameters tree-based models have been shown to be more successful in high-dimensional structured and partly discrete problems [##] – such as the CASH problem – and are also used in the AutoML system HYPEROPT-SKLEARN [##]. Among the tree-based Bayesian optimization methods Thornton et al. [#] found the random-forest- based SMAC [#] to outperform the tree Parzen estimator TPE [##] and we therefore use SMAC to solve the CASH problem in this paper. Next to its use of random forests [##] SMAC’s main distinguishing feature is that it allows fast cross-validation by evaluating one fold at a time and discarding poorly-performing hyperparameter settings early. # Figure #: Our improved AutoML approach. We add two components to Bayesian hyperparameter optimization of an ML framework: meta-learning for initializing the Bayesian optimizer and automated ensemble construction from conﬁgurations evaluated during optimization. # New methods for increasing efﬁciency and robustness of AutoML We now discuss our two improvements of the AutoML approach. First we include a meta-learning step to warmstart the Bayesian optimization procedure which results in a considerable boost in efﬁciency. Second we include an automated ensemble construction step allowing us to use all classiﬁers that were found by Bayesian optimization. Figure # summarizes the overall AutoML workﬂow including both of our improvements. We note that we expect their effectiveness to be greater for ﬂexible ML frameworks that offer many degrees of freedom (e.g. many algorithms hyperparameters and preprocessing methods). #.# Meta-learning for ﬁnding good instantiations of machine learning frameworks Domain experts derive knowledge from previous tasks: They learn about the performance of machine learning algorithms. The area of meta-learning [##] mimics this strategy by reasoning about the performance of learning algorithms across datasets. In this work we apply meta-learning to select instantiations of our given machine learning framework that are likely to perform well on a new dataset. More speciﬁcally for a large number of datasets we collect both performance data and a set of meta-features i.e. characteristics of the dataset that can be computed efﬁciently and that help to determine which algorithm to use on a new dataset. This meta-learning approach is complementary to Bayesian optimization for optimizing an ML framework. Meta-learning can quickly suggest some instantiations of the ML framework that are likely to perform quite well but it is unable to provide ﬁne-grained information on performance. In contrast Bayesian optimization is slow to start for hyperparameter spaces as large as those of entire ML frameworks but can ﬁne-tune performance over time. We exploit this complementarity by selecting k conﬁgurations based on meta-learning and use their result to seed Bayesian optimization. This approach of warmstarting optimization by meta-learning has already been successfully applied before [# # #] but never to an optimization problem as complex as that of searching the space of instantiations of a full-ﬂedged ML framework. Likewise learning across datasets has also been applied in collaborative Bayesian optimization methods [## ##]; while these approaches are promising they are so far limited to very few meta-features and cannot yet cope with the high- dimensional partially discrete conﬁguration spaces faced in AutoML. More precisely our meta-learning approach works as follows. In an ofﬂine phase for each machine learning dataset in a dataset repository (in our case ### datasets from the OpenML [##] repository) we evaluated a set of meta-features (described below) and used Bayesian optimization to determine and store an instantiation of the given ML framework with strong empirical performance for that dataset. (In detail we ran SMAC [#] for ## hours with ##-fold cross-validation on two thirds of the data and stored the resulting ML framework instantiation which exhibited best performance on the remaining third). Then given a new dataset D we compute its meta-features rank all datasets by their L# distance to D in meta-feature space and select the stored ML framework instantiations for the k = ## nearest datasets for evaluation before starting Bayesian optimization with their results. To characterize datasets we implemented a total of ## meta-features from the literature including simple information-theoretic and statistical meta-features [## ##] such as statistics about the number of data points features and classes as well as data skewness and the entropy of the targets. All meta-features are listed in Table # of the supplementary material. Notably we had to exclude the prominent and effective category of landmarking meta-features [##] (which measure the performance of simple base learners) because they were computationally too expensive to be helpful in the online evaluation phase. We note that this meta-learning approach draws its power from the availability of # AutoMLsystemMLframework{Xtrain Ytrain Xtest b L}meta-learningdatapre-processorfeaturepreprocessorclassiﬁerbuildensembleˆYtestBayesianoptimizer a repository of datasets; due to recent initiatives such as OpenML [##] we expect the number of available datasets to grow ever larger over time increasing the importance of meta-learning. #.# Automated ensemble construction of models evaluated during optimization While Bayesian hyperparameter optimization is data-efﬁcient in ﬁnding the best-performing hyperpa- rameter setting we note that it is a very wasteful procedure when the goal is simply to make good predictions: all the models it trains during the course of the search are lost usually including some that perform almost as well as the best. Rather than discarding these models we propose to store them and to use an efﬁcient post-processing method (which can be run in a second process on-the-ﬂy) to construct an ensemble out of them. This automatic ensemble construction avoids to commit itself to a single hyperparameter setting and is thus more robust (and less prone to overﬁtting) than using the point estimate that standard hyperparameter optimization yields. To our best knowledge we are the ﬁrst to make this simple observation which can be applied to improve any Bayesian hyperparameter optimization method. It is well known that ensembles often outperform individual models [## ##] and that effective ensembles can be created from a library of models [## ##]. Ensembles perform particularly well if the models they are based on (#) are individually strong and (#) make uncorrelated errors [##]. Since this is much more likely when the individual models are different in nature ensemble building is particularly well suited for combining strong instantiations of a ﬂexible ML framework. However simply building a uniformly weighted ensemble of the models found by Bayesian optimiza- tion does not work well. Rather we found it crucial to adjust these weights using the predictions of all individual models on a hold-out set. We experimented with different approaches to optimize these weights: stacking [##] gradient-free numerical optimization and the method ensemble selection [##]. While we found both numerical optimization and stacking to overﬁt to the validation set and to be computationally costly ensemble selection was fast and robust. In a nutshell ensemble selection (introduced by Caruana et al. [##]) is a greedy procedure that starts from an empty ensemble and then iteratively adds the model that maximizes ensemble validation performance (with uniform weight but allowing for repetitions). Procedure # in the supplementary material describes it in detail. We used this technique in all our experiments – building an ensemble of size ##. # A practical automated machine learning system To design a robust AutoML system as our underlying ML framework we chose scikit-learn [#] one of the best known and most widely used machine learning libraries. It offers a wide range of well es- tablished and efﬁciently-implemented ML algorithms and is easy to use for both ex- perts and beginners. Since our AutoML system closely resembles AUTO-WEKA but – like HYPEROPT-SKLEARN – is based on scikit-learn we dub it AUTO-SKLEARN. Figure # depicts AUTO-SKLEARN’s overall components. It comprises ## classiﬁcation algorithms ## preprocessing methods and # data preprocessing methods. We param- eterized each of them which resulted in a space of ### hyperparameters. Most of these are conditional hyperparameters that are only active if their respective component is selected. We note that SMAC [#] can handle this conditionality natively. All ## classiﬁcation algorithms in AUTO-SKLEARN are listed in Table #a (and described in detail in Section A.# of the supplementary material). They fall into different categories such as general linear models (# algorithms) support vector machines (#) discriminant analysis (#) nearest neighbors (#) na¨ıve Bayes (#) decision trees (#) and ensembles (#). In contrast to AUTO-WEKA [#] we Figure #: Structured conﬁguration space. Squared boxes denote parent hyperparameters whereas boxes with rounded edges are leaf hyperparameters. Grey colored boxes mark active hyperparameters which form an example conﬁguration and machine learning pipeline. Each pipeline comprises one feature preprocessor classiﬁer and up to three data prepro- cessor methods plus respective hyperparameters. # datapreprocessorestimatorfeaturepreprocessorclassiﬁerAdaBoost···RFkNN#estimatorslearningratemax.depthpreprocessing···NonePCAfastICArescaling···min/maxstandardonehotenc.···imputationmean···medianbalancingweightingNone #λ name # AdaBoost (AB) Bernoulli na¨ıve Bayes # # decision tree (DT) # extreml. rand. trees Gaussian na¨ıve Bayes - # gradient boosting (GB) # kNN # LDA # linear SVM # kernel SVM multinomial na¨ıve Bayes # # passive aggressive # QDA # random forest (RF) Linear Class. (SGD) ## cat (cond) cont (cond) # (-) # (-) # (-) # (-) - - # (-) # (-) # (-) # (-) # (-) # (-) - # (-) # (-) # (-) # (-) # (-) # (-) - # (-) # (-) # (#) # (-) # (#) # (-) # (-) # (-) # (-) # (#) (a) classiﬁcation algorithms name #λ extreml. rand. trees prepr. # # fast ICA # feature agglomeration # kernel PCA rand. kitchen sinks # # linear SVM prepr. - no preprocessing # nystroem sampler # PCA # polynomial # random trees embed. select percentile # # select rates cat (cond) cont (cond) # (-) # (-) # () # (-) # (-) # (-) # (-) # (-) # (-) # (-) - - - # (-) # (#) # (-) # (#) # (-) # (-) - # (#) # (-) # (-) # (-) # (-) # (-) one-hot encoding imputation balancing rescaling # # # # # (-) # (-) # (-) # (-) # (#) - - - (b) preprocessing methods Table #: Number of hyperparameters for each possible classiﬁer (left) and feature preprocessing method (right) for a binary classiﬁcation dataset in dense representation. Tables for sparse binary classiﬁcation and sparse/dense multiclass classiﬁcation datasets can be found in the Section E of the supplementary material Tables #a #a #a #b #b and #b. We distinguish between categorical (cat) hyperparameters with discrete values and continuous (cont) numerical hyperparameters. Numbers in brackets are conditional hyperparameters which are only relevant when another parameter has a certain value. focused our conﬁguration space on base classiﬁers and excluded meta-models and ensembles that are themselves parameterized by one or more base classiﬁers. While such ensembles increased AUTO-WEKA’s number of hyperparameters by almost a factor of ﬁve (to ###) AUTO-SKLEARN “only” features ### hyperparameters. We instead construct complex ensembles using our post-hoc method from Section #.#. Compared to AUTO-WEKA this is much more data-efﬁcient: in AUTO- WEKA evaluating the performance of an ensemble with # components requires the construction and evaluation of # models; in contrast in AUTO-SKLEARN ensembles come largely for free and it is possible to mix and match models evaluated at arbitrary times during the optimization. The preprocessing methods for datasets in dense representation in AUTO-SKLEARN are listed in Table #b (and described in detail in Section A.# of the supplementary material). They comprise data preprocessors (which change the feature values and are always used when they apply) and feature preprocessors (which change the actual set of features and only one of which [or none] is used). Data preprocessing includes rescaling of the inputs imputation of missing values one-hot encoding and balancing of the target classes. The ## possible feature preprocessing methods can be categorized into feature selection (#) kernel approximation (#) matrix decomposition (#) embeddings (#) feature clustering (#) polynomial feature expansion (#) and methods that use a classiﬁer for feature selection (#). For example L#-regularized linear SVMs ﬁtted to the data can be used for feature selection by eliminating features corresponding to zero-valued model coefﬁcients. As with every robust real-world system we had to handle many more important details in AUTO- SKLEARN; we describe these in Section B of the supplementary material. # Comparing AUTO-SKLEARN to AUTO-WEKA and HYPEROPT-SKLEARN As a baseline experiment we compared the performance of vanilla AUTO-SKLEARN (without our improvements) to AUTO-WEKA and HYPEROPT-SKLEARN reproducing the experimental setup with ## datasets of the paper introducing AUTO-WEKA [#]. We describe this setup in detail in Section G in the supplementary material. Table # shows that AUTO-SKLEARN performed statistically signiﬁcantly better than AUTO-WEKA in #/## cases tied it in ## cases and lost against it in #. For the three datasets where AUTO- WEKA performed best we found that in more than ##% of its runs the best classiﬁer it chose is not implemented in scikit-learn (trees with a pruning component). So far HYPEROPT-SKLEARN is more of a proof-of-concept – inviting the user to adapt the conﬁguration space to her own needs – than a full AutoML system. The current version crashes when presented with sparse data and missing values. It also crashes on Cifar-## due to a memory limit which we set for all optimizers to enable a # e n o l a b A n o z a m A # # - r a f i C r a C # # - r a f i C l l a m S x e v n o C r e t x e D a e h t o r o D n a m r e G t i d e r C e t t e s i G ##.## ##.## #.## AS AW ##.## ##.## #.## HS ##.## ##.## #.## ##.## ##.## ##.## #.## ##.## ##.## ##.## #.## - ##.## ##.## - #.## #.## - ##.## #.## ##.## #.## ##.## #.## # # D D K y c n e t e p p A #.## #.## - P K - s v - R K n o l e d a M T S I N M c i s a B I B R M m o c e S n o i e m e S e l t t u h S m r o f e v a W y t i l a u Q e n i W t s a e Y #.## #.## #.## ##.## #.## ##.## #.## ##.## #.## ##.## #.## ##.## #.## ##.## - #.## #.## #.## #.## #.## #.## ##.## ##.## ##.## ##.## ##.## ##.## ##.## ##.## ##.## Table #: Test set classiﬁcation error of AUTO-WEKA (AW) vanilla AUTO-SKLEARN (AS) and HYPEROPT- SKLEARN (HS) as in the original evaluation of AUTO-WEKA [#]. We show median percent error across ### ### bootstrap samples (based on ## runs) simulating # parallel runs. Bold numbers indicate the best result. Underlined results are not statistically signiﬁcantly different from the best according to a bootstrap test with p = #.##. Figure #: Average rank of all four AUTO-SKLEARN variants (ranked by balanced test error rate (BER)) across ### datasets. Note that ranks are a relative measure of performance (here the rank of all methods has to add up to ##) and hence an improvement in BER of one method can worsen the rank of another. The supplementary material shows the same plot on a log-scale to show the time overhead of meta-feature and ensemble computation. fair comparison. On the ## datasets on which it ran it statistically tied the best optimizer in # cases and lost against it in #. # Evaluation of the proposed AutoML improvements In order to evaluate the robustness and general applicability of our proposed AutoML system on a broad range of datasets we gathered ### binary and multiclass classiﬁcation datasets from the OpenML repository [##] only selecting datasets with at least #### data points to allow robust performance evaluations. These datasets cover a diverse range of applications such as text classiﬁ- cation digit and letter recognition gene sequence and RNA classiﬁcation advertisement particle classiﬁcation for telescope data and cancer detection in tissue samples. We list all datasets in Table # and # in the supplementary material and provide their unique OpenML identiﬁers for reproducibility. Since the class distribution in many of these datasets is quite imbalanced we evaluated all AutoML methods using a measure called balanced classiﬁcation error rate (BER). We deﬁne balanced error rate as the average of the proportion of wrong classiﬁcations in each class. In comparison to standard classiﬁcation error (the average overall error) this measure (the average of the class-wise error) assigns equal weight to all classes. We note that balanced error or accuracy measures are often used in machine learning competitions (e.g. the AutoML challenge [#] uses balanced accuracy). We performed ## runs of AUTO-SKLEARN both with and without meta-learning and with and without ensemble prediction on each of the datasets. To study their performance under rigid time constraints and also due to computational resource constraints we limited the CPU time for each run to # hour; we also limited the runtime for a single model to a tenth of this (# minutes). To not evaluate performance on data sets already used for meta-learning we performed a leave-one-dataset-out validation: when evaluating on dataset D we only used meta-information from the ### other datasets. Figure # shows the average ranks over time of the four AUTO-SKLEARN versions we tested. We observe that both of our new methods yielded substantial improvements over vanilla AUTO-SKLEARN. The most striking result is that meta-learning yielded drastic improvements starting with the ﬁrst # ###########################time [sec]#.##.##.##.##.##.##.#average rankvanilla auto-sklearnauto-sklearn + ensembleauto-sklearn + meta-learningauto-sklearn + meta-learning + ensemble D I t e s a t a d L M n e p O ## ## ### ### ### ### ### #### #### #### #### ### ### N R A E L K S - O T U A #.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## #.## ##.## t s o o B a d A #.## #.## ##.## ##.## #.## ##.## #.## ##.## ##.## ##.## #.## #.## ##.## s e y a B e v ¨ı a n i l l u o n r e B ##.## - ##.## - - ##.## ##.## ##.## ##.## ##.## #.## ##.## - n o i s i c e d e e r t #.## #.## ##.## ##.## ##.## ##.## ##.## ##.## ##.## ##.## #.## #.## ##.## s e e r t . d n a r . l m e r t x e ##.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## #.## ##.## s e y a B e v ¨ı a n n a i s s u a G ##.## #.## ##.## ##.## ##.## ##.## ##.## ##.## ##.## ##.## #.## ##.## ##.## t n e i d a r g g n i t s o o b #.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## ##.## ##.## N N k A D L ##.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## #.## ##.## #.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## ##.## ##.## M V S r a e n i l ##.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## ##.## ##.## M V S l e n r e k ##.## #.## ##.## ##.## #.## ##.## #.## ##.## ##.## ##.## #.## ###.## ##.## l a i m o n i t l u m s e y a B e v ¨ı a n ##.## #.## ##.## ##.## ##.## ##.## ##.## ##.## ##.## ##.## #.## ##.## ##.## e v i s e r g g a e v i s s a p ##.## #.## ##.## ##.## ###.## ##.## ##.## ##.## ##.## ##.## #.## ##.## ##.## A D Q #.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## ##.## ##.## t s e r o f m o d n a r #.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## #.## ##.## . s s a l C r a e n i L ) D G S ( ##.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## ##.## ##.## Table #: Median balanced test error rate (BER) of optimizing AUTO-SKLEARN subspaces for each classiﬁcation method (and all preprocessors) as well as the whole conﬁguration space of AUTO-SKLEARN on ## datasets. All optimization runs were allowed to run for ## hours except for AUTO-SKLEARN which ran for ## hours. Bold numbers indicate the best result; underlined results are not statistically signiﬁcantly different from the best according to a bootstrap test using the same setup as for Table #. D I t e s a t a d L M n e p O ## ## ### ### ### ### ### #### #### #### #### ### ### N R A E L K S - O T U A #.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## #.## ##.## r e ﬁ i s n e d - - - - - - - - - - - ##.## ##.## . d n a r . l m e r t x e . r p e r p s e e r t #.## #.## ##.## ##.## #.## ##.## #.## ##.## ##.## ##.## #.## #.## ##.## n o i t a r e m o l g g a e r u t a e f #.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## - - A C I t s a f #.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## - - A C P l e n r e k #.## #.## ###.## ##.## ###.## ##.## ##.## ##.## ###.## ##.## #.## ###.## ##.## s k n i s n e h c t i k . d n a r #.## #.## ##.## ##.## ###.## ##.## ##.## ##.## ##.## ##.## #.## ##.## ##.## . r p e r p M V S r a e n i l #.## #.## ##.## #.## #.## ##.## #.## ##.## ##.## ##.## #.## #.## ##.## . c o r p e r p o n #.## #.## ##.## ##.## #.## ##.## #.## ##.## ##.## ##.## #.## #.## ##.## m e o r t s y n r e l p m a s #.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## ##.## ##.## l a i m o n y l o p #.## #.## ##.## ##.## ###.## ##.## #.## ##.## ##.## ##.## ##.## - - A C P #.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## - - e l i t n e c r e p t c e l e s n o i t a c ﬁ i s s a l c . d e b m e s e e r t m o d n a r ##.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## #.## ##.## #.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## #.## ##.## D V S d e t a c n u r t - - - - - - - - - - - #.## ##.## s e t a r t c e l e s #.## #.## ##.## ##.## #.## ##.## ##.## ##.## ##.## ##.## #.## #.## ##.## Table #: Like Table # but instead optimizing subspaces for each preprocessing method (and all classiﬁers). conﬁguration it selected and lasting until the end of the experiment. We note that the improvement was most pronounced in the beginning and that over time vanilla AUTO-SKLEARN also found good solutions without meta-learning letting it catch up on some datasets (thus improving its overall rank). Moreover both of our methods complement each other: our automated ensemble construction improved both vanilla AUTO-SKLEARN and AUTO-SKLEARN with meta-learning. Interestingly the ensemble’s inﬂuence on the performance started earlier for the meta-learning version. We believe that this is because meta-learning produces better machine learning models earlier which can be directly combined into a strong ensemble; but when run longer vanilla AUTO-SKLEARN without meta-learning also beneﬁts from automated ensemble construction. # Detailed analysis of AUTO-SKLEARN components We now study AUTO-SKLEARN’s individual classiﬁers and preprocessors compared to jointly optimizing all methods in order to obtain insights into their peak performance and robustness. Ideally we would have liked to study all combinations of a single classiﬁer and a single preprocessor in isolation but with ## classiﬁers and ## preprocessors this was infeasible; rather when studying the performance of a single classiﬁer we still optimized over all preprocessors and vice versa. To obtain a more detailed analysis we focused on a subset of datasets but extended the conﬁguration budget for optimizing all methods from one hour to one day and to two days for AUTO-SKLEARN. Speciﬁcally we clustered our ### datasets with g-means [##] based on the dataset meta-features and used one dataset from each of the resulting ## clusters (see Table # in the supplementary material for the list of datasets). We note that in total these extensive experiments required ##.# CPU years. Table # compares the results of the various classiﬁcation methods against AUTO-SKLEARN. Overall as expected random forests extremely randomized trees AdaBoost and gradient boosting showed # (a) MNIST (OpenML dataset ID ###) (b) Promise pc# (OpenML dataset ID ####) Figure #: Performance of a subset of classiﬁers compared to AUTO-SKLEARN over time. We show median test error rate and the ﬁfth and ##th percentile over time for optimizing three classiﬁers separately with optimizing the joint space. A plot with all classiﬁers can be found in Figure # in the supplementary material. While AUTO-SKLEARN is inferior in the beginning in the end its performance is close to the best method. the most robust performance and SVMs showed strong peak performance for some datasets. Besides a variety of strong classiﬁers there are also several models which could not compete: The decision tree passive aggressive kNN Gaussian NB LDA and QDA were statistically signiﬁcantly inferior to the best classiﬁer on most datasets. Finally the table indicates that no single method was the best choice for all datasets. As shown in the table and also visualized for two example datasets in Figure # optimizing the joint conﬁguration space of AUTO-SKLEARN led to the most robust performance. A plot of ranks over time (Figure # and # in the supplementary material) quantiﬁes this across all ## datasets showing that AUTO-SKLEARN starts with reasonable but not optimal performance and effectively searches its more general conﬁguration space to converge to the best overall performance over time. Table # compares the results of the various preprocessors against AUTO-SKLEARN. As for the comparison of classiﬁers above AUTO-SKLEARN showed the most robust performance: It performed best on three of the datasets and was not statistically signiﬁcantly worse than the best preprocessor on another # of ##. # Discussion and Conclusion We demonstrated that our new AutoML system AUTO-SKLEARN performs favorably against the previous state of the art in AutoML and that our meta-learning and ensemble improvements for AutoML yield further efﬁciency and robustness. This ﬁnding is backed by the fact that AUTO- SKLEARN won the auto-track in the ﬁrst phase of ChaLearn’s ongoing AutoML challenge. In this paper we did not evaluate the use of AUTO-SKLEARN for interactive machine learning with an expert in the loop and weeks of CPU power but we note that that mode has also led to a third place in the human track of the same challenge. As such we believe that AUTO-SKLEARN is a promising system for use by both machine learning novices and experts. The source code of AUTO-SKLEARN is available under an open source license at Our system also has some shortcomings which we would like to remove in future work. As one example we have not yet tackled regression or semi-supervised problems. Most importantly though the focus on scikit-learn implied a focus on small to medium-sized datasets and an obvious direction for future work will be to apply our methods to modern deep learning systems that yield state-of- the-art performance on large datasets; we expect that in that domain especially automated ensemble construction will lead to tangible performance improvements over Bayesian optimization. Acknowledgments This work was supported by the German Research Foundation (DFG) under Priority Programme Autonomous Learning (SPP #### grant HU ####/#-#) under Emmy Noether grant HU ####/#-# and under the BrainLinks- BrainTools Cluster of Excellence (grant number EXC ####). # ############time [sec]#######Balanced Error Rateauto-sklearngradient boostingkernel SVMrandom forest############time [sec]################Balanced Error Rateauto-sklearngradient boostingkernel SVMrandom forest References [#] I. Guyon K. Bennett G. Cawley H. Escalante S. Escalera T. Ho N.Maci`a B. Ray M. Saeed A. Statnikov and E. Viegas. Design of the #### ChaLearn AutoML Challenge. In Proc. of IJCNN’## ####. [#] C. Thornton F. Hutter H. Hoos and K. Leyton-Brown. Auto-WEKA: combined selection and hyperpa- rameter optimization of classiﬁcation algorithms. In Proc. of KDD’## pages ###–### ####. [#] E. Brochu V. Cora and N. de Freitas. A tutorial on Bayesian optimization of expensive cost functions with application to active user modeling and hierarchical reinforcement learning. CoRR abs/####.#### ####. [#] M. Feurer J. Springenberg and F. Hutter. Initializing Bayesian hyperparameter optimization via meta- learning. In Proc. of AAAI’## pages ####–#### ####. [#] Reif M F. Shafait and A. Dengel. Meta-learning for evolutionary parameter optimization of classiﬁers. Machine Learning ##:###–### ####. [#] T. Gomes R. Prudˆencio C. Soares A. Rossi and A. Carvalho. Combining meta-learning and search techniques to select parameters for support vector machines. Neurocomputing ##(#):#–## ####. [#] F. Pedregosa G. Varoquaux A. Gramfort V. Michel B. Thirion O. Grisel M. Blondel P. Prettenhofer R. Weiss V. Dubourg J. Vanderplas A. Passos D. Cournapeau M. Brucher M. Perrot and E. Duchesnay. Scikit-learn: Machine learning in Python. JMLR ##:####–#### ####. [#] M. Hall E. Frank G. Holmes B. Pfahringer P. Reutemann and I. Witten. The WEKA data mining software: An update. SIGKDD ##(#):##–## ####. [#] F. Hutter H. Hoos and K. Leyton-Brown. Sequential model-based optimization for general algorithm conﬁguration. In Proc. of LION’## pages ###–### ####. [##] J. Bergstra R. Bardenet Y. Bengio and B. K´egl. Algorithms for hyper-parameter optimization. In Proc. of NIPS’## pages ####–#### ####. [##] J. Snoek H. Larochelle and R. P. Adams. Practical Bayesian optimization of machine learning algorithms. In Proc. of NIPS’## pages ####–#### ####. [##] K. Eggensperger M. Feurer F. Hutter J. Bergstra J. Snoek H. Hoos and K. Leyton-Brown. Towards an empirical foundation for assessing Bayesian optimization of hyperparameters. In NIPS Workshop on Bayesian Optimization in Theory and Practice ####. [##] B. Komer J. Bergstra and C. Eliasmith. Hyperopt-sklearn: Automatic hyperparameter conﬁguration for scikit-learn. In ICML workshop on AutoML ####. [##] L. Breiman. Random forests. MLJ ##:#–## ####. [##] P. Brazdil C. Giraud-Carrier C. Soares and R. Vilalta. Metalearning: Applications to Data Mining. Springer ####. [##] R. Bardenet M. Brendel B. K´egl and M. Sebag. Collaborative hyperparameter tuning. In Proc. of ICML’## [##] pages ###–###. [##] D. Yogatama and G. Mann. Efﬁcient transfer learning method for automatic hyperparameter tuning. In Proc. of AISTATS’## pages ####–#### ####. [##] J. Vanschoren J. van Rijn B. Bischl and L. Torgo. OpenML: Networked science in machine learning. SIGKDD Explorations ##(#):##–## ####. [##] D. Michie D. Spiegelhalter C. Taylor and J. Campbell. Machine Learning Neural and Statistical Classiﬁcation. Ellis Horwood ####. [##] A. Kalousis. Algorithm Selection via Meta-Learning. PhD thesis University of Geneve ####. [##] B. Pfahringer H. Bensusan and C. Giraud-Carrier. Meta-learning by landmarking various learning algorithms. In Proc. of (ICML’##) pages ###–### ####. [##] I. Guyon A. Saffari G. Dror and G. Cawley. Model selection: Beyond the Bayesian/Frequentist divide. JMLR ##:##–## ####. [##] A. Lacoste M. Marchand F. Laviolette and H. Larochelle. Agnostic Bayesian learning of ensembles. In Proc. of ICML’## pages ###–### ####. [##] R. Caruana A. Niculescu-Mizil G. Crew and A. Ksikes. Ensemble selection from libraries of models. In Proc. of ICML’## page ## ####. [##] R. Caruana A. Munson and A. Niculescu-Mizil. Getting the most out of ensemble selection. In Proc. of ICDM’## pages ###–### ####. [##] D. Wolpert. Stacked generalization. Neural Networks #:###–### ####. [##] G. Hamerly and C. Elkan. Learning the k in k-means. In Proc. of NIPS’## pages ###–### ####. [##] Proc. of ICML’## ####. #\n",
            "response:  The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning (AutoML) problem with the help of efficient Bayesian optimization methods.\n",
            "summarize: Learning Networks of Heterogeneous Inﬂuence Nan Du∗ Le Song∗ Alex Smola† Ming Yuan∗ Georgia Institute of Technology∗ Google Research† dunan@gatech.edu lsong@cc.gatech.edu alex@smola.org myuan@isye.gatech.edu Abstract Information disease and inﬂuence diffuse over networks of entities in both nat- ural systems and human society. Analyzing these transmission networks plays an important role in understanding the diffusion processes and predicting future events. However the underlying transmission networks are often hidden and in- complete and we observe only the time stamps when cascades of events happen. In this paper we address the challenging problem of uncovering the hidden net- work only from the cascades. The structure discovery problem is complicated by the fact that the inﬂuence between networked entities is heterogeneous which can not be described by a simple parametric model. Therefore we propose a kernel- based method which can capture a diverse range of different types of inﬂuence without any prior assumption. In both synthetic and real cascade data we show that our model can better recover the underlying diffusion network and drastically improve the estimation of the transmission functions among networked entities. Introduction # Networks have been powerful abstractions for modeling a variety of natural and artiﬁcial systems that consist of a large collection of interacting entities. Due to the recent increasing availability of large-scale networks network modeling and analysis have been extensively applied to study the spreading and diffusion of information ideas and even virus in social and information net- works (see e.g. [## # ## # #]). However the process of inﬂuence and diffusion often occurs in a hidden network that might not be easily observed and identiﬁed directly. For instance when a disease spreads among people epidemiologists can know only when a person gets sick but they can hardly ever know where and from whom he (she) gets infected. Similarly when consumers rush to buy some particular products marketers can know when purchases occurred but they cannot track in further where the recommendations originally came from [##]. In all such cases we could observe only the time stamp when a piece of information has been received by a particular entity but the exact path of diffusion is missing. Therefore it is an interesting and challenging question whether we can uncover the diffusion paths based just on the time stamps of the events. There are many recent studies on estimating correlation or causal structures from multivariate time- series data (see e.g. [# # ##]). However in these models time is treated as discrete index and not modeled as a random variable. In the diffusion network discovery problem time is treated explic- itly as a continuous variable and one is interested in capturing how the occurrence of event at one node affects the time for its occurence at other nodes. This problem recently has been explored by a number of studies in the literature. Speciﬁcally Meyers and Leskovec inferred the diffusion net- work by learning the infection probability between two nodes using a convex programming called CONNIE [##]. Gomez-Rodriguez et al. inferred the network connectivity using a submodular opti- mization called NETINF [#]. However both CONNIE and NETINF assume that the transmission model for each pair of nodes is ﬁxed with predeﬁned transmission rate. Recently Gomez-Rodriguez et al. proposed an elegant method called NETRATE [#] using continuous temporal dynamics model to allow variable diffusion rates across network edges. NETRATE makes fewer number of assumptions and achieves better performance in various aspects than the previous two approaches. However the limitation of NETRATE is that it requires the inﬂuence model on each edge to have a # (a) Pair # (b) Pair # (c) Pair # Figure #: The histograms of the interval between the time when a post appeared in one site and the time when a new post in another site links to it. Dotted and dash lines are density ﬁtted by NETRATE. The solid lines are given by KernelCascade. ﬁxed parametric form such as exponential power-law or Rayleigh distribution although the model parameters learned from cascades could be different. In practice the patterns of information diffusion (or a spreading disease) among entities can be quite complicated and different from each other going far beyond what a single family of parametric models can capture. For example in twitter an active user can be online for more than ## hours a day and he may instantly respond to any interesting message. However an inactive user may just log in and respond once a day. As a result the spreading pattern of the messages between the active user and his friends can be quite different from that of the inactive user. Another example is from the information diffusion in a blogsphere: the hyperlinks between posts can be viewed as some kind of information ﬂow from one media site to another and the time difference between two linked posts reveal the pattern of diffusion. In Figure # we examined three pairs of media sites from the MemeTracker dataset [# #] and plotted the histograms of the intervals between the the moment when a post ﬁrst appeared in one site and the moment when it was linked by a new post in another site. We can observe that information can have very different transmission patterns for these pairs. Parametric models ﬁtted by NETRATE may capture the simple pattern in Figure #(a) but they might miss the multimodal patterns in Figure #(b) and Figure #(c). In contrast our method called KernelCascade is able to ﬁt both data accurately and thus can handle the heterogeneity. In the reminder of this paper we present the details of our approach KernelCascade. Our key idea is to model the continuous information diffusion process using survival analysis by kernelizing the hazard function. We obtain a convex optimization problem with grouped lasso type of regularization and develop a fast block-coordinate descent algorithm for solving the problem. The sparsity patterns of the coefﬁcients provide us the structure of the diffusion network. In both synthetic and real world data our method can better recover the underlying diffusion networks and drastically improve the estimation of the transmission functions among networked entities. # Preliminary In this section we will present some basic concepts from survival analysis [# #] which are essential for our later modeling. Given a nonnegative random variable T corresponding to the time when an # f (x)dx be its cumulative distribution function. The probability that an event does not happen up to time t is thus given by the survival function S(t) = P r(T ≥ t) = # − F (t). The survival function is a continuous and monotonically decreasing function with S(#) = # and S(∞) = limt→∞ S(t) = #. Given f (t) and S(t) we can deﬁne the instantaneous risk (or rate) that an event has not happened yet up to time t but happens at time t by the hazard function event happens let f (t) be the probability density function of T and F (t) = P r(T ≤ t) =(cid:##) t P r(t ≤ T ≤ t + ∆t|T ≥ t) h(t) = lim ∆t→# ∆t = f (t) S(t) . (#) With this deﬁnition h(t)∆t will be the approximate probability that an event happens in [t t + ∆t) given that the event has not happened yet up to t. Furthermore the hazard function h(t) is also related to the survival function S(t) via the differential equation h(t) = − d dt log S(t) where we have used f (t) = −S(cid:##)(t). Solving the differential equation with boundary condition S(#) = # we can recover the survival function S(t) and the density function f (t) based on the hazard function h(t) i.e. S(t) = exp h(x) dx and f (t) = h(t) exp h(x) dx . (#) (cid:##) t (cid:##) − (cid:##) (cid:##) t (cid:##) − (cid:##) # # # #############.##.##.#t(hours)pdf histogramexprayleighKernelCascade#######.###.###.###.###.#t(hours)pdf histogramexprayleighKernelCascade########.###.###.###.###.#t(hours)pdf histogramexprayleighKernelCascade (a) Hidden network (b) Node e gets infected at time t# (c) Node e survives Figure #: Cascades over a hidden network. Solid lines in panel(a) represent connections in a hidden network. In panel (b) and (c) ﬁlled circles indicate infected nodes while empty circles represent uninfected ones. Node a b c and d are the parents of node e which got infected at t# < t# < t# < t# respectively and tended to infect node e. In panel (b) node e survives given node a b and c shown in green dash lines. However it was infected by node d. In panel (c) node e survives even though all its parents got infected. # Modeling Cascades using Survival Analysis We use survival analysis to model information diffusion for networked entities. We will largely follow the presentation of Gomez-Rodriguez et al. [#] but add clariﬁcation when necessary. We assume that there is a ﬁxed population of N nodes connected in a directed network G = (V E). Neighboring nodes are allowed to directly inﬂuence each other. Nodes along a directed path may inﬂuence each other only through a diffusion process. Because the true underlying network is un- known our observations are only the time stamps when events occur to each node in the network. The time stamps are then organized as cascades each of which corresponds to a particular event. For instance a piece of news posted on CNN website about “Facebook went public” can be treated as an event. It can spread across the blogsphere and trigger a sequence of posts from other sites referring to it. Each site will have a time stamp when this particular piece of news is being discussed and cited. The goal of the model is to capture the interplay between the hidden diffusion network and the cascades of observed event time stamps. More formally a directed edge j → i is associated with an transmission function fji(ti|tj) which is the conditional likelihood of an event happening to node i at time ti given that the same event has already happened to node j at time tj. The transmission function attempts to capture the temporal dependency between the two successive events for node i and j. In addition we focus on shift- invariant transmission functions whose value only depends on the time difference i.e. fji(ti|tj) = fji(ti − tj) = fji(∆ji) where ∆ji := ti − tj. Given the likelihood function we can compute the corresponding survival function Sji(∆ji) and hazard function hji(∆ji). When there is no directed edge j → i the transmission function and hazard function are both identically zeros i.e. fji(∆ji) = # and hji(∆ji) = # but the survival function is identically one i.e. Sji(∆ji) = #. Therefore the structure of the diffusion network is reﬂected in the non-zero patterns of a collection of transmission functions (or hazard functions). N )(cid:##) with i-th dimension recording the time A cascade is an N-dimensional vector tc := (tc # . . . tc i ∈ [# T c] ∪ {∞} and the symbol ∞ labels stamp when event c occurs to node i. Furthermore tc nodes that have not been inﬂuenced during observation window [# T c] — it does not imply that nodes are never inﬂuenced. The ‘clock’ is set to # at the start of each cascade. A dataset can contain a collection C of cascades(cid:#)t# . . . t|C|(cid:#). The time stamps assigned to nodes by a cascade induce a directed acyclic graph (DAG) by deﬁning node j as the parent of i if tj < ti. Thus it is meaningful to refer to parents and children within a cascade [#] which is different from the parent-child structural relation on the true underlying diffusion network. Since the true network is inferred from many cascades (each of which imposes its own DAG structure) the inferred network is typically not a DAG. The likelihood (cid:##)(tc) of a cascade induced by event c is then simply a product of all individual likelihood (cid:##)i(tc) that event c occurs to each node i. Depending on whether event c actually occurs to node i in the data we can compute this individual likelihood as: Event c did occur at node i. We assume that once an event occurs at node i under the inﬂuence of a particular parent j in a cascade the same event will not happen again. In Figure #(b) node e is susceptible given its parent a b c and d. However only node d is the ﬁrst parent who infects node e. Because each parent could be equally likely to ﬁrst inﬂuence node i the likelihood is just a simple sum over the likelihoods of the mutually disjoint events that node i has survived from the inﬂuence of all the other parents except the ﬁrst parent j i.e. Ski(∆c (cid:##) (cid:##) (cid:##) (cid:##) Ski(∆c ki). hji(∆c ji) ki) = (cid:##)+ i (tc) = fji(∆c ji) j:tc j <tc i k:k(cid:##)=j tc k<tc i (#) j:tc j <tc i k:tc k<tc i # a b c d e t# t# t# t# t# a b c d e t# t# t# t# a b c d e Event c did not occur at node i. In other words node i survives from the inﬂuence of all par- ents (see Figure #(c) for illustration). The likelihood is a product of survival functions i.e. Combining the above two scenarios together we can obtain the overall likelihood of a cascade tc by multiplying together all individual likelihoods i.e. (cid:##)− i (tc) (cid:##)+ i (tc) (cid:##)(tc) = (#) . (cid:##) tj≤T c (cid:##)− i (tc) = Sji(T c − tj). (cid:##) (cid:###) tc i >T c (cid:###)(cid:###) uninfected nodes × (cid:##) (cid:###) (cid:###) (cid:###)(cid:###) i≤T c tc infected nodes (cid:###) (#)  (#) the likelihood of all cascades is a product of the these individual cascade likeli- c=# . |C| (cid:##)(tc). In the end we take the negative log of this likeli- hood function and regroup all terms associated with edges pointing to node i together to derive Therefore hoods i.e. (cid:##)({t# . . . t|C|}) =(cid:##) (cid:##) L({t# . . . t|C|}) = −(cid:##) (cid:##) (cid:##) (cid:##) i j {c|tc i} j <tc log S(∆c ji) + log {c|tc i (cid:##)T c} i} {tc j <tc h(∆c ji) There are two interesting implications from this negative log likelihood function. First the function can be expressed using only the hazard and the survival function. Second the function is decom- posed into additive contribution from each node i. We can therefore estimate the hazard and survival function for each node separately. Previously Gomez-Rodriguez et al. [#] used parametric hazard and survival functions and they estimated the model parameters using the convex programming. In contrast we will instead formulate an algorithm using kernels and grouped parameter regularization which allows us to estimate complicated hazard and survival functions without overﬁtting. # KernelCascade for Learning Diffusion Networks This section presents our kernel method for uncovering diffusion networks from cascades. Our key idea is to kernelize the hazard function used in the negative log-likelihood in (#) and then estimate the parameters using grouped lasso type of optimization. #.# Kernelizing survival analysis Kernel methods are powerful tools for generalizing classical linear learning approaches to analyze nonlinear relations. A kernel function k : X × X → R is a real-valued positive deﬁnite symmetric function iff. for any set of points {τ# τ# . . . τm} ∈ X the kernel matrix K with entris Kls := k(τl τs) is positive deﬁnite. We want to model heterogeneous transmission functions fji(∆ji) from j to i. Rather than directly kernelizing the transmission function we kernelize the hazard function instead by assuming that it is a linear combination of m kernel functions i.e. αl hji(∆ji) = ji . . . αm jik(τl ∆ji) (#) where we ﬁx one argument of each kernel function k(τl ·) to a point τl in a uniform grid of m locations in the range of (# maxc T c]. To achieve fully nonparametric modeling of the hazard function we can let m grow as we see more cascades. Alternatively we can also place a non- linear basis function on each time point in the observed cascades. For efﬁciency consideration we will use a ﬁxed uniform grid in our later experiments. Since the hazard function is always positive we use positive kernel functions and require the weights to be positive i.e. k(· ·) ≥ # ji ≥ # to capture such constraint. For simplicity of notation we will deﬁne vectors αji := and αl ji )(cid:##) and k(∆ji) := (k(τ# ∆ji) . . . k(τm ∆ji))(cid:##). Hence the hazard function can be (α# written as hji(∆ji) = α(cid:##) In addition the survival function and likelihood function can also be kernelized based on their k(τl x)dx respective relation with the hazard function in (#). More speciﬁcally let gl(∆ji) :=(cid:##) ∆ji Sji(∆ji) = exp(cid:#)−α(cid:##) jik(∆ji)(cid:#) exp(cid:#)−α(cid:##) and the corresponding vector g(∆ji) := (g#(∆ji) . . . gm(∆ji))(cid:##). We then can derive (#) In the formulation we need to perform integration over the kernel function to compute gl(∆ji). This can be done efﬁciently for many kernels such as the Gaussian RBF kernel the Laplacian kernel the Quartic kernel and the Triweight kernel. In later experiments we mainly focus on the Gaussian fji(∆ji) =(cid:#)α(cid:##) jig(∆ji)(cid:#) . jig(∆ji)(cid:#) jik(∆ji). and # m(cid:##) l=# # (cid:##) (cid:##)(cid:##) (cid:##) τl√ (cid:##) τl − ∆ji√ (cid:##) (cid:##) ∆ji (cid:##) ∞ t e−x# # π #σ √ erfc #πσ # − erfc k(τl x) dx = RBF kernel k(τl τs) = exp(−(cid:###)τl − τs(cid:###)#/(#σ#)) and derive a closed form solution for gl(∆ji) as (#) gl(∆ji) = where erfc(t) := #√ dx is the error function. Yet our method is not limited to the particu- lar RBF kernel. If there is no closed form solution for the one-dimensional integration we can use a large number of available numerical integration methods for this purpose [##]. We note that given a dataset both the vector k(∆ji) and g(∆ji) need to be computed only once as a preprocessing and then can be reused in the algorithm. #.# Estimating sparse diffusion networks Next we plug in the kernelized hazard function and survival function into the likelihood of cascades in (#). Since the negative log likelihood is separable for each node i we can optimize the set of variables {αji}N j=# separately. As a result the negative log likelihood for the data associated with node i can be estimated as #σ (cid:#){αji}N j=# (cid:##) (cid:#) = Li (cid:##) ji) − (cid:##) α(cid:##) jig(∆c α(cid:##) jik(∆c ji). (##) (cid:##) j {c|tc i} j <tc log {c|tc i (cid:##)T c} i} {tc j <tc A desirable feature of this function is that it is convex in its arguments {αji}N to bring various convex optimization tools to solve the problem efﬁciently. In addition we want to induce a sparse network structure from the data and avoid overﬁtting. Basically if the coefﬁcients αji = # then there is no edge (or direct inﬂuence) from node j to i. For this purpose we will impose grouped lasso type of regularization on the coefﬁcients j (cid:###)αji(cid:###))# [## ##]. Grouped lasso type of regularization has the tendency to select a small number of groups of non-zero coefﬁcients but push other groups of coefﬁcients to be zero. Overall the optimization problem trades off between the data likelihood term and the group sparsity of the coefﬁcients αji i.e. ((cid:##) j=# which allows us (cid:#){αji}N j=# (cid:##)(cid:##) (cid:#) + λ (cid:###)αji(cid:###)(cid:##)# Li s.t. αji ≥ # ∀j (##) min {αji}N j=# j where λ is the regularization parameter. After we obtain a sparse solution from the above opti- mization we obtain partial network structures each of which centers around a particular node i. We can then join all the partial structures together and obtain the overall diffusion network. The corresponding hazard function along each edge can also be obtained from (#). #.# Optimization We note that (##) is a nonsmooth optimization problem because of the regularizer. There are many ways to solve the optimization problem and we will illustrate this using a simple algo- rithm originating from multiple kernel learning [## ##]. In this approach an additional set of variables are introduced to turn the optimization problem into a smooth optimization problem. j γj = #. Then using Cauchy-Schwartz inequality we have j (cid:###)αji(cid:###)# /γj where More speciﬁcally let γi ≥ # and(cid:##) ((cid:##) j (cid:###)αji(cid:###))# = ((cid:##) j γj) = (cid:##) )# ≤ ((cid:##) j((cid:###)αji(cid:###) /γ#/# )γ#/# j j the equality holds when j (cid:###)αji(cid:###)# /γj)((cid:##) (cid:##) (cid:###)αji(cid:###) . (##) With these additional variables γj we can solve an alternative smooth optimization problem which is jointly convex in both αji and γj j γj = (cid:###)αji(cid:###) / (cid:#){αji}N j=# (cid:#) + λ (cid:##) Li (cid:###)αji(cid:###)# γj min {αji γj}N s.t. αji ≥ # γj ≥ # γj = # ∀j. (##) j=# j j There are many ways to solve the convex optimization problem in (##). In this paper we used a block coordinate descent approach alternating between the optimization of αji and γj. More speciﬁcally when we ﬁxed αji we can obtain the best γj using the closed form formula in (##); when we ﬁxed γj we can optimize over αji using e.g. a projected gradient method. The overall algorithm pseudocodes are given in Algorithm #. Moreover we can speed up the optimization in three ways. First because the optimization is independent for each node i the overall process can be easily parallelized into N separate sub-problems. Second we can prune the possible nodes that were never infected before node i in any cascade where i was infected. Third if we further assume that all the edges from the same node belong to the same type of models especially when the sample (cid:##) # size is small the N edges could share a common set of m parameters and thus we can only estimate N × m parameters in total. Algorithm #: KernelCascade Initialize the diffusion network G to be empty; for i = # to N do Intialize {αji}N repeat j=# and {γj}N j=#; j=# using projected gradient method with {γj}N j=# using formula (##) with {αji}N Update {αji}N Update {γj}N until convergence; Extract the sparse neighborhood N (i) of node i from nonzero αji; Join N (i) to the diffusion network G j=# from last update; j=# from last update; exp bi bi (cid:##)# (cid:##)#(cid:##) (cid:##) t−ai (cid:##) −(cid:##) t−ai # Experimental Results We will evaluate KernelCascade on both realistic synthetic networks and real world networks. We compare it to NETINF [#] and NETRATE [#] and we show that KernelCascade can perform signif- icantly better in terms of both recovering the network structures and the transmission functions. #.# Synthetic Networks Network generation. We ﬁrst generate synthetic networks that mimic the structural properties of real networks. These synthetic networks can then be used for simulation of information diffusion. Since the latent networks for generating cascades are known in advance we can perform detailed comparisons between various methods. We use Kronecker generator [##] to examine two types of networks with directed edges: (i) the core-periphery structure [##] which mimics the information diffusion process in real world networks and (ii) the Erd˝os-R´enyi random networks. Inﬂuence function. For each edge j → i in a network G we will assign it a mixture of two Rayleigh distributions: fji(t|θ a# b# a# b#) = θR#(t|a# b#) + (# − θ)R#(t|a# b#) where Ri(t|ai bi) = t (cid:##) ai and θ ∈ (# #) is a mixing proportion. We examine # t−ai three different parameter settings for the transmission function: (#) all edges in network G have the same transmission function p(t) = f (t|#.# ## # ## #); (#) all edges in network G have the same transmission function q(t) = f (t|#.# # # ## #); and (#) all edges in network G are uniformly randomly assigned to either p(t) or q(t). Cascade generation. Given a network G and the collection of transmission functions fji for each edge we generate a cascade from G by randomly choosing a node of G as the root of the cascade. The root node j is then assigned to time stamp tj = #. For each neighbor node i pointed by j its event time ti is sampled from fji(t). The diffusion process will continue by further infecting the neighbors pointed by node i in a breadth-ﬁrst fashion until either the overall time exceed the predeﬁned observation time window T c or there is no new node being infected. If a node is infected more than once by multiple parents only the ﬁrst infection time stamp will be recorded. Experiment setting and evaluation metric. We consider a combination of two network topolo- gies (i)-(ii) with three different transmission function settings (#)-(#) which results in six different experimental settings. For each setting we randomly instantiate the network topologies and trans- mission functions for ## times and then vary the number of cascades from ## ### ### ### ### to ####. For KernelCascade we use a Gaussian RBF kernel. The kernel bandwidth σ is chosen using median pairwise distance between grid time points. The regularization parameter is chosen using two fold cross-validation. NETINF requires the desired number of edges as input and we give it an advantage and supply the true number of edges to it. For NETRATE we experimented with both exponential and Rayleigh transmission function. We compare different methods in terms of (#) F # score for the network recovery. F # := #·precision·recall precision+recall where precision is the fraction of edges in the inferred network that also present in the true network and recall is the fraction of edges in the true network that also present in the inferred network; (#) KL divergence between the estimated transmission function and the true transmission function averaged over all edges in a network; (#) the shape of the ﬁtted transmission function compared to the true transmission function. # (a) Core-Periphery p(t) (b) Core-Periphery q(t) (c) Core-Periphery mix p(t) q(t) (d) Random p(t) (e) Random q(t) Figure #: F# Scores for network recovery. (f) Random mix p(t) q(t) (a) Core-Periphery p(t) (b) Core-Periphery q(t) (c) Core-Periphery mix p(t) q(t) (d)Random p(t) Figure #: KL Divergence between the estimated and the true transmission function. (e) Random q(t) (f) Random mix p(t) q(t) F# score for network recovery. From Figure # we can see that in all cases KernelCascade per- forms consistently and signiﬁcantly better than NETINF and NETRATE. Furthermore its perfor- mance also steadily increases as we increase the number of cascades and ﬁnally KernelCascade re- covers the entire network with around #### cascades. In contrast the competitor methods seldom fully recover the entire network given the same number of cascades. We also note that the perfor- mance of NETRATE is very sensitive to the choice of the transmission function (exponential vs. Rayleigh). For instance depending on the actual data generating process the performance of NE- TRATE with Rayleigh model can vary from the second best to the worst. KL divergence for transmission function. Besides better network recovery KernelCascade also estimates the transmission function better. In all cases we experimented KernelCascade leads to drastic improvement in recovering the transmission function (Figure #). We also observe that as we increase the number of cascades KernelCascade adapts better to the actual transmission function. In contrast the performance of NETRATE with exponential model does not improve with increasing number of cascades since the parametric model assumption is incorrect. We note that NETINF does not recover the transmission function and hence there is no corresponding curve in the plot. Visualization of the transmission function. We also visualize the estimated transmission function for an edge from different methods in Figure #. We can see that KernelCascade captures the essential # ##########.##.##.##.##num of cascadesaverage F# netinfnetrate(rayleigh)netrate(exp)KernelCascade##########.##.##.##.##num of cascadesaverage F# netinfnetrate(rayleigh)netrate(exp)KernelCascade##########.##.##.##.##num of cascadesaverage F# netinfnetrate(rayleigh)netrate(exp)KernelCascade##########.##.##.##.##num of cascadesaverage F# netinfnetrate(rayleigh)netrate(exp)KernelCascade##########.##.##.##.##num of cascadesaverage F# netinfnetrate(rayleigh)netrate(exp)KernelCascade##########.##.##.##.##num of cascadesaverage F# netinfnetrate(rayleigh)netrate(exp)KernelCascade#############num of cascadeslog(KL Distance) netrate(rayleigh)netrate(exp)KernelCascade#############num of cascadeslog(KL Distance) netrate(rayleigh)netrate(exp)KernelCascade#############num of cascadeslog(KL Distance) netrate(rayleigh)netrate(exp)KernelCascade#############num of cascadeslog(KL Distance) netrate(rayleigh)netrate(exp)KernelCascade#############num of cascadeslog(KL Distance) netrate(rayleigh)netrate(exp)KernelCascade#############num of cascadeslog(KL Distance) netrate(rayleigh)netrate(exp)KernelCascade (a) An edge with transmission function p(t) (b) An edge with transmission function q(t) Figure #: Estimated transmission function of a single edge based on #### cascades against the true transmission function (blue curve). (a) KernelCascade (b) NETINF (c) NETRATE Figure #: Estimated network of top ## sites. Edges in grey are correctly uncovered while edges highlighted in red are either missed or estimated falsely. features of the true transmission function i.e. bi-modal behavior while the competitor methods miss out the important statistical feature completely. #.# Real world dataset Finally we use the MemeTracker dataset [#] to compare NETINF NETRATE and KernelCascade. In this dataset the hyperlinks between articles and posts can be used to represent the ﬂow of in- formation from one site to another site. When a site publishes a new post it will put hyperlinks to related posts in some other sites published earlier as its sources. Later as it also becomes “older” it will be cited by other newer posts as well. As a consequence all the time-stamped hyperlinks form a cascade for particular piece of information (or event) ﬂowing among different sites. The networks formed by these hyperlinks are used to be the ground truth. We have extracted a network consisting of top ### sites with # ### edges and ## ### cascades from # ### ### posts in a month and we want to recover the the underlying networks. From Table # we can see that KernelCascade achieves a much better F # score for network recovery compared to other methods. Finally we visualize the estimated sub-network structure for the top ## sites in Figure #. By comparison KernelCascade has a relatively better performance with fewer misses and false predictions. Table #: Network recovery results from MemeTracker dataset. predicted edges precision methods NETINF NETRATE(exp) KernelCascade #.## #.## #.## recall #.## #.## #.## F# #.## #.## #.## #### #### #### # Conclusion In this paper we developed a ﬂexible kernel method called KernelCascade to model the latent dif- fusion processes and to infer the hidden network with heterogeneous inﬂuence between each pair of nodes. In contrast to previous state-of-the-art such as NETRATE NETINF and CONNIE Ker- nelCascade makes no restricted assumption on the speciﬁc form of the transmission function over network edges. Instead it can infer it automatically from the data which allows each pair of nodes to have a different type of transmission model and better captures the heterogeneous inﬂuence among entities. We obtain an efﬁcient algorithm and demonstrate experimentally that KernelCascade can signiﬁcantly outperforms previous state-of-the-art in both synthetic and real data. In future we will explore the combination of kernel methods sparsity inducing norms and other point processes to address a diverse range of social network problems. Acknowledgement: L.S. is supported by NSF IIS-####### and startup funds from Gatech. # #########.##.##.##.##.#tpdf KernelCascadeexprayleighdata#########.##.##.##.##.#tpdf KernelCascadeexprayleighdata References [#] M. De Choudhury W. A. Mason J. M. Hofman and D. J. Watts. networks from interpersonal communication. In WWW pages ###–### ####. Inferring relevant social [#] N. Eagle A. S. Pentland and D. Lazer. From the cover: Inferring friendship network structure by using mobile phone data. Proceedings of the National Academy of Sciences ###(##):#####–##### Sept. ####. [#] M. Gomez-Rodriguez D. Balduzzi and B. Sch¨olkopf. Uncovering the temporal dynamics of diffusion networks. In ICML pages ###–### ####. [#] M. Gomez-Rodriguez J. Leskovec and A. Krause. Inferring networks of diffusion and inﬂu- ence. In KDD pages ####–#### ####. [#] D. Kempe J. M. Kleinberg and ´E. Tardos. Maximizing the spread of inﬂuence through a social network. In KDD pages ###–### ####. [#] M. Kolar L. Song A. Ahmed and E. Xing. Estimating time-varying networks. The Annals of Applied Statistics #(#):##–### ####. [#] J. F. Lawless. Statistical Models and Methods for Lifetime Data. Wiley-Interscience ####. [#] E. T. Lee and J. Wang. Statistical Methods for Survival Data Analysis. Wiley-Interscience Apr. ####. [#] J. Leskovec L. Backstrom and J. M. Kleinberg. Meme-tracking and the dynamics of the news cycle. In KDD pages ###–### ####. [##] J. Leskovec D. Chakrabarti J. M. Kleinberg C. Faloutsos and Z. Ghahramani. Kronecker graphs: An approach to modeling networks. Journal of Machine Learning Research ##:###– #### ####. [##] J. Leskovec K. J. Lang and M. W. Mahoney. Empirical comparison of algorithms for network community detection. In WWW pages ###–### ####. [##] J. Leskovec A. Singh and J. M. Kleinberg. Patterns of inﬂuence in a recommendation network. In PAKDD pages ###–### ####. [##] A. C. Lozano and V. Sindhwani. Block variable selection in multivariate regression and high- dimensional causal inference. In NIPS pages ####–#### ####. [##] S. A. Myers and J. Leskovec. On the convexity of latent social network inference. In NIPS pages ####–#### ####. [##] W. Press S. Teukolsky W. Vetterling and B. Flannery. Numerical recipes in C: the art of scientiﬁc computing. Cambridge ####. [##] A. Rakotomamonjy F. Bach S. Canu Y. Grandvalet et al. Simplemkl. Journal of Machine Learning Research #:####–#### ####. [##] D. Watts and S. Strogatz. ###(####):###–### June ####. Collective dynamics of small-world networks. Nature [##] D. J. Watts and P. S. Dodds. Inﬂuentials networks and public opinion formation. Journal of Consumer Research ##(#):###–### ####. [##] Z. Xu R. Jin H. Yang I. King and M. R. Lyu. Simple and efﬁcient multiple kernel learning by group lasso. In ICML pages ####–#### ####. #\n",
            "response:  Information disease and influence diffuse over networks of entities in both artificial systems and human society. Analyzing these transmission networks plays an important role in understanding the diffusion processes and predicting future events. However the underlying transmission networks are often hidden and incomplete and we observe only the time stamps when cascades of events happen.\n",
            "summarize: Spike and Slab Variational Inference for Multi-Task and Multiple Kernel Learning Michalis K. Titsias University of Manchester mtitsias@gmail.com Miguel L´azaro-Gredilla Univ. de Cantabria & Univ. Carlos III de Madrid miguel@tsc.uc#m.es Abstract We introduce a variational Bayesian inference algorithm which can be widely applied to sparse linear models. The algorithm is based on the spike and slab prior which from a Bayesian perspective is the golden standard for sparse inference. We apply the method to a general multi-task and multiple kernel learning model in which a common set of Gaussian process functions is linearly combined with task-speciﬁc sparse weights thus inducing relation between tasks. This model uniﬁes several sparse linear models such as generalized linear models sparse factor analysis and matrix factorization with missing values so that the variational algorithm can be applied to all these cases. We demonstrate our approach in multi- output Gaussian process regression multi-class classiﬁcation image processing applications and collaborative ﬁltering. # Introduction Sparse inference has found numerous applications in statistics and machine learning [# # #]. It is a generic idea that can be combined with popular models such as linear regression factor analysis and more recently multi-task and multiple kernel learning models. In the regularization theory literature sparse inference is tackled via (cid:##)# regularization [#] which requires expensive cross-validation for model selection. From a Bayesian perspective the spike and slab prior [# # #] also called two- groups prior [#] is the golden standard for sparse linear models. However the discrete nature of the prior makes Bayesian inference a very challenging problem. Speciﬁcally for M linear weights inference under a spike and slab prior distribution on those weights requires a combinatorial search over #M possible models. The problems found when working with the spike and slab prior led several researchers to consider soft-sparse or shrinkage priors such as the Laplace and other related scale mixtures of normals [# # # # ##]. However such priors are not ideal since they assign zero probability mass to events associated with weights having zero value. In this paper we introduce a simple and efﬁcient variational inference algorithm based on the spike and slab prior which can be widely applied to sparse linear models. The novel characteristic of this algorithm is that the variational distribution over sparse weights has a factorial nature i.e. it can be written as a mixture of #M components where M is the number of weights. Unlike the standard mean ﬁeld approximation which uses a unimodal variational distribution our variational algorithm can more precisely match the combinational nature of the posterior distribution over the weights. We will show that the proposed variational approach is more accurate and robust to unfavorable initializations than the standard mean ﬁeld variational approximation. We apply the variational method to a general multi-task and multiple kernel learning model that expresses the correlation between tasks by letting them share a common set of Gaussian process latent functions. Each task is modeled by linearly combining these latent functions with task- speciﬁc weights which are given a spike and slab prior distribution. This model is a spike and slab Bayesian reformulation of previous Gaussian process-based single-task multiple kernel learning # methods [## ## ##] and multi-task Gaussian processes (GPs) [## ## ## ##]. Further this model uniﬁes several sparse linear models such as generalized linear models factor analysis probabilistic PCA and matrix factorization with missing values. In the experiments we apply the variational in- ference algorithms to all the above models and present results in multi-output regression multi-class classiﬁcation image denoising image inpainting and collaborative ﬁltering. # Spike and slab multi-task and multiple kernel learning Section #.# discusses the spike and slab multi-task and multiple kernel learning (MTMKL) model that linearly combines Gaussian process latent functions. Spike and slab factor analysis and proba- bilistic PCA is discussed in Section #.# while missing values are dealt with in Section #.#. (#a) (#b) ∀n q ∀q ∀q m ∀m. #.# The model Let D = {X Y} with X ∈ RN×D and Y ∈ RN×Q be a dataset such that the n-th row of X is an input vector xn and the n-th row of Y is the set of Q corresponding tasks or outputs. We use yq to refer to the q-th column of Y and ynq to the (n q) entry. Outputs Y are then assumed to be generated according to the following hierarchical Bayesian model: ynq ∼ N (ynq|fq(xn) σ# q ) M(cid:##) m=# wqmφm(x) = w(cid:##) fq(x) = wqm ∼ πN (wqm|# σ# φm(x) ∼ GP(µm(x) km(xi xj)) q φ(x) w) + (# − π)δ#(wqm) (#c) (#d) Here each µm(x) is a mean function km(xi xj) a covariance function wq = [wq# . . . wqM ](cid:##) φ(x) = [φ#(x) . . . φM (x)](cid:##) and δ#(wqm) denotes the Dirac delta function centered at zero. Since each of the Q tasks is a linear combination of the same set of latent functions {φm(x)}M m=# (where typically M < Q ) correlation is induced in the outputs. Sharing a common set of features means that “knowledge transfer” between tasks can occur and latent functions are inferred more accurately since data belonging to all tasks are used. Several linear models can be expressed as special cases of the above. For instance a generalized linear model is obtained when the GPs are Dirac delta measures (with zero covariance functions) that deterministically assign each φm(x) to its mean function µm(x). However the model in (#) has a number of additional features not present in standard linear models. Firstly the basis functions are no longer deterministic but they are instead drawn from different GPs so an extra layer of ﬂexibility is added to the model. Thus a posterior distribution over the basis functions of the generalized linear model can be inferred from data. Secondly a truly sparse prior the spike and slab prior (#c) is placed over the weights of the model. Speciﬁcally with probability #−π each wqm is zero and with probability π it is drawn from a Gaussian. This contrasts with previous approaches [# # # # ##] in which soft-sparse priors that assign zero probability mass to the weights being exactly zero were used. Hyperparameters π and σ# w are learnable in order to determine the amount of sparsity and the discrepancy of nonzero weights respectively. Thirdly the number of basis functions M can be inferred from data since the sparse prior on the weights allows basis functions to be “switched off” as necessary by setting the corresponding weights to zero. Further the model in (#) can be considered as a spike and slab Bayesian reformulation of multi- task [## ##] and multiple kernel learning previous methods [## ##] that learn the weights using maximum likelihood. By assuming the weights wq are given each output function yq(x) is a GP with covariance function M(cid:##) Cov[(yq(xi) yq(xj)] = w# qmkm(xi xj) which clearly consists of a conic combination of kernel functions. Therefore the proposed model can be reinterpreted as multiple kernel learning in which the weights of each kernel are assigned spike and slab priors in a full Bayesian formulation. m=# # #.# Sparse factor and principal component analysis An interesting case arises when µm(x) = # and km(xi xj) = δij ∀m where δij is the Kronecker delta. This says that each latent function is drawn from a white process so that it consists of indepen- dent values each following the standard normal distribution. We ﬁrst deﬁne matrices Φ ∈ RN×M and W ∈ RQ×M whose elements are respectively φnm = φm(xn) and wqm. Then the model in (#) reduces to Y = ΦW(cid:##) + ξ w) + (# − π)δ#(wqm) wqm ∼ πN (wqm|# σ# φnm ∼ N (φnm|# #) ξnq ∼ N (ξnq|# σ# q ) (#a) (#b) (#c) (#d) where ξ is an N × Q noise matrix with entries ξnq. The resulting model thus corresponds to sparse factor analysis or sparse probabilistic PCA (when the noise is homoscedastic i.e. σ# q is constant for all q). Observe that the sparse spike and slab prior is placed on the factor loadings W. ∀q m ∀n m ∀n q #.# Missing values The method can easily handle missing values and thus be applied to problems involving matrix completion and collaborative ﬁltering. More precisely in the presence of missing values we have a binary matrix Z ∈ RN×Q that indicates the observed elements in Y. Using Z the likelihood in q ) ∀n q s.t. [Z]nq = #. In the experiments we (#a) is modiﬁed according to ynq ∼ N (ynq|fq(xn) σ# consider missing values in applications such as image inpainting and collaborative ﬁltering. # Efﬁcient variational inference that follows the probability distribution in eq. (#c). This allows to reparameterize wqm according to The presence of the Dirac delta mass function makes the application of variational approximate inference algorithms in spike and slab Bayesian models troublesome. However there exists a sim- ple reparameterization of the spike and slab prior that is more amenable to approximate inference w) and a Bernoulli methods. Speciﬁcally assume a Gaussian random variable (cid:###)wqm ∼ N ((cid:###)wqm|# σ# random variable sqm ∼ πsqm (# − π)#−sqm. The product sqm(cid:###)wqm forms a new random variable wqm = sqm(cid:###)wqm and assign the above prior distributions on sqm and (cid:###)wqm. Thus the reparameter- sqm(cid:###)wqm. After the above reparameterization a standard mean ﬁeld variational method that uses the factorized variational distribution over(cid:###)W = {(cid:###)wq}Q q=# takes the form q((cid:###)W S) = (cid:##)Q q=# q((cid:###)wq sq) where (#) Notice that the presence of wqm in the likelihood function in (#a) is now replaced by the product p((cid:###)wqm sqm) = N (wqm|# σ# ized spike and slab prior takes the form: w)πsqm (# − π)#−sqm q=# and S = {sq}Q ∀q m. q((cid:###)wq sq) = q((cid:###)wq)q(sq) = N ((cid:###)wq|µwq Σwq ) M(cid:##) qm (# − γqm)#−sqm γsqm (#) m=# and where (µwq Σwq γq) are variational parameters. Such an approach has extensively used in [##] and also considered in [##]. However the above variational distribution leads to a very inefﬁcient approximation. This is because (#) is a unimodal distribution and therefore has limited capacity when approximating the factorial true posterior distribution which can have exponentially many modes. To analyze the nature of the true posterior distribution we consider the following two properties derived by assuming for simplicity a single output (Q = #) so index q is dropped. Property #: The true marginal posterior p((cid:###)w|Y) can be written as a mixture distribution having #M components. This is an obvious fact since p((cid:###)w|Y) =(cid:##) s p((cid:###)w|s Y)p(s|Y) where the summation The second property characterizes the nature of each conditional p((cid:###)w|s Y) in the above sum. Property #: Assume the conditional distribution p((cid:###)w|s Y). We can write s = s# ∪ s# where involves all #M possible values of the binary vector s. s# denotes the elements in s with value one and s# the elements with value zero. Using the # correspondence between s and (cid:###)w we have (cid:###)w = (cid:###)w# ∪ (cid:###)w#. Then p((cid:###)w|s Y) factorizes as p((cid:###)w|s Y) = p((cid:###)w#|Y)N ((cid:###)w#|# σ# wI|(cid:###)w#|) which says that the posterior over (cid:###)w# given s# = # is equal to the prior over (cid:###)w#. This property is obvious because (cid:###)w# and s# appear in the likelihood as an elementwise product (cid:###)w# ◦ s# thus when s# = # (cid:###)w# becomes disconnected from the data. p((cid:###)w|Y) which is a mixture with #M components with a single Gaussian distribution. Next we The standard variational distribution in (#) ignores these properties and approximates the marginal present an alternative variational approximation that takes into account the above properties. #.# The proposed variational method In the reparameterized spike and slab prior each pair of variables {(cid:###)wqm sqm} is strongly correlated mation must treat each pair {(cid:###)wqm sqm} as a unit so that {(cid:###)wqm sqm} are placed in the same factor since their product is the underlying variable that interacts with the data. Thus a sensible approxi- of the variational distribution. The simplest factorization that achieves this is: M(cid:##) q((cid:###)wq sq) = q((cid:###)wqm sqm). (#) m=# a mixture of #M components is obtained. Therefore Property # is satisﬁed by (#). In turns out that Property # is also satisﬁed. This can be shown by taking the stationary condition for the factor This variational distribution yields a marginal q((cid:###)wq) which has #M components. This can be seen by writing q((cid:###)wq) =(cid:##)M m=# [q((cid:###)wqm sqm = #) + q((cid:###)wqm sqm = #)] and then by multiplying the terms q((cid:###)wqm sqm) when maximizing the variational lower bound (on the true marginal likelihood): w)πsqm (# − π)#−sqm q((cid:###)wqm sqm)q(Θ) where Θ are the remaining random variables in the model (i.e. excluding {(cid:###)wqm sqm}) and q(Θ) their variational distribution. The stationary condition for q((cid:###)wqm sqm) is p(Y (cid:###)wqm sqm Θ)p(Θ)N ((cid:###)wqm|# σ# q((cid:###)wqm sqm)q(Θ) (cid:##) (cid:##) (#) log q((cid:###)wqm sqm) = Z e(cid:###)log p(Y (cid:###)wqm sqm Θ)(cid:###)q(Θ)N ((cid:###)wqm|# σ# # w)πsqm (# − π)#−sqm that does not depend on {(cid:###)wqm sqm}. where Z is a normalizing constant have q((cid:###)wqm|sqm = #) ∝ q((cid:###)wqm sqm = #) = C Therefore we e(cid:###)log p(Y (cid:###)wqm sqm=# Θ)(cid:###)q(Θ) is a constant that does not depend on (cid:###)wqm. From the last expression w)(# − π) where C = we obtain q((cid:###)wqm|sqm = #) = N ((cid:###)wqm|# σ# slab probability models as long as the weights(cid:###)w and binary variables s interact inside the likelihood function according to (cid:###)w ◦ s. The above remarks regarding variational distribution (#) are general and can hold for many spike and w) which implies that Property # is satisﬁed. Z N ((cid:###)wqm|# σ# (#) #.# Application to the multi-task and multiple kernel learning model Here we brieﬂy discuss the variational method applied to the multi-task and multiple kernel model described in Section #.# and refer to supplementary material for variational EM update equations. The explicit form of the joint probability density function on the training data of model (#) is p(Y (cid:###)W S Φ) = N (Y|Φ((cid:###)W◦S)(cid:##) Σ) N (φm|µm Km) where {(cid:###)W S Φ} is the whole set of random variables that need to be marginalized out to compute w)πsqm(# − π)sqm(cid:#) M(cid:##) (cid:#)N ((cid:###)wqm|# σ# the marginal likelihood. The marginal likelihood is analytically intractable so we lower bound it using the following variational distribution (cid:##) m=# q m q((cid:###)W S Φ) = Q(cid:##) M(cid:##) M(cid:##) q((cid:###)wqm sqm) q=# m=# m=# # q(φm). (#) w π {θm}M The stationary conditions of the lower bound result in analytical updates for all factors above. More precisely q(φm) is an N-dimensional Gaussian distribution and each factor q((cid:###)wqm sqm) leads to a marginal q((cid:###)wqm) which is a mixture of two Gaussians where one component is q((cid:###)wqm|sqm = #) = N ((cid:###)wqm|# σ# w) as shown in the previous section. The optimization proceeds using an EM algorithm that at the E-step updates the factors in (#) and at the M-step updates hyperparameters m=#} where θm parameterize kernel matrix Km. There is however one {{σq}Q surprise in these updates. The GP hyperparameters θm are strongly dependent on the factor q(φm) of the corresponding GP latent vector so updating θm by keeping ﬁxed the factor q(φm) exhibits slow convergence. This problem is efﬁciently resolved by applying a Marginalized Variational step [##] which jointly updates the pair (q(φm) θm). This more advanced update together with all remaining updates of the EM algorithm are discussed in detail in the supplementary material. # Assessing the accuracy of the approximation In this section we compare the proposed variational inference method in the following called paired mean ﬁeld (PMF) against the standard mean ﬁeld (MF) approximation. For simplicity we consider a single-output linear regression problem where the data are generated according to: y = ((cid:###)w ◦ s)T x + ξ. Moreover to remove the effect of hyperparameter learning from the com- accuracy when approximating the true posterior mean value for the parameter vector wtr = E[(cid:###)w◦ s] w) are ﬁxed to known values. The objective of the comparison is to measure the where the expectation is under the true posterior distribution. wtr is obtained by running a very long run of Gibbs sampling. PMF and MF provide alternative approximations wPMF and wMF and absolute errors between these approximations and wtr are used to measure accuracy. Since initial- ization is crucial for variational non-convex algorithms the accuracy of PMF and MF is averaged over many random initializations of their respective variational distributions. q=# σ# parison (σ# π σ# soft-error soft-bound extreme-error extreme-bound MF PMF #.### [#.### #.###] #.### [#.### #.###] -###.# [-###.# -###.#] -###.# [-###.# -###.#] #.### [#.### #.###] #.### [#.### #.###] -###.# [-###.# -####.#] -###.# [-###.# -###.#] m=# |wtr m − wappr for soft and extreme initializations. Average values for the variational lower bound are also shown. Table #: Comparison of MF and PMF in Boston-housing data in terms of approximating the ground-truth. m |) together with ##% conﬁdence intervals (given by percentiles) are shown Average errors ((cid:##)## exactly the same principle as PMF. This Gibbs sampler iteratively samples the pair ((cid:###)wm sm) from the conditional p((cid:###)wm sm|(cid:###)w\\m s\\m y) and has been observed to mix much faster than the standard Gibbs sampler that samples (cid:###)w and s separately. More details about the paired Gibbs sampler are For the purpose of the comparison we also derived an efﬁcient paired Gibbs sampler that follows given in the supplementary material. We considered the Boston-housing dataset which consists of ### training examples and ## inputs. Hyperparameters were ﬁxed to values (σ# = #.#×var(y) π = #.## σ# w = #) where var(y) denotes the variance of the data. We performed two types of experiments each repeated ### times. Each repetition of the ﬁrst type uses a soft random initialization of each q(sm = #) = γm from the range (# #). The second type uses an extreme random initialization so that each γm is initialized to either # or #. For each run PMF and MF are initialized to the same variational parameters. Table # reports average absolute errors and also average values of the variational lower bounds. Clearly PMF is more accurate than MF achieves signiﬁcantly higher values for the lower bound and exhibits smaller variance under different initializations. Further for the more difﬁcult case of extreme initializations the performance of MF becomes worse while the performance of PMF remains unchanged. This shows that optimization in PMF although non-convex is very robust to unfavorable initializations. Similar experiments in other datasets have conﬁrmed the above remarks. # Experiments Toy multi-output regression dataset. To illustrate the capabilities of the proposed model we ﬁrst apply it to a toy multi-output dataset with missing observations. Toy data is generated as follows: # Ten random latent functions are generated by sampling i.i.d. from zero-mean GPs with the following non-stationary covariance function (cid:##)−x# i − x# ## j (cid:##) k(xi xj) = exp (# cos(#.#(xi − xj)) + cos(#(xi − xj))) at ### evenly spaced points in the interval x ∈ [−## ##]. Ten tasks are then generated by adding Gaussian noise with standard deviation #.# to those random latent functions and two additional tasks consist only of Gaussian noise with standard deviations #.# and #.#. Finally for each of the ## tasks we artiﬁcially simulate missing data by removing ## contiguous observations as shown in Figure #. Missing data are not available to any learning algorithm and will be used to test performance only. Note that the above covariance function is rank-# so ten out of the twelve tasks will be related though we do not know how or which ones. All tasks are then learned using both independent GPs with squared exponential (SE) covariance function kSE(xi xj) = exp(−(xi − xj)#/(#(cid:##))) and the proposed MTMKL with M = # latent functions each of them also using the SE prior. Hyperparameter (cid:##) as well as noise levels are learned independently for each latent function. Figure # shows the inferred posterior means. Figure #: Twelve related tasks and predictions according to independent GPs (blue continuous line) and MTMKL (red dashed line). Missing data for each task is represented using green circles. The mean square error (MSE) between predictions and missing observations for each task are dis- played in Table #. MTMKL is able to infer how tasks are related and then exploit that information to make much better predictions. After learning only # out of the # available latent functions re- main active while the other ones are pruned by setting the corresponding weights to zero. This is in correspondence with the generating covariance function which only had # eigenfunctions showing how model order selection is automatic. Method \\ Task # ## Independent GPs #.## ##.## #.## #.## #.## ##.## #.## #.## #.## #.## ##.## ##.## #.## MTMKL #.## #.## #.## #.## #.## #.## #.## #.## #.## #.## # ## # # # # #.## # # # ## # Table #: MSE performance of independent GPs vs. MTMKL on the missing observations for each task. # −##−#−#−#−########−#−#.#−#−#.###.###.###.#−##−#−#−#−########−#.#−#−#.#−#−#.###.###.##−##−#−#−#−########−#.#−#−#.###.###.#−##−#−#−#−########−#−######−##−#−#−#−########−#−#−#−####−##−#−#−#−########−#−#−#####−##−#−#−#−########−#.#−#.#−#.#−#.###.##.##.#−##−#−#−#−########−#−#.#−#−#.###.###.###.#−##−#−#−#−########−#−#−########−##−#−#−#−########−#.#−#−#.###.###.###.#−##−#−#−#−########−#.#−#−#.#−#−#.###.###.###.#−##−#−#−#−########−#−#.#−#−#.#−#−#.###.###.# Inferred noise standard deviations for the noise-only tasks are #.## and #.## and the average for the remaining tasks is #.## which agrees well with the stated actual values. The ﬂowers dataset. Though the proposed model has been designed as a tool for regression it can also be used approximately to solve classiﬁcation problems by using output values to identify class membership. In this section we will apply it to the challenging ﬂower identiﬁcation problem posed in [##]. There are #### instances of ﬂowers for training and #### for testing mainly acquired from the web with varying scales resolutions etc. which are labeled into ### categories. In [##] four relevant features are identiﬁed: Color histogram of gradient orientations and the scale invariant feature transform sampled on both the foreground region and its boundary. More information is available at For this type of dataset state of the art performance has been achieved using a weighted linear combination of kernels (one per feature) in a support vector machine (SVM) classiﬁer. A different set of weights is learned for each class. In [##] it is shown that these weights can be learned by solving a convex optimization problem. I.e. the standard approach to tackle the ﬂower classiﬁcation problem would correspond to solving ### independent binary classiﬁcation problems each using a linear combination of # kernels. We take a different approach: Since all the ### binary classiﬁcation tasks are related we learn all of them at once as a multi-task multiple-kernel problem hoping that knowledge transfer between them will enhance performance. For each training instance we set the corresponding output to +# for the desired task whereas the output for the remaining tasks is set to -#. Then we consider both using ## and ## latent functions per feature (i.e. M = ## and M = ##). We measure performance in terms of the recognition rate (RR) which is the average of break-even points (where precision equals recall) for each class; average area under the curve (AUC); and the multi-class accuracy (MA) which is the rate of correctly classiﬁed instances. As baseline recall that a random classiﬁer would yield a RR and AUC of #.# and a MA of #/### = #.####. Results are reported in Table #. Latent function # AUC on test set RR on test set MA on test set Method MTMKL M = ## MTMKL M = ## MKL from [##] M = ### MKL from [##] M = ### #.### #.### - #.### #.### #.### #.### - #.### #.### - - Table #: Performance of the different multiple kernel learning algorithms on the ﬂowers dataset. MTMKL signiﬁcantly outperforms the state-of-the-art method in [##] yielding a performance in line with [##] due to its ability to share information across tasks. Image denoising and dictionary learning. Here we illustrate denoising on the ### × ### “house” image used in [##]. Three noise levels (standard deviations ## ## and ##) are considered. Follow- ing [##] we partition the noisy image in ## ### overlapping # × # blocks and regard each block as a different task. MTMKL is then run using M = ## “latent blocks” also known as “dictionary elements” (bigger dictionaries do not result in signiﬁcant performance increase). For the covariance of the latent functions we consider two possible choices: Either a white covariance function (as in [##]) or an exponential covariance of the form kEXP(xi xj) = e− |xi−xj| where x are the pixel coordinates within each block. The ﬁrst option is equivalent to placing an independent standard nor- mal prior on each pixel of the dictionary. The second one on the other hand introduces correlation between neighboring pixels in the dictionary. Results are shown in Table #. The exponential co- variance clearly enhances performance and produces a more structured dictionary as can be seen in Figure #.(a). The Peak-to-Signal Ratio (PSNR) obtained using the proposed approach is comparable to the state-of-the-art results obtained in [##]. Image inpainting and dictionary learning. We now address the inpainting problem in color im- ages. Following [##] we consider a color image in which a random ##% of the RGB components are missing. Using an analogous partitioning scheme as in the previous section we obtain ### ### blocks of size #× #× # each of which is regarded as a different task. A dictionary size of M = ### and a white covariance function (which is used in [##]) are selected. Note that we do not apply any other preprocessing to data or any speciﬁc initialization as it is done in [##]. The PSNR of the image (cid:##) # PSNR (dB) Noise std Noisy image White ##.## ##.## ##.## σ = ## σ = ## σ = ## ##.## ##.## ##.## Expon. ##.## ##.## ##.## Figure #: Noisy “house” image with σ = ## and re- stored version using Exponential cov. function. Table #: PSNR for noisy and restored image using several noise levels and covariance functions. after it is restored using MTMKL is ##.## dB see Figure #.(b). This result is similar to the results reported in [##] and close to the state-of-the-art result of ##.## dB achieved in [##]. (a) House: Dict. for white and Exponential (b) Castle: Missing values restored and original Figure #: Dictionaries inferred from noisy (σ = ##) “house” image; and “castle” inpainting results. Collaborative ﬁltering. Finally we performed an experiment on the ##M MovieLens data set that consists of ## million ratings for ## ### users and ## ### ﬁlms with ratings ranging {# #.# # . . . #.# #}. We followed the setup in [##] and used the ra and rb partitions provided with the database that split the data into a training and testing so that they are ## ratings per user in the test set. We applied the sparse factor analysis model (i.e. sparse PCA but with heteroscedastic noise for the columns of the observation matrix Y which corresponds to ﬁlms) with M = ## latent dimensions. The RMSE for the ra partition was #.## for the rb partition was #.## so one average #.###. This result is slightly better than #.#### RMSE reported in [##] using GP-LVM. # Discussion In this work we have proposed a spike and slab multi-task and multiple kernel learning model. A novel variational algorithm to perform inference in this model has been derived. The key contri- bution in this regard that explains the good performance of the algorithm is the choice of a joint distribution over ˜wqm and sqm in the variational posterior as opposed to the usual independence assumption. This has the effect of using exponentially many modes to approximate the posterior thus rendering it more accurate and much more robust to poor initializations of the variational pa- rameters. The relevance and wide applicability of the proposed model has been illustrated by using it on very diverse tasks: multi-output regression multi-class classiﬁcation image denoising image inpainting and collaborative ﬁltering. Prior structure beliefs were introduced in image dictionaries which is also a novel contribution to the best of our knowledge. Finally an interesting topic for future research is to optimize the variational distribution proposed here with alternative approximate infer- ence frameworks such as belief propagation or expectation propagation. This could allow to extend current methodologies within such frameworks that assume unimodal approximations [## ##]. Acknowledgments We thank the reviewers for insightful comments. MKT was supported by EPSRC Grant No EP/F######/# “Gaussian Processes for Systems Identiﬁcation with Applications in Systems Bi- ology”. MLG gratefully acknowledges funding from CAM project CCG##-UC#M/TIC-#### and CONSOLIDER-INGENIO #### CSD####-##### (COMONSENS). # References [#] T.J. Mitchell and J.J. Beauchamp. Bayesian variable selection in linear regression. Journal of the Ameri- can Statistical Association ##(###):####–#### ####. [#] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society Series B ##:###–### ####. [#] M.E. Tipping. Sparse Bayesian learning and the relevance vector machine. Journal of Machine Learning Research #:###–### ####. [#] E.I. George and R.E. Mcculloch. Variable selection via Gibbs sampling. Journal of the American Statis- tical Association ##(###):###–### ####. [#] M. West. Bayesian factor regression models in the ”large p small n” paradigm. In Bayesian Statistics pages ###–###. Oxford University Press ####. [#] B. Efron. Microarrays empirical Bayes and the two-groups model. Statistical Science ##:#–## ####. [#] C. Archambeau and F. Bach. Sparse probabilistic projections. In D. Koller D. Schuurmans Y. Bengio and L. Bottou editors Advances in Neural Information Processing Systems ## pages ##–##. ####. [#] F. Caron and A. Doucet. Sparse Bayesian nonparametric regression. In In ##th International Conference on Machine Learning (ICML). ACM ####. [#] Matthias W. Seeger and Hannes Nickisch. Compressed sensing and Bayesian experimental design. In ICML pages ###–### ####. [##] C.M. Carvalho N.G. Polson and J.G. Scott. The horseshoe estimator for sparse signals. Biometrika ##:###–### ####. [##] T. Damoulas and M.A. Girolami. Probabilistic multi-class multi-kernel learning: on protein fold recogni- tion and remote homology detection. Bioinformatics ##:####–#### ####. [##] M. Christoudias R. Urtasun and T. Darrell. Bayesian localized multiple kernel learning. Technical report EECS Department University of California Berkeley Jul ####. [##] C. Archambeau and F. Bach. Multiple Gaussian process models. In NIPS ## workshop on New Directions in Multiple Kernel Learning. ####. [##] Y.W. Teh M. Seeger and M.I. Jordan. Semiparametric latent factor models. International Workshop on Artiﬁcial Intelligence and Statistics volume ## ####. In Proceedings of the [##] E.V. Bonilla K.M.A. Chai and C.K.I. Williams. Multi-task Gaussian process prediction. In Advances Neural Information Processing Systems ## ####. [##] P Boyle and M. Frean. Dependent Gaussian processes. In Advances in Neural Information Processing Systems ## pages ###–###. MIT Press ####. [##] M. Alvarez and N.D. Lawrence. Sparse convolved Gaussian processes for multi-output regression. In Advances in Neural Information Processing Systems ## pages ##–## ####. [##] R. Yoshida and M. West. Bayesian learning in sparse graphical factor models via variational mean-ﬁeld annealing. Journal of Machine Learning Research ##:####–#### ####. [##] M. Zhou H. Chen J. Paisley L. Ren G. Sapiro and L. Carin. Non-parametric Bayesian dictionary learning for sparse image represent ations. In Y. Bengio D. Schuurmans J. Lafferty C. K. I. Williams and A. Culotta editors Advances in Neural Information Processing Systems ## pages ####–####. ####. In ##th International Conference on Machine Learning (ICML-##) pages ###–### New York NY USA June ####. ACM. [##] M. L´azaro-Gredilla and M. Titsias. Variational heteroscedastic Gaussian process regression. [##] M.E. Nilsback and A. Zisserman. Automated ﬂower classiﬁcation over a large number of classes. In Proceedings of the Indian Conference on Computer Vision Graphics and Image Processing Dec ####. [##] M. Varma and D. Ray. Learning the discriminative power invariance trade-off. In International Confer- ence on Computer Vision. ####. [##] J. Mairal M. Elad and G. Sapiro. Sparse representation for color image restoration. IEEE Trans. Image Processing ## ####. [##] N.D. Lawrence and R. Urtasun. Non-linear matrix factorization with Gaussian processes. In Proceedings of the ##th Annual International Conference on Machine Learning pages ###–### ####. [##] K. Sharp and M. Rattray. Dense message passing for sparse principal component analysis. International Conference on Artiﬁcial Intelligence and Statistics (AISTATS) pages ###–### ####. In ##th [##] J.M. Hern´andez-Lobato D. Hern´andez-Lobato and A. Su´arez. Network-based sparse Bayesian classiﬁ- cation. Pattern Recognition ##(#):###–### ####. #\n",
            "response:  We introduce a variational Bayesian inference algorithm which can be widely applied to sparse linear models. The algorithm is based on the spike and slab prior which from a Bayei perspective is the golden standard for sparsing inference. We apply the method to a general multi-task and multiple kernel learning model in which a common set of Gaussian process functions is linearly combined with task-specific sparser weights thus inducing relation between tasks.\n",
            "summarize: Fast Efﬁcient Hyperparameter Tuning for Policy Gradient Methods Supratik Paul Vitaly Kurin Shimon Whiteson {supratik.paul vitaly.kurin shimon.whiteson}@cs.ox.ac.uk Deptartment of Computer Science University of Oxford Abstract The performance of policy gradient methods is sensitive to hyperparameter settings that must be tuned for any new application. Widely used grid search methods for tuning hyperparameters are sample inefﬁcient and computationally expensive. More advanced methods like Population Based Training (Jaderberg et al. ####) that learn optimal schedules for hyperparameters instead of ﬁxed settings can yield better results but are also sample inefﬁcient and computationally expensive. In this paper we propose Hyperparameter Optimisation on the Fly (HOOF) a gradient- free algorithm that requires no more than one training run to automatically adapt the hyperparameter that affect the policy update directly through the gradient. The main idea is to use existing trajectories sampled by the policy gradient method to optimise a one-step improvement objective yielding a sample and computationally efﬁcient algorithm that is easy to implement. Our experimental results across multiple domains and algorithms show that using HOOF to learn these hyperparameter schedules leads to faster learning with improved performance. # Introduction Policy gradient methods (Williams ####; Sutton et al. ####) optimise reinforcement learning policies by performing gradient ascent on the policy parameters and have shown considerable success in environments characterised by large or continuous action spaces (Mordatch et al. ####; Schulman et al. ####; Rajeswaran et al. ####). However like other gradient-based optimisation methods their performance can be sensitive to a number of key hyperparameters. For example the performance of ﬁrst order policy gradient methods can depend critically on the learning rate the choice of which in turn often depends on the task the particular policy gradient method in use and even the optimiser e.g. RMSProp (Tieleman and Hinton ####) and ADAM (Kingma and Ba ####) have narrow ranges for good learning rates (Henderson et al. ####b) which may not be known a priori. Even for second order methods like Natural Policy Gradients (NPG) (Kakade ####) or Trust Region Policy Optimisation (TRPO) (Schulman et al. ####) which are more robust to the KL divergence constraint (which can be interpreted as a learning rate) signiﬁcant performance gains can often be obtained by tuning this parameter (Duan et al. ####). Similarly variance reduction techniques such as Generalised Advantage Estimators (GAE) (Schulman et al. ####) which trade variance for bias in policy gradient estimates introduce key hyperparameters (γ λ) that can also greatly affect performance (Schulman et al. ####; Mahmood et al. ####). Given such sensitivities there is a great need for effective methods for tuning policy gradient hyperparameters. Perhaps the most popular hyperparameter optimiser is simply grid search (Schulman et al. ####; Mnih et al. ####; Duan et al. ####; Igl et al. ####; Farquhar et al. ####). More sophisticated techniques such as Bayesian optimisation (BO) (Srinivas et al. ####; Hutter et al. ##rd Conference on Neural Information Processing Systems (NeurIPS ####) Vancouver Canada. ####; Snoek et al. ####; Chen et al. ####) have also proven effective and new innovations such as Population Based Training (PBT) (Jaderberg et al. ####) and meta-gradients (Xu et al. ####) have shown considerable promise. Furthermore a host of methods have been proposed for hyperparameter optimisation in supervised learning (see Section #). However all these methods suffer from a major problem: they require performing many learning runs to identify good hyperparameters. This is particularly problematic in reinforcement learning where it incurs not just computational costs but sample costs as new learning runs typically require fresh interactions with the environment. This sample inefﬁciency is obvious in the case of grid search BO based methods and PBT. However even meta-gradients which reuses samples collected by the underlying policy gradient method to train the meta-learner requires multiple training runs. This is because the meta-learner introduces its own set of hyperparameters e.g. meta learning rate and reference (γ λ) all of which need tuning to achieve good performance. Furthermore grid search and BO based methods typically estimate only the best ﬁxed values of the hyperparameters which often actually need to change dynamically during learning (Jaderberg et al. ####; François-Lavet et al. ####). This is particularly important in reinforcement learning where the distribution of visited states the need for exploration and the cost of taking suboptimal actions can all vary greatly during a single learning run. To make hyperparameter optimisation practical for reinforcement learning methods such as policy gradients we need radically more efﬁcient methods that can dynamically set key hyperparameters on the ﬂy not just ﬁnd the best ﬁxed values and do so within a single run using only the data that the baseline method would have gathered anyway without introducing new hyperparameters that need tuning. This goal may seem ambitious but in this paper we show that it is actually entirely feasible using a surprisingly simple method we call Hyperparameter Optimisation on the Fly (HOOF). The main idea is as follows: At each iteration sample trajectories using the current policy. Next generate some candidate policies and estimate their value sample efﬁciently by using an off-policy method. Finally update the policy greedily with respect to the estimated value of the candidates. In practice HOOF uses the policy gradient method with different hyperparameter (e.g. the learning rate γ and λ) settings to generate candidate policies and then uses importance sampling (IS) to construct off-policy estimates of the value of each candidate policy. The viability of such a simple approach is counter-intuitive since off-policy evaluation using IS tends to have high variance that grows rapidly as the behaviour and evaluation policies diverge. However HOOF is motivated by the insight that in second order methods such as NPG and TRPO constraints on the magnitude of the update in policy space ensure that the IS estimates remain informative. While this is not the case for ﬁrst order methods we show that adding a simple KL constraint without any of the complications of second order methods sufﬁces to keep IS estimates informative and enable effective hyperparameter optimisation. We further show that the performance of HOOF is robust to the setting of this KL constraint. HOOF is #) sample efﬁcient requiring no more than one training run; #) computationally efﬁcient compared to sequential and parallel search methods; #) able to learn a dynamic schedule for the hyperparameters that outperforms methods that learn ﬁxed hyperparameter settings; and #) simple to implement. Being gradient free HOOF also avoids the limitations of gradient-based methods (Sutton ####; Luketina et al. ####; Xu et al. ####) for learning hyperparameters. While such methods can be more sample efﬁcient than grid search or PBT they can be sensitive to the choice of their own hyperparameters (see Sections # and #.#) and thus require more than one training run to tune their own hyperparameters. We evaluate HOOF across a range of simulated continuous control tasks using the Mujoco OpenAI Gym environments (Brockman et al. ####). First we apply HOOF to A#C (Mnih et al. ####) and show that using it to learn the learning rate can improve performance. We also perform a benchmarking exercise where we use HOOF to learn both the learning rate and the weighting for the entropy term and compare it against a grid search across these two hyperparameters. Next we show that using HOOF to learn optimal hyperparameter schedules for NPG can outperform TRPO. This suggests that while strictly enforcing the KL constraint enables TRPO to outperform NPG doing so becomes unnecessary once we can properly adapt NPG’s hyperparameters. # # Background value function of the state st is V (st) = Ea∼π s∼P [(cid:##)∞ J(π) = Ea∼π s∼P s#∼p(s#)[(cid:##) Consider the RL task where an agent interacts with its environment and tries to maximise its expected return. At timestep t it observes the current state st takes an action at receives a reward rt = r(st at) and transitions to a new state st+# following some transition probability P. The i=# γirt+i] for some discount rate γ ∈ [# #). The undiscounted formulation of the objective is to ﬁnd a policy that maximises the expected return t rt]. In stochastic policy gradient algorithms at is sampled from a parametrised stochastic policy π(a|s) that maps states to actions. These methods perform an update of the form π(cid:##) = π + f (ψ). (#) # τ π # . . . τ π Here f (ψ) represents a step along the gradient direction for some objective function estimated from a batch of sampled trajectories {τ π K} and ψ is the set of hyperparameters. We use π to denote both the policy as well as the parameters. (cid:##) For policy gradient methods with GAE ψ = (α γ λ) and the update takes the form: (cid:###) ∇ log π(at|st)AGAE(γ λ) f (α γ λ) = α (cid:###)(cid:###) (cid:###) (#) t t g(γ λ) t t + λA(#) t + λ#A(#) = (#− λ)(A(#) t + . ) with A(k) t = −V (st) + rt + γrt+# + . + where AGAE(γ λ) γk−#rt+k−# + γkV (st+k). By discounting future rewards and bootstrapping off the value function GAE reduces the variance due to rewards observed far in the future but adds bias to the policy gradient estimate. Well chosen (γ λ) can signiﬁcantly speed up learning (Schulman et al. ####; Henderson et al. ####a; Mahmood et al. ####). In ﬁrst order methods small updates in parameter space can lead to large changes in policy space leading to large changes in performance. Second order methods like NPG address this by restricting the change to the policy through the constraint KL(π(cid:##)||π) ≤ δ. An approximate solution to this constrained optimisation problem leads to the update rule: (cid:###) f (δ γ λ) = #δ g(γ λ)T I(π)−#g(γ λ) I(π)−#g(γ λ) (#) where I(π) is the estimated Fisher information matrix (FIM). Since the above is only an approximate solution the KL(π(cid:##)||π) constraint can be violated in some iterations. Further since δ is not adaptive it might be too large for some iterations. TRPO addresses these issues by requiring an improvement in the surrogate Lπ(π(cid:##)) = Ea∼π s∼P [ π(cid:##)(a|s) π(a|s) AGAE(γ λ)] as well as ensuring that the KL-divergence constraint is satisﬁed. It does this by performing a backtracking line search along the gradient direction. As a result TRPO is more robust to the choice of δ (Schulman et al. ####). # Hyperparameter Optimisation on the Fly The main idea behind HOOF is to automatically adapt the hyperparameters during training by greedily maximising the value of the updated policy i.e. starting with policy πn at iteration n HOOF sets ψn = argmax ψ J(πn+#) = argmax ψ J(πn + f (ψ)) (#) Given a set of sampled trajectories f (ψ) can be computed for any ψ and thus we can generate different candidate πn+# without requiring any further samples. However solving the optimisation problem in (#) requires evaluating J(πn+#) for each such candidate. Any on-policy approach would have prohibitive sample requirements so HOOF uses weighted importance sampling (WIS) to # Algorithm # HOOF input Initial policy π# number of policy iterations N search space for ψ KL constraint \u0001 if using ﬁrst order policy gradient method. Sample trajectories τ#:K using πn. for z = # # . . . Z do #: for n = # # # # . . . N do #: #: #: #: #: #: #: #: ##: end for Generate candidate hyperparameter {ψz} from the search space. Compute candidate policy πz using ψz in (#) Estimate J(πz) using WIS (#) Compute KL(πz||πn) if using ﬁrst order policy gradient method end for Select ψn and hence πn+# according to (#) or (#) construct an off-policy estimate of J(πn+#). Given sampled trajectories {τ πn corresponding returns {Rπn # Rπn # . τ πn K } with (cid:##) J(πn+#) = # . Rπn # τ πn (cid:##) K } the WIS estimate of J(πn+#) is given by: K(cid:##) wk(cid:##)K k ∼πn) . Since p(τ|π) = p(s#)(cid:##)T k=# wk i=# π(ai|si)p(si+#|si ai) the transitions cancel (cid:##)T (cid:##)T i=# πn+#(ai|sk i ) i=# πn(ai|sk i ) Rπn k wk = (#) (#) where wk = P (τ πn P (τ πn out and we have: k ∼πn+#) k=# . The success of this approach depends critically on the quality of the WIS estimates which can suffer from high variance that grows rapidly as the distributions of πn+# and πn diverge. Fortunately for natural gradient methods like NPG KL(πn+#||πn) is automatically approximately bounded by the update ensuring reasonable WIS estimates when HOOF directly uses (#). In the following we consider the more challenging case of ﬁrst order methods. #.# First Order HOOF Without a KL bound on the policy update it may seem that WIS will not yield adequate estimates to solve (#). However a key insight is that while the estimated policy value can have high variance the relative ordering of the policies which HOOF solves for has much lower variance (See Appendix E for an illustrative example). Nonetheless HOOF could still fail if KL(πn+#||πn) becomes too large which can occur in ﬁrst order methods. Hence First Order HOOF modiﬁes (#) by constraining KL(πn+#||πn): ψn = argmax ψ J(πn+#) s.t. KL(πn+#||πn) < \u0001. (#) While this yields an update that superﬁcially resembles that of natural gradient methods the KL constraint is applied only during the search for the optimal hyperparameter settings using WIS. The direction of the update is determined solely by a ﬁrst order gradient update rule and estimation and inversion of the FIM is not required. From a practical perspective this constraint is enforced by computing the KL for each candidate policy based on the observed trajectories and the candidate is rejected if this sample KL is greater than the constraint. If learning the learning rate using HOOF we can also use the KL constraint to dynamically adjust the search bounds: At each iteration if none of the candidates violate the KL constraint we increase the upper bound of the search space by a factor ν while if a large proportion of the candidates violate the KL constraint we reduce the upper bound by ν. This makes HOOF even more robust to the initial setting of the search space. Note that this is entirely optional and is simply a means to reduce the number of number of candidates that would otherwise need to be generated and evaluated to ensure that a good solution of (#) is found. # #.# (γ λ) Conditioned Value Function If we use HOOF to learn (γ λ) gn has to be computed for each setting of (γ λ). With neural net value functions we modify our value function such that its inputs are (s γ λ) similar to Universal Value Function Approximators (Schaul et al. ####). Thus we learn a (γ λ)-conditioned value function that can make value predictions for any candidate (γ λ) at the cost of a single forward pass. In Appendix D we present some experimental results to show that learning a (γ λ)-conditioned value function is key to the success of HOOF. #.# Robustness to HOOF Hyperparameters and Computational Costs HOOF introduces two types of hyperparameters of its own: the search spaces for the various hyperparameters it tunes and the number of candidate policies generated for evaluation. Since the candidate policies are generated using random search these hyperparameters express a straight up trade-off between performance and computational cost: A larger search space and larger number of candidates should lead to better solution for (#) but incur higher computational cost. However just like in random search the generation and evaluation of the candidate policies can be performed in parallel to reduce wall clock time. Alternatively Bayesian Optimisation could be used to solve (#) efﬁciently. Finally we note that HOOF with random search is always more computationally efﬁcient than grid/random search over the hyperparameters with the same number of candidates as HOOF saves on the additional computational cost of sampling trajectories for each candidate incurred by grid/random search. HOOF additionally introduces the KL constraint hyperparameter for ﬁrst order methods. We show experimentally that the performance of HOOF is robust to a wide range of settings for this. #.# Choice of Optimiser Throughout this paper we use random search as the optimiser for (#) to show that the simplest methods sufﬁce. However any gradient-free optimiser could be used instead. For example grid search CMA-ES (Hansen and Ostermeier ####) or Bayesian Optimisation (Brochu et al. ####) are all viable alternatives. Gradient based methods are not viable for two reasons. First they require that J(πn+#) be differen- tiable w.r.t. the hyperparameters which might be difﬁcult or impossible to compute e.g. with the TRPO update. Second they introduce learning rate and initialisation hyperparameters which require tuning at the expense of sample efﬁciency. # Related Work Most hyperparameter search methods can be broadly classiﬁed into sequential search parallel search and gradient based methods. Sequential search methods perform a training run with some candidate hyperparameters and use the results to inform the choice of the next set of hyperparameters for evaluation. BO is a sample efﬁcient global optimisation framework that models performance as a function of the hyperparameters and is especially suited for sequential search as each training run is expensive. After each training run BO uses the observed performance to update the model in a Bayesian way which then informs the choice of the next set of hyperparameters for evaluation. Several modiﬁcations have been suggested to further reduce the number of evaluations required: input warping (Snoek et al. ####) to address nonstationary ﬁtness landscapes; freeze-thaw BO (Swersky et al. ####) to decide whether a new training run should be started and the current one discontinued based on interim performance; transferring knowledge about hyperparameters across similar tasks (Swersky et al. ####); and modelling training time as a function of dataset size (Klein et al. ####). To further speed up the wall clock time some BO based methods use a hybrid mode wherein batches of hyperparameter settings are evaluated in parallel (Contal et al. ####; Desautels et al. ####; Shah and Ghahramani ####; Wang et al. ####; Kandasamy et al. ####). By contrast parallel search methods like grid search and random search run multiple training runs with different hyperparameter settings in parallel to reduce wall clock time but require more parallel computational resources. These methods are easy to implement and have been shown to perform well (Bergstra et al. ####; Bergstra and Bengio ####). # Both sequential and parallel search suffer from two key disadvantages. First they require performing multiple training runs to identify good hyperparameters. Not only is this computationally inefﬁcient but when applied to RL also sample inefﬁcient as each run requires fresh interactions with the environment. Second these methods learn ﬁxed values for the hyperparameters that are used throughout training instead of a schedule which can lead to suboptimal performance (Luketina et al. ####; Jaderberg et al. ####; Xu et al. ####). PBT (Jaderberg et al. ####) is a hybrid of random and sequential search with the added beneﬁt of adapting hyperparameters during training. It starts by training a population of hyperparameters which are then updated periodically to further explore promising hyperparameter settings. However by requiring multiple training runs it inherits the sample inefﬁciency of random search. HOOF is much more sample efﬁcient because it requires no more interactions with the environment than those gathered by the underlying policy gradient method for one training run. Consequently it is also far more computationally efﬁcient. However while HOOF can only optimise hyperparameters that directly affect the policy update these methods can tune other hyperparameters e.g. policy architecture. Combining these complementary strengths in an interesting topic for future work. Gradient based methods (Sutton ####; Bengio ####; Luketina et al. ####; Pedregosa ####; Xu et al. ####) adapt the hyperparameters by performing gradient descent on the policy gradient update function with respect to the hyperparameters. This raises the fundamental problem that the update function needs to be differentiable. For example the update function for TRPO uses conjugate gradient to approximate I(π)−#g performs a backtracking line search to enforce the KL constraint and introduces a surrogate improvement constraint which introduce discontinuities in the update and makes it non-differentiable. A second major disadvantage of these methods is that they introduce their own set of hyperparameters which can make them sample inefﬁcient if they require tuning. For example the meta-gradient estimates can have high variance which in turn signiﬁcantly affects performance. To address this the objective function of meta-gradients introduces reference (γ(cid:##) λ(cid:##)) hyperparameters to trade off bias and variance. As a result its performance can be sensitive to these as the experimental results of Xu et al. (####) show. Furthermore gradient based methods tend to be highly sensitive to the setting of the learning rate and these methods introduce their own learning rate hyperparameter for the meta learner which requires tuning as we show in our experiments. As a gradient-free method HOOF does not require a differentiable objective and while it introduces a few hyperparameters of its own these do not affect sample efﬁciency as mentioned in Section #.#. Other work on non-gradient based methods includes that of Kearns and Singh (####) who derive a theoretical schedule for the TD(λ) hyperparameter that they show is better than any ﬁxed value. Downey et al. (####) learn a schedule for TD(λ) using a Bayesian approach. White and White (####) greedily adapt the TD(λ) hyperparameter as a function of state. Unlike HOOF these methods can only be applied to TD(λ) and in the case of Kearns and Singh (####) are not compatible with function approximation. # Experiments To experimentally validate HOOF we apply it to four simulated continuous control tasks from MuJoCo OpenAI Gym (Brockman et al. ####): HalfCheetah Hopper Ant and Walker. We start with A#C and show that HOOF performs better than multiple baselines and is also far more sample efﬁcient. Next we use NPG as the underlying policy gradient method and apply HOOF to learn (δ γ λ) and show that it outperforms TRPO. We repeat all experiments across ## random starts. In all ﬁgures solid lines represent the median and shaded regions the quartiles. Similarly all results in tables represent the median. Hyperparameters that are not tuned are held constant across HOOF and baselines to ensure comparability. Details about all hyperparameters can be found in the appendices and code is available at com/supratikp/HOOF. #.# HOOF with A#C In the A#C framework a neural net with parameters θ is commonly used to represent both the policy and the value function usually with some shared layers. The update function (#) for A#C is a linear # (a) HalfCheetah (b) Hopper (c) Ant (d) Walker Figure #: Performance of HOOF with \u0001 = #.## compared to Baseline A#C and Tuned Meta-Gradients. The hyperparameters (α# β) of meta gradients had to be tuned using grid search which required ##x the samples used by HOOF. Table #: Performance of HOOF with different values of the KL constraint (\u0001 parameter). The results show that the performance is relatively robust to the setting of \u0001. KL constraint HalfCheetah Hopper Ant Walker # ### ### ### ### # ### ### ### ### # ### ### ### ### \u0001 = #.## \u0001 = #.## \u0001 = #.## # ### ### ### ### # ### ### ### ### \u0001 = #.## \u0001 = #.## \u0001 = #.## \u0001 = #.## #### ### ### ### #### ### ### ### combination of the gradients of the policy loss the value loss and the policy entropy: fθ(α) = α{∇θ log πθ(a|s)(R − Vθ(s)) + c#∇θ(R − Vθ(s))# + c#∇θH(πθ(s))} (#) where we have omitted the dependence on the timestep and other hyperparameters for ease of notation. The performance of A#C is particularly sensitive to the choice of the learning rate α (Henderson et al. ####b) which requires careful tuning. We learn α using HOOF with the KL constraint \u0001 = #.## (‘HOOF’). We compare this against two baselines: (#) Baseline A#C i.e. A#C with the initial learning rate set to the OpenAI Baselines default (#.####) and (#) learning rate being learnt by meta-gradients (‘Tuned Meta-Gradient’) where the hyperparameters introduced by meta-gradients were tuned using grid search. The learning curves in Figure # shows that across all environments HOOF learns faster than Baseline A#C and also outperforms it in HalfCheetah and Walker demonstrating that learning the learning rate online can yield signiﬁcant gains. The update rule for meta-gradients when learning α reduces to α(cid:##) = α + β∇θ(cid:##) log πθ(cid:##)(a|s)(R − Vθ(cid:##)(s)) fθ(ψ) α where β is the meta learning rate. This leads to two issues: what should the learning rate be initialised to (α#) and what should the meta learning rate be set to? Like all gradient based methods the performance of meta gradients can be sensitive to the choices of these two hyperparamters. When we set α# to the OpenAI baselines default setting and β to #.### as per Xu et al. (####) A#C fails to learn at all. Thus we had to run a grid search over (α# β) to ﬁnd the optimal settings across these hyperparameters. In Figure # we plot the best run from this grid search. Despite using ## times as many samples (due to the grid search) meta-gradients still cannot outperform HOOF and learns slower in # of the # tasks. The returns for each of the ## points on the grid are presented in Appendix B.# and they show that the performance of meta gradients can be sensitive to these two hyperparamters. To show that HOOF’s performance is robust to \u0001 its own hyperparameter quantifying the KL constraint we repeated our experiments with different values of \u0001. The results presented in Table # show that HOOF’s performance is stable across different values of this parameter. This is not surprising – the sole purpose of the constraint is to ensure that the WIS estimates remain viable. Finally to ascertain the sample efﬁciency of HOOF relative to grid search we perform a benchmarking exercise. We used HOOF to learn both the learning rate and the entropy coefﬁcient (c# in (#)). We split the search bounds for these across a grid with ##x## points and ran A#C for each setting on the grid. For computational reasons we set the budget for each training run to # million timesteps. Given a budget of n training runs we randomly subsample n points from the grid (without replacement) and note the best return. We repeat this #### times to get an estimate of the expected best return # Table #: Comparison of sample efﬁciency of HOOF over grid search. Max return over subsampled grid of size # # HOOF Returns ### ### ### ### HalfCheetah Hopper Ant Walker -### ### -#### ## -### ### -### ### # ### ### ### ### ## ### ### ### ### (a) HalfCheetah (b) Hopper (c) Ant (d) Walker Figure #: Performance of HOOF-TNPG vs TRPO baselines. of the grid search with a budget of n training runs. The results presented in Table # compares the returns of HOOF to that of the expected best return for grid search with different training budgets. The performance of grid search is much worse than that of HOOF with the same budget (i.e. only # training run). The results show that grid search can take more than ## times as many samples to match HOOF’s performance. Appendix A.# contains further experimental details including results conﬁrming that the KL con- straint is crucial to ensuring sound WIS estimates. In Appendix A.# we show that HOOF is also robust to the choice of the optimiser by running the experiments with SGD (instead of RMSProp) as the optimiser. In this case the difference in performance is highly signiﬁcant with Baseline A#C failing to learn at all. #.# HOOF with Truncated Natural Policy Gradients (TNPG) A major disadvantage of natural policy gradient methods is that they require the inversion of the FIM in (#) which can be prohibitively expensive for large neural net policies with thousands of parameters. TNPG (Duan et al. ####) and TRPO address this by using the conjugate gradient algorithm to efﬁciently approximate I(π)−#g. TRPO has been shown to perform better than TNPG in continuous control tasks (Schulman et al. ####) a result attributed to stricter enforcement of the KL constraint. However in this section we show that stricter enforcement of the KL constraint becomes unnecessary once we properly adapt TNPG’s learning rate. To do so we apply HOOF to learn (δ γ λ) of TNPG (‘HOOF-TNPG’) and compare it with TRPO with the OpenAI Baselines default settings of (\u0001 = #.## γ = #.## λ = #.##) (‘Baseline TRPO’). Figure # shows the learning curves of HOOF-TNPG and the Baseline TRPO. HOOF-TNPG learns much faster and outperforms Baseline TRPO in all environments except for Walker where there’s no signiﬁcant difference. Figure # presents the learnt (δ γ λ). The results show that different KL constraints and GAE hyperparameters are needed for different domains. We could not compare with meta-gradients as the objective function is not differentiable as discussed earlier in Section #. We also could not perform a comparison against grid search similar to the one in Section #.# as the computational burden of performing a grid search over three hyperparameters was too large. # Conclusions & Future Work The performance of a policy gradient method is highly dependent on its hyperparameters. However methods typically used to tune these hyperparameters are highly sample inefﬁcient computationally expensive and learn only a ﬁxed setting of the hyperparameters. In this paper we presented HOOF a sample efﬁcient method that automatically learns a schedule for the learning rate and GAE hyperpa- rameters of policy gradient methods without requiring multiple training runs. We believe that this # (a) Learnt δ (b) Learnt γ (c) Learnt λ Figure #: Hyperparameters learnt by HOOF-TNPG for HalfCheetah Hopper and Walker. combined with its simplicity and ease of implementation makes HOOF a compelling method for optimising policy gradient hyperparameters. While we have presented HOOF as a method to learn the hyperparameters of a policy gradient algorithm the underlying principles are far more general. For example one could compute a distribution for the gradient and generate candidate policies by sampling from that distribution instead of just using the point estimate of the gradient. It has also been hypothesised that state/action dependent discount factors might help speed up learning (White ####; Fedus et al. ####). This could be achieved by using HOOF to learn the parameters of a function that maps the states/actions to the discount factors. Acknowledgements This project has received funding from the European Research Council (ERC) under the European Union’s Horizon #### research and innovation programme (grant agreement #######) and Samsung R&D Institute UK. The experiments were made possible by a generous equipment grant from NVIDIA. References Bengio Y. (####). Gradient-based optimization of hyperparameters. Neural computation ##(#):####– ####. Bergstra J. and Bengio Y. (####). Random search for hyper-parameter optimization. Journal of Machine Learning Research ##(Feb):###–###. Bergstra J. S. Bardenet R. Bengio Y. and Kégl B. (####). Algorithms for hyper-parameter optimization. In Advances in Neural Information Processing Systems. Brochu E. Cora V. M. and de Freitas N. (####). A tutorial on bayesian optimization of expensive cost functions with application to active user modeling and hierarchical reinforcement learning. eprint arXiv:####.#### arXiv.org. Brockman G. Cheung V. Pettersson L. Schneider J. Schulman J. Tang J. and Zaremba W. (####). Openai gym. Chen Y. Huang A. Wang Z. Antonoglou I. Schrittwieser J. Silver D. and de Freitas N. (####). Bayesian optimization in alphago. CoRR abs/####.#####. Contal E. Buffoni D. Robicquet A. and Vayatis N. (####). Parallel gaussian process optimization with upper conﬁdence bound and pure exploration. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Desautels T. Krause A. and Burdick J. W. (####). Parallelizing exploration-exploitation tradeoffs in gaussian process bandit optimization. The Journal of Machine Learning Research ##(#):####– ####. Dhariwal P. Hesse C. Klimov O. Nichol A. Plappert M. Radford A. Schulman J. Sidor S. Wu Y. and Zhokhov P. (####). Openai baselines. # Downey C. Sanner S. et al. (####). Temporal difference bayesian model averaging: A bayesian perspective on adapting lambda. In International Conference on Machine Learning. Duan Y. Chen X. Houthooft R. Schulman J. and Abbeel P. (####). Benchmarking deep reinforcement learning for continuous control. In International Conference on Machine Learning. Farquhar G. Rocktaschel T. Igl M. and Whiteson S. (####). Treeqn and atreec: Differentiable tree-structured models for deep reinforcement learning. In International Conference on Learning Representations. Fedus W. Gelada C. Bengio Y. Bellemare M. G. and Larochelle H. (####). Hyperbolic discounting and learning over multiple horizons. arXiv preprint arXiv:####.#####. François-Lavet V. Fonteneau R. and Ernst D. (####). How to discount deep reinforcement learning: Towards new dynamic strategies. In NIPS #### Workshop on Deep Reinforcement Learning. Hansen N. and Ostermeier A. (####). Completely derandomized self-adaptation in evolution strategies. Evol. Comput. Henderson P. Islam R. Bachman P. Pineau J. Precup D. and Meger D. (####a). Deep reinforcement learning that matters. In AAAI. Henderson P. Romoff J. and Pineau J. (####b). Where did my optimum go?: An empirical analysis of gradient descent optimization in policy gradient methods. CoRR abs/####.#####. Hutter F. Hoos H. H. and Leyton-Brown K. (####). Sequential model-based optimization for general algorithm conﬁguration. In International Conference on Learning and Intelligent Optimization. Igl M. Zintgraf L. M. Le T. A. Wood F. and Whiteson S. (####). Deep variational reinforcement learning for pomdps. In International Conference on Machine Learning. Jaderberg M. Dalibard V. Osindero S. Czarnecki W. M. Donahue J. Razavi A. Vinyals O. Green T. Dunning I. Simonyan K. et al. (####). Population based training of neural networks. arXiv preprint arXiv:####.#####. Kakade S. (####). A natural policy gradient. In Advances in Neural Information Processing Systems. Kandasamy K. Krishnamurthy A. Schneider J. and Póczos B. (####). Parallelised bayesian optimisation via thompson sampling. In International Conference on Artiﬁcial Intelligence and Statistics. Kearns M. J. and Singh S. P. (####). Bias-variance error bounds for temporal difference updates. In Conference on Learning Theory. Kingma D. P. and Ba J. (####). Adam: A method for stochastic optimization. CoRR abs/####.####. Klein A. Falkner S. Bartels S. Hennig P. and Hutter F. (####). Fast bayesian optimization of machine learning hyperparameters on large datasets. arXiv preprint arXiv:####.#####. Luketina J. Raiko T. Berglund M. and Greff K. (####). Scalable gradient-based tuning of continuous regularization hyperparameters. In International Conference on Machine Learning. Mahmood A. R. Korenkevych D. Vasan G. Ma W. and Bergstra J. (####). Benchmarking reinforcement learning algorithms on real-world robots. In Conference on Robot Learning. Mnih V. Badia A. P. Mirza M. Graves A. Lillicrap T. Harley T. Silver D. and Kavukcuoglu K. (####). Asynchronous methods for deep reinforcement learning. In International Conference on Machine Learning. Mordatch I. Lowrey K. Andrew G. Popovic Z. and Todorov E. V. (####). Interactive control of diverse complex characters with neural networks. In Advances in Neural Information Processing Systems. ## Pedregosa F. (####). Hyperparameter optimization with approximate gradient. arXiv preprint arXiv:####.#####. Rajeswaran A. Lowrey K. Todorov E. V. and Kakade S. M. (####). Towards generalization and simplicity in continuous control. In Advances in Neural Information Processing Systems. Schaul T. Horgan D. Gregor K. and Silver D. (####). Universal value function approximators. In International Conference on Machine Learning. Schulman J. Levine S. Abbeel P. Jordan M. and Moritz P. (####). Trust region policy optimiza- tion. In International Conference on Machine Learning. Schulman J. Moritz P. Levine S. Jordan M. and Abbeel P. (####). High-dimensional contin- uous control using generalized advantage estimation. In International Conference on Learning Representations. Shah A. and Ghahramani Z. (####). Parallel predictive entropy search for batch global optimization of expensive objective functions. In Advances in Neural Information Processing Systems pages ####–####. Snoek J. Larochelle H. and Adams R. P. (####). Practical bayesian optimization of machine learning algorithms. In Advances in Neural Information Processing Systems. Snoek J. Swersky K. Zemel R. and Adams R. (####). Input warping for bayesian optimization of non-stationary functions. In International Conference on Machine Learning. Srinivas N. Krause A. Kakade S. M. and Seeger M. (####). Gaussian process optimization in the bandit setting: no regret and experimental design. In International Conference on Machine Learning. Sutton R. S. (####). Adapting bias by gradient descent: An incremental version of delta-bar-delta. In AAAI. Sutton R. S. McAllester D. Singh S. and Mansour Y. (####). Policy gradient methods for reinforcement learning with function approximation. In Advances in Neural Information Processing Systems. Swersky K. Snoek J. and Adams R. P. (####). Multi-task bayesian optimization. In Advances in Neural Information Processing Systems. Swersky K. Snoek J. and Adams R. P. (####). Freeze-thaw bayesian optimization. arXiv preprint arXiv:####.####. Tieleman T. and Hinton G. (####). Lecture #.#-rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural networks for machine learning #(#):##–##. Wang J. Clark S. C. Liu E. and Frazier P. I. (####). Parallel bayesian global optimization of expensive functions. arXiv preprint arXiv:####.#####. White M. (####). Unifying task speciﬁcation in reinforcement learning. In International Conference on Machine Learning. White M. and White A. (####). A greedy approach to adapting the trace parameter for temporal difference learning. In Proceedings of the #### International Conference on Autonomous Agents & Multiagent Systems pages ###–###. International Foundation for Autonomous Agents and Multiagent Systems. Williams R. J. (####). Simple statistical gradient-following algorithms for connectionist reinforce- ment learning. Machine Learning. Xu Z. van Hasselt H. P. and Silver D. (####). Meta-gradient reinforcement learning. In Advances in Neural Information Processing Systems. ##\n",
            "response:  The performance of policy gradient methods is sensitive to hyperparameter settings that must be tuned for any new application. Widely used grid search methods for tuning hyperpara meters are sample inefficient and computationally expensive. More advanced methods like Population Based Training (Jaderberg et al. ####) that learn optimal schedules for hyperparamètres instead of fixed settings can yield better results but are also sample inefficiency and computationalLY expensive.\n",
            "summarize: Metric Learning with Multiple Kernels Jun Wang Huyen Do Adam Woznica Alexandros Kalousis {Jun.Wang Huyen.Do Adam.Woznica Alexandros.Kalousis}@unige.ch AI Lab Department of Informatics University of Geneva Switzerland Abstract Metric learning has become a very active research ﬁeld. The most popular representative–Mahalanobis metric learning–can be seen as learning a linear trans- formation and then computing the Euclidean metric in the transformed space. Since a linear transformation might not always be appropriate for a given learning problem kernelized versions of various metric learning algorithms exist. How- ever the problem then becomes ﬁnding the appropriate kernel function. Multiple kernel learning addresses this limitation by learning a linear combination of a number of predeﬁned kernels; this approach can be also readily used in the con- text of multiple-source learning to fuse different data sources. Surprisingly and despite the extensive work on multiple kernel learning for SVMs there has been no work in the area of metric learning with multiple kernel learning. In this paper we ﬁll this gap and present a general approach for metric learning with multiple kernel learning. Our approach can be instantiated with different metric learning algorithms provided that they satisfy some constraints. Experimental evidence suggests that our approach outperforms metric learning with an unweighted ker- nel combination and metric learning with cross-validation based kernel selection. # Introduction Metric learning (ML) which aims at learning dissimilarities by determining the importance of dif- ferent input features and their correlations has become a very active research ﬁeld over the last years [## # # ## ## # ##]. The most prominent form of ML is learning the Mahalanobis metric. Its computation can be seen as a two-step process; in the ﬁrst step we perform a linear projection of the instances and in the second step we compute their Euclidean metric in the projected space. Very often a linear projection cannot adequately represent the inherent complexities of a problem at hand. To address this limitation various works proposed kernelized versions of ML methods in order to implicitly compute a linear transformation and Euclidean metric in some non-linear feature space; this computation results in a non-linear projection and distance computation in the original input space [## # # ## ##]. However we are now faced with a new problem namely that of ﬁnding the appropriate kernel function and the associated feature space matching the requirements of the learning problem. The simplest approach to address this problem is to select the best kernel from a predeﬁned kernel set using internal cross-validation. The main drawback of this approach is that only one kernel is selected which limits the expressiveness of the resulting method. Additionally this approach is limited to a small number of kernels–due to computational constraints–and requires the use of extra data. Multiple Kernel Learning (MKL) [## ##] lifts the above limitations by learning a linear combination of a number of predeﬁned kernels. The MKL approach can also naturally handle the multiple-source learning scenarios where instead of combining kernels deﬁned on a single input data which depending on the selected kernels could give rise to feature spaces with redundant # features we combine different and complementary data sources. In [## ##] the authors propose a method that learns a distance metric for multiple-source problems within a multiple-kernel scenario. The proposed method deﬁnes the distance of two instances as the sum of their distances in the feature spaces induced by the different kernels. During learning a set of Mahalanobis metrics one for each source are learned together. However this approach ignores the potential correlations between the different kernels. To the best of our knowledge most of the work on MKL has been conﬁned in the framework of SVMs and despite the recent popularity of ML there exists so far no work that performs MKL in the ML framework by learning a distance metric in the weighted linear combination of feature spaces. In this paper we show how to perform the Mahalanobis ML with MKL. We ﬁrst propose a general framework of ML with MKL which can be instantiated with virtually any Mahalanobis ML algo- rithm h provided that the latter satisﬁes some stated conditions. We examine two parametrizations of the learning problem that give rise to two alternative formulations denoted by MLh-MKLµ and MLh-MKLP. Our approach can be seen as the counterpart of MKL with SVMs [## ## ##] for ML. Since the learned metric matrix has a regularized form (i.e. it has internal structure) we propose a straightforward non-regularized version of ML with MKL denoted by NR-MLh-MKL; however due to the number of free parameters the non-regularized version can only scale with very small number of kernels and requires ML methods that are able to cope with large dimensionalities. We performed a number of experiments for ML with MKL in which for the needs of this paper we have cho- sen the well known Large Margin Nearest Neighbor [##] (LMNN) algorithm as the ML method h. The experimental results suggest that LMNN-MKLP outperforms LMNN with an unweighted kernel combination and the single best kernel selected by internal cross-validation. # Preliminaries In the different ﬂavors of metric learning we are given a matrix of learning instances X : n × d the i ∈ Rd instance and a vector of class labels y = (y# . . . yn)T yi ∈ i-th row of which is the xT {# . . . c}. Consider a mapping Φl(x) of instances x to some feature space Hl i.e. x → Φl(x) ∈ Hl. The corresponding kernel function kl(xi xj) computes the inner product of two instances in the Hl feature space i.e. kl(xi xj) = (cid:###)Φl(xi) Φl(xj)(cid:###). We denote dimensionality of Hl (possibly inﬁnite) as dl. The squared Mahalanobis distance of two instances in the Hl space (Φl(xi) Φl(xj)) = (Φl(xi) − Φl(xj))T Ml(Φl(xi) − Φl(xj)) where Ml is is given by d# a Positive Semi-Deﬁnite (PSD) metric matrix in the Hl space (Ml (cid:##) #). For some given ML method h we optimize (most often minimize) some cost function Fh with respect to the Ml met- ric matrix# under the PSD constraint for Ml and an additional set of pairwise distance constraints Ch({d# (Φl(xi) Φl(xj)) | i j = # . . . n}) that depend on the choice of h e.g. similarity and dissimilarity pairwise constraint [#] and relative comparison constraint [##]. In the reminder of this paper for simplicity we denote this set of constraints as Ch(d# (Φl(xi) Φl(xj))). The kernelized ML optimization problem can be now written as: s.t. Ch(d# (Φl(xi) Φl(xj))) Ml (cid:##) # Fh(Ml) (#) Ml Ml Ml Ml min Ml Kernelized ML methods do not require to learn the explicit form of the Mahalanobis metric Ml. It was shown in [#] that the optimal solution of the Mahalanobis metric Ml is in the form of Ml = ηhI + Φl(X)T AlΦl(X) where I is the identity matrix of dimensionality dl × dl Al is a n × n PSD matrix Φl(X) is the matrix of learning instances in the Hl space (with instances in rows) and ηh is a constant that depends on the ML method h. Since in the vast majority of the existing ML methods [## # ## ## # ## ##] the value of constant ηh is zero in this paper we only consider the optimal form of Ml with ηh = #. Under the optimal parametrization of Ml = Φl(X)T AlΦl(X) the squared Mahalanobis distance becomes: (Φl(xi) Φl(xj)) = (Ki (#) d# Ml l is the i-th column of kernel matrix Kl the (i j) element of which is Klij = kl(xi xj). (Φl(xi) Φl(xj)) l )T Al(Ki l ) = d# Al l − Kj l − Kj where Ki As a result (#) can be rewritten as: min Al Fh(Φl(X)T AlΦl(X)) s.t. Ch(d# Al (Φl(xi) Φl(xj))) Al (cid:##) # (#) #The optimization could also be done with respect to other variables of the cost function and not only Ml. However to keep the notation uncluttered we parametrize the optimization problem only over Ml. # In MKL we are given a set of kernel functions Z = {kl(xi xj) | l = # . . . m} and the goal is to learn an appropriate kernel function kµ(xi xj) parametrized by µ under a cost function Q. The cost function Q is determined by the cost function of the learning method that is coupled with multiple kernel learning e.g. it can be the SVM cost function if one is using an SVM as the learning approach. As in [## ##] we parametrize kµ(xi xj) by a linear combination of the form: µlkl(xi xj) µl ≥ # kµ(xi xj) = (#) We denote the feature space that is induced by the kµ kernel by Hµ feature space which is given by the mapping x → Φµ(x) = ( µmΦm(x)T )T ∈ Hµ. We denote the dimen- sionality of Hµ by d; it can be inﬁnite. Finally we denote by H the feature space that we get by the unweighted concatenation of the m feature spaces i.e. ∀µi µi = # whose representation is given by x → Φ(x) = (Φ#(x)T . . . Φm(x)T )T . µ#Φ#(x)T . . . µl = # √ √ i=l l m(cid:##) m(cid:##) # Metric Learning with Multiple Kernel Learning The goal is to learn a metric matrix M in the feature space Hµ induced by the mapping Φµ as well as the kernel weight µ; we denote this metric by d# M µ. Based on the optimal form of the Mahalanobis metric M for metric learning method learning with a single kernel function [#] we have the following lemma: Lemma #. Assume that for a metric learning method h the optimal parameterization of its Maha- lanobis metric M∗ is Φl(X)T A∗Φl(X) for some A∗ when learning with a single kernel function kl(x x(cid:##)). Then for h with multiple kernel learning the optimal parametrization of its Mahalanobis metric M∗∗ is given by Φµ(X)T A∗∗Φµ(X) for some A∗∗. The proof of the above Lemma is similar to the proof of Theorem # in [#] (it is not presented here due to the lack of space). Following Lemma # we have: M µ(Φµ(xi) Φµ(xj)) = d# (Φµ(xi) − Φµ(xj))T Φµ(X)T AΦµ(X)(Φµ(xi) − Φµ(xj)) (#) A µ(Φµ(xi) Φµ(xj)) = (cid:##) l )T A(cid:##) l − Kj l − Kj l ) = d# µl(Ki µl(Ki l l Based on (#) and the constraints from (#) the ML optimization problem with MKL can be presented as: min A µ Fh(Φµ(X)T AΦµ(X)) s.t. Ch(d# A µ(Φµ(xi) Φµ(xj))) A (cid:##) # µl ≥ # µl = #(#) m(cid:##) l We denote the resulting optimization problem and the learning method by MLh-MKLµ; clearly this is not fully speciﬁed until we choose a speciﬁc ML method h.  (Ki (Ki # − Kj . . . m − Kj #)T m)T . We note that d# Let B = as: A µ(Φµ(xi) Φµ(xj)) from (#) can also be written A µ(Φµ(xi) Φµ(xj)) = µT BABTµ = tr(PBABT) = d# d# (#) where P = µµT and tr(·) is the trace of a matrix. We use ΦP(X) to emphasize the explicit the dependence of Φµ(X) to P = µµT . As a result instead of optimizing over µ we can also use the parametrization over P; the new optimization problem can now be written as: min A P A P(ΦP(xi) ΦP(xj)) (#) Pij = # Pij ≥ # Rank(P) = # P = PT Fh(ΦP(X)T AΦP(X)) Ch(d# A P(ΦP(xi) ΦP(xj))) A (cid:##) # ij Pij = # Pij ≥ # Rank(P) = # and P = PT are added so that P = µµT . We call the optimization problem and learning method (#) as MLh-MKLP; as before in order to fully instantiate it we need to choose a speciﬁc metric learning method h. s.t. where the constraints(cid:##) (cid:##) ij # Now we derive an alternative parametrization of (#). We need two additional matrices: Cµiµj = µiµjI where the dimensionality of I is n × n and Φ (X) which is an mn × d dimensional matrix: . . . . . . . . . Φm(X) (cid:##) Φ#(X) (X) = # . . . . . . # (cid:##) Φ (cid:##) (cid:##) We have: A µ(Φµ(xi) Φµ(xj)) = (Φ(xi) − Φ(xj))T M d# (cid:##) (Φ(xi) − Φ(xj)) where: and A(cid:##) is a mn × mn matrix: A(cid:##) = (cid:##) M (cid:##) = Φ (cid:##) (X)T A(cid:##)Φ (cid:##) Cµ#µ#A . . . Cµ#µmA (X) . . . . . . . . . Cµmµ#A . . . CµmµmA (cid:##) . (#) (##) (##) From (#) we see that the Mahalanobis metric parametrized by the M or A matrix in the feature space Hµ induced by the kernel kµ is equivalent to the Mahalanobis metric in the feature space H which is parametrized by M(cid:##) or A(cid:##). As we can see from (##) MLh-MKLµ and MLh-MKLP learn a regularized matrix A(cid:##) (i.e. matrix with internal structure) that corresponds to a parametrization of the Mahalanobis metric M(cid:##) in the feature space H. #.# Non-Regularized Metric Learning with Multiple Kernel Learning We present here a more general formulation of the optimization problem (#) in which we lift the regularization of matrix A(cid:##) from (##) and learn instead a full PSD matrix A(cid:##)(cid:##): (cid:##) A## A(cid:##)(cid:##) = . . . A#m . . . . . . . . . A#m . . . Amm (cid:##) (##) where Akl is an n × n matrix. The respective Mahalanobis matrix which we denote by M(cid:##)(cid:##) still (cid:##) (cid:##) have the same parametrization form as in (##) i.e. M(cid:##)(cid:##) = Φ (X). As a result by using A(cid:##)(cid:##) instead of A(cid:##) the squared Mahalanobis distance can be written now as: (X)T A(cid:##)(cid:##)Φ A(cid:##)(cid:##)(Φ(xi) Φ(xj)) = (Φ(xi) − Φ(xj))T M d# m)T ]A(cid:##)(cid:##)[(Ki = [(Ki = [ΦZ(xi) − ΦZ(xj)]T A(cid:##)(cid:##)(ΦZ(xi) − ΦZ(xj)] #)T . . . (Ki m − Kj # − Kj (cid:##)(cid:##) (Φ(xi) − Φ(xj)) # − Kj #)T . . . (Ki m − Kj m)T ]T (##) m)T )T ∈ HZ. What we see here is that under the M(cid:##)(cid:##) where ΦZ(xi) = ((Ki parametrization computing the Mahalanobis metric in the H is equivalent to computing the Ma- halanobis metric in the HZ space. Under the parametrization of the Mahalanobis distance given by (##) the optimization problem of metric learning with multiple kernel learning is the following: #)T . . . (Ki (cid:##) A(cid:##)(cid:##) Fh(Φ min (cid:##) (X)T A(cid:##)(cid:##)Φ (X)) s.t. Ch(d# A(cid:##)(cid:##)(Φ(xi) Φ(xj))) A(cid:##)(cid:##) (cid:##) # (##) We call this optimization problem NR-MLh-MKL. We should note that this formulation has scaling problems since it has O(m#n#) parameters that need to be estimated and it clearly requires a very efﬁcient ML method h in order to be practical. # Optimization #.# Analysis The NR-MLh-MKL optimization problem obviously has the same convexity properties as the metric (cid:##) learning algorithm h that will be used since the parametrization M(cid:##)(cid:##) = Φ (X) used in NR-MLh-MKL is linear with A(cid:##)(cid:##) and the composition of a function with an afﬁne mapping preserves (cid:##) (X)T A(cid:##)(cid:##)Φ # the convexity property of the original function [#]. This is also valid for the subproblems of learning matrix A in MLh-MKLµ and MLh-MKLP given the weight vector µ. Given the PSD matrix A we have the following two lemmas for optimization problems MLh- MKL{µ|P}: Lemma #. Given the PSD matrix A the MLh-MKLµ optimization problem is convex with µ if metric learning algorithm h is convex with µ. Proof. The last two constraints on µ of the optimization problem from (#) are linear thus this problem is convex if metric learning algorithm h is convex with µ. A µ(Φµ(xi) Φµ(xj)) is convex quadratic of µ which can be easily proved based on the Since d# PSD property of matrix BABT in (#) many of the well known metric learning algorithms such as Pairwise SVM [##] POLA [##] and Xing’s method [##] satisfy the conditions in Lemma #. The MLh-MKLP optimization problem (#) is not convex given a PSD matrix A because the rank constraint is not convex. However when the number of kernels m is small e.g. a few tens of kernels there is an equivalent convex formulation. Lemma #. Given the PSD matrix A the MLh-MKLP optimization problem (#) can be formulated as an equivalent convex problem with respect to P if the ML algorithm h is linear with P and the number of kernel m is small. Proof. Given the PSD matrix A if h is linear with P we can formulate the rank constraint problem with the help of the two following convex problems [#]: Fh(ΦP(X)T AΦP(X)) + w · tr(PT W) Ch(d# A P(ΦP(xi) ΦP(xj))) A (cid:##) # P (cid:##) # Pij = # Pij ≥ # P = PT (cid:##) min P (##) s.t. where w is a positive scalar just enough to make tr(PT W) vanish i.e. global convergence deﬁned in (##) and the direction matrix W is an optimal solution of the following problem: ij min W tr(P∗T W) s.t. # (cid:##) W (cid:##) I tr(W) = m − # (##) where P∗ is an optimal solution of (##) given A and W and m is the number of kernels. The problem (##) has a closed form solution W = UUT where U ∈ Rm×m−# is the eigenvector matrix of P∗ whose columns are the eigenvectors which correspond to the m − # smallest eigenvalues of P∗. The two convex problems are iteratively solved until global convergence deﬁned as: m(cid:##) λ(P∗)i = tr(P∗T W∗) = λ(P∗)T λ(W∗) ≡ # (##) i=# where λ(P∗)i is the i-th largest eigenvalue of P∗. This formulation is not a projection method. At global convergence the convex problem (##) is not a relaxation of the original problem instead it is an equivalent convex problem [#]. We will now prove the convergence of problem (##). Suppose the objective value of (##) is fi at iteration i. Since both (##) and (##) minimize the objective value of (##) we have fj < fi for any iteration j > i. Beacuse the inﬁmum f∗ of the objective value of (##) corresponds to the optimal objective value of (##) when the second term is removed. Thus the nonincreasing sequence of objective values is bounded below and as a result converges because any bounded monotonic sequence in R is convergent. Thus the local convergence of (##) is now established. Only the local convergence can be established for problem (##) because the objective tr(PT W) is generally multimodal [#]. However as indicated in section #.# [#] when the size of m is small the global optimal of problem (##) can be often achieved. This can be simply veriﬁed by comparing the difference between the inﬁmum f∗ and the optimal objective value f of problem (##). For a number of known metric learning algorithms such as LMNN [##] POLA [##] MLSVM [##] and Xing’s method [##] linearity with respect to P holds given A (cid:##) #. # Algorithm # MLh-MKLµ MLh-MKLP Input: X Y A# µ# and matrices K# . . . Km Output: A and µ repeat Kµ(i) =(cid:##) µ(i)=WeightLearning(A(i−#)) A(i)=MetricLearningh(A(i−#) X Kµ(i)) i := i + # kKk k µi until convergence #.# Optimization Algorithms The NR-MLh-MKL optimization problem can be directly solved by any metric learning algorithm h on the space HZ when the optimization problem of the latter only involves the squared pairwise Mahalanobis distance e.g. LMNN [##] and MCML [#]. When the metric learning algorithm h has regularization term on M e.g. trace norm [#] and Frobenius norm [## ##] most often the NR-MLh-MKL optimization problem can be solved by a slightly modiﬁcation of original algorithm. We now describe how we can solve the optimization problems of MLh-MKLµ and MLh-MKLP. Based on Lemmas # and # we propose for both methods a two-step iterative algorithm Algorithm # at the ﬁrst step of which we learn the kernel weighting and at the second the metric under the kernel weighting learned in the ﬁrst step. At the ﬁrst step of the i-th iteration we learn the µ(i) kernel weight vector under ﬁxed PSD matrices A(i−#) learned at the preceding iteration (i − #). For MLh-MKLµ we solve the weight learning problem using Lemma # and for MLh-MKLP using Lemma #. At the second step we apply the metric learning algorithm h and we learn the PSD matrices A(i) with l Ki kernel matrix using as the initial metric matrices the A(i−#). We should make clear that the optimization problem we are solving is only individually convex with respect to µ given the PSD matrix A and vice-versa. As a result the convergence of the two-step algorithm (possible to a local optima) is guaranteed [#] and checked by the variation of µ and the objective value of metric learning method h. In our experiments (Section #) we observed that it most often converges in less than ten iterations. the Kµ(i) = (cid:##) l µ(i) # LMNN-Based Instantiation We have presented two basic approaches to metric learning with multiple kernel learning: MLh- MKLµ (MLh-MKLP) and NR-MLh-MKL. In order for the approaches to be fully instantiated we have to specify the ML algorithm h. In this paper we focus on the LMNN state-of-the-art method [##]. Due to the relative comparison constraint LMNN does not satisfy the condition of Lemma #. How- ever as we already mentioned LMNN satisﬁes the condition of Lemma # so we get the MLh-MKLP variant of the optimization problem for LMNN which we denote by LMNN-MKLP. The resulting optimization problem is: A P(ΦP(xi) ΦP(xj)) + γ (# − Yik)ξijk} (##) Sij{(# − γ)d# (cid:##) (cid:##) ij A P(ΦP(xi) ΦP(xk)) − d# d# min A P ξ s.t. (cid:##) k A P(ΦP(xi) ΦP(xj)) ≥ # − ξijk ξijk > # A (cid:##) # Pkl = # Pkl ≥ # Rank(P) = # P = PT kl where the matrix Y Yij ∈ {# #} indicates if the class labels yi and yj are the same (Yij = #) or different (Yij = #). The matrix S is a binary matrix whose Sij entry is non-zero if instance xj is one of the k same class nearest neigbors of instance xi. The objective is to minimize the sum of the distances of all instances to their k same class nearest neighbors while allowing for some errors trade of which is controlled by the γ parameter. As the objective function of LMNN only involves the squared pairwise Mahalanobis distances the instantiation of NR-MLh-MKL is straightforward and it consists simply of the application of LMNN on the space HZ in order to learn the metric. We denote this instantiation by NR-LMNN-MKL. # Table #: Accuracy results. The superscripts +−= next to the accuracies of NR-LMNN-MKLand LMNN-MKLPindicate the result of the McNemar’s statistical test of their comparison to the accura- cies of LMNNHand LMNN-MKLCV and denote respectively a signiﬁcant win loss or no difference. The number in the parenthesis indicates the score of the respective algorithm for the given dataset based on the pairwise comparisons of the McNemar’s statistical test. Datasets Sonar Wine Iris Ionosphere Wdbc CentralNervous Colon Leukemia MaleFemale Ovarian Prostate Stroke Total Score NR-LMNN-MKL ##.##+=(#.#) ##.##==(#.#) ##.##==(#.#) ##.##==(#.#) ##.##−=(#.#) ##.##==(#.#) ##.##==(#.#) ##.##+=(#.#) ##.##==(#.#) ##.##+=(#.#) ##.##==(#.#) ##.##==(#.#) ##.# LMNN-MKLP ##.##==(#.#) ##.##==(#.#) ##.##==(#.#) ##.##=+(#.#) ##.##=+(#.#) ##.##==(#.#) ##.##+=(#.#) ##.##+=(#.#) ##.##+=(#.#) ##.##+=(#.#) ##.##==(#.#) ##.##==(#.#) ##.# LMNNH ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.# LMNN-MKLCV ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.# #-NN ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.##(#.#) ##.# # Experiments In this section we perform a number of experiments on real world datasets in order to compare the two of the LMNN-based instantiations of our framework i.e. LMNN-MKLP and NR-LMNN-MKL. We compare these methods against two baselines: LMNN-MKLCV in which a kernel is selected from a set of kernels using #-fold inner cross-validation (CV) and LMNN with the unweighted sum of kernels which induces the H feature space denoted by LMNNH. Additionally we report performance of #-Nearest-Neighbor denoted as #-NN with no metric learning. The PSD matrix A and weight vector µ in LMNN-MKLP were respectively initialized by I and equal weighting (# divided by the number of kernels). The parameter w in the weight learning subproblem of LMNN- MKLP was selected from {##i | i = # # . . . #} and was the smallest value enough to achieve Its direction matrix W was initialized by #. The number of k same class global convergence. nearest neighbors required by LMNN was set to # and its γ parameter to #.#. After learning the metric and the multiple kernel combination we used #-NN for classiﬁcation. #.# Benchmark Datasets We ﬁrst experimented with ## different datasets: ﬁve from the UCI machine learning repository i.e. Sonar Ionosphere Wine Iris and Wdbc; three microarray datasets i.e. CentralNervous Colon and Leukemia; and four proteomics datasets i.e. MaleFemale Stroke Prostate and Ovarian. The attributes of all the datasets are standardized in the preprocessing step. The Z set of kernels that we use consists of the following ## kernels: ## polynomial with degree from one to ten ten Gaussians with bandwidth σ ∈ {#.# # # # # ## ## ## ## ##} (the same set of kernels was used in [#]). Each basic kernel Kk was normalized by the average of its diag(Kk). LMNN-MKLP LMNNH and LMNN-MKLCV were tested using the complete Z set. For NR-LMNN-MKL due to its scaling limi- tations we could only use a small subset of Z consisting of the linear the second order polynomial and the Gaussian kernel with the kernel width of #.#. We use ##-fold CV to estimate the predictive performance of the different methods. To test the statistical signiﬁcance of the differences we used McNemar’s test and we set the p-value to #.##. To get a better understanding of the relative per- formance of the different methods for a given dataset we used a ranking schema in which a method A was assigned one point if its accuracy was signiﬁcantly better than that of another method B #.# points if the two methods did not have a signiﬁcantly different performance and zero points if A was found to be signiﬁcantly worse than B. The results are reported in Table #. First we observe that by learning the kernel inside LMNN- MKLP we improve performance over LMNNH that uses the unweighted kernel combination. More precisely LMNN-MKLP is signiﬁcantly better than LMNNH in four out of the thirteen datasets. If we now compare LMNN-MKLP with LMNN-MKLCV the other baseline method where we select the best kernel with CV we can see that LMNN-MKLP also performs better being statistically signiﬁcant # Table #: Accuracy results on the multiple source datasets. Datasets Multiple Feature Oxford Flowers LMNN-MKLP ##.##++(#.#) ##.##++(#.#) LMNNH ##.##(#.#) ##.##(#.#) LMNN-MKLCV ##.##(#.#) ##.##(#.#) #-NN ##.##(#.#) ##.##(#.#) better in two dataset. If we now examine NR-LMNN-MKL and LMNNH we see that the former method even though learning with only three kernels is signiﬁcantly better in two datasets while it is signiﬁcantly worse in one dataset. Comparing NR-LMNN-MKL and LMNN-MKLCV we observe that the two methods achieve comparable predictive performances. We should stress here that NR- LMNN-MKL has a disadvantage since it only uses three kernels as opposed to other methods that use ## kernels; the scalability of NR-LMNN-MKL is left as a future work. In terms of the total score that the different methods obtain the best one is LMNN-MKLP followed by LMNN-MKLCV and NR-LMNN-MKL. #.# Multiple Source Datasets To evaluate the proposed method on problems with multiple sources of information we also perform experiments on the Multiple Features and the Oxford ﬂowers datasets [##]. Multiple Features from UCI has six different feature representations for # ### handwritten digits (#-#); each class has ### instances. In the preprocessing step all the features are standardized in all the data sources. Oxford ﬂowers dataset has ## category ﬂower images; each class has ## instances. In the experiment seven distance matrices from the website# are used; these matrices are precomputed respectively from seven features the details of which are described in [## ##]. For both datasets Gaussian kernels are constructed respectively using the different feature representations of instances with kernel width σ# where σ# is the mean of all pairwise distances. We experiment with ## random splits where half of the data is used for training and the other half for testing. We do not experiment here with NR-LMNN-MKL here due to its scaling limitations. The accuracy results are reported in Table #. We can see that by learning a linear combination of different feature representations LMNN-MKLP achieves the best predictive performance on both datasets being signiﬁcantly better than the two baselines LMNNH and LMNN-MKLCV . The bad performance of LMNN-MKLCV on the Oxford ﬂowers dataset could be explained by the fact that the different Gaussian kernels are complementary for the given problem but in LMNN-MKLCV only one kernel is selected. # Conclusions In this paper we combine two recent developments in the ﬁeld of machine learning namely metric learning and multiple kernel learning and propose a general framework for learning a metric in a feature space induced by a weighted combination of a number of individual kernels. This is in contrast with the existing kernelized metric learning techniques which consider only one kernel function (or possibly an unweighted combination of a number of kernels) and hence are sensitive to the selection of the associated feature space. The proposed framework is general as it can be coupled with many existing metric learning techniques. In this work to practically demonstrate the effectiveness of the proposed approach we instantiate it with the well know LMNN metric learning method. The experimental results conﬁrm that the adaptively induced feature space does bring an advantage in the terms of predictive performance with respect to feature spaces induced by an unweighted combination of kernels and the single best kernel selected by internal CV. Acknowledgments This work was funded by the Swiss NSF (Grant ######-######/#). The support of the European Commission through EU projects DebugIT (FP#-######) and e-LICO (FP#-######) is also grate- fully acknowledged. # # References [#] S.P. Boyd and L. Vandenberghe. Convex optimization. Cambridge Univ Pr ####. [#] J. Dattorro. Convex optimization & Euclidean distance geometry. Meboo Publishing USA ####. [#] J.V. Davis B. Kulis P. Jain S. Sra and I.S. Dhillon. Information-theoretic metric learning. In ICML ####. [#] K. Gai G. Chen and C. Zhang. Learning kernels with radiuses of minimum enclosing balls. NIPS ####. [#] A. Globerson and S. Roweis. Metric learning by collapsing classes. In NIPS ####. [#] L. Grippo and M. Sciandrone. On the convergence of the block nonlinear gauss-seidel method under convex constraints* #. Operations Research Letters ##(#):###–### ####. [#] M. Guillaumin J. Verbeek and C. Schmid. Is that you? Metric learning approaches for face identiﬁcation. In ICCV pages ###–### ####. [#] K. Huang Y. Ying and C. Campbell. Gsml: A uniﬁed framework for sparse metric learning. In Data Mining ####. ICDM’##. Ninth IEEE International Conference on pages ###–###. IEEE ####. [#] P. Jain B. Kulis and I. Dhillon. ####. Inductive regularized learning of kernel functions. NIPS [##] G.R.G. Lanckriet N. Cristianini P. Bartlett L. El Ghaoui and M.I. Jordan. Learning the Kernel Matrix with Semideﬁnite Programming. Journal of Machine Learning Research #:##– ## ####. [##] B. McFee and G. Lanckriet. Partial order embedding with multiple kernels. In Proceedings of the ##th Annual International Conference on Machine Learning pages ###–###. ACM ####. [##] B. McFee and G. Lanckriet. Metric learning to rank. In ICML. ACM New York NY USA ####. [##] B. McFee and G. Lanckriet. Learning multi-modal similarity. The Journal of Machine Learn- ing Research ##:###–### ####. [##] N. Nguyen and Y. Guo. Metric Learning: A Support Vector Approach. In ECML/PKDD ####. [##] M.E. Nilsback and A. Zisserman. A visual vocabulary for ﬂower classiﬁcation. In Computer Vision and Pattern Recognition #### IEEE Computer Society Conference on volume # pages ####–####. Ieee ####. [##] M.E. Nilsback and A. Zisserman. Automated ﬂower classiﬁcation over a large number of classes. In Computer Vision Graphics & Image Processing ####. ICVGIP’##. Sixth Indian Conference on pages ###–###. IEEE ####. [##] A. Rakotomamonjy F. Bach S. Canu and Y. Grandvalet. SimpleMKL. Journal of Machine Learning Research #:####–#### ####. [##] M. Schultz and T. Joachims. Learning a distance metric from relative comparisons. In NIPS ####. [##] S. Shalev-Shwartz Y. Singer and A.Y. Ng. Online and batch learning of pseudo-metrics. In Proceedings of the twenty-ﬁrst international conference on Machine learning. ACM ####. [##] S. Sonnenburg G. Ratsch and C. Schafer. A general and efﬁcient multiple kernel learning algorithm. In NIPS ####. [##] J.P. Vert J. Qiu and W. Noble. A new pairwise kernel for biological network inference with support vector machines. BMC bioinformatics #(Suppl ##):S# ####. [##] K.Q. Weinberger and L.K. Saul. Distance metric learning for large margin nearest neighbor classiﬁcation. The Journal of Machine Learning Research ##:###–### ####. [##] E.P. Xing A.Y. Ng M.I. Jordan and S. Russell. Distance metric learning with application to clustering with side-information. In NIPS ####. #\n",
            "response:  Metric learning has become a very active research field. The most popular representative---Mahalanobis metric learning---can be seen as learning a linear transformation and then computing the Euclidean metric in the transformed space. Since a given learning problem kernelized versions of various metric learn algorithms exist. However the problem then becomes finding the appropriate kernel function.\n",
            "summarize: Implicit Regularization of Accelerated Methods in Hilbert Spaces Nicolò Pagliana University of Genoa DIMA & MaLGa pagliana@dima.unige.it Lorenzo Rosasco University of Genoa DIBRIS MaLGa IIT & MIT lrosasco@mit.edu Abstract We study learning properties of accelerated gradient descent methods for linear least-squares in Hilbert spaces. We analyze the implicit regularization properties of Nesterov acceleration and a variant of heavy-ball in terms of corresponding learning error bounds. Our results show that acceleration can provides faster bias decay than gradient descent but also suffers of a more unstable behavior. As a result acceleration cannot be in general expected to improve learning accuracy with respect to gradient descent but rather to achieve the same accuracy with reduced computations. Our theoretical results are validated by numerical simulations. Our analysis is based on studying suitable polynomials induced by the accel- erated dynamics and combining spectral techniques with concentration inequalities. # Introduction The focus on optimization is a major trend in modern machine learning where efﬁciency is mandatory in large scale problems [#]. Among other solutions ﬁrst order methods have emerged as methods of choice. While these techniques are known to have potentially slow convergence guarantees they also have low iteration costs ideal in large scale problems. Consequently the question of accelerating ﬁrst order methods while keeping their small iteration costs have received much attention see e.g. [##]. Since machine learning solutions are typically derived minimizing an empirical objective (the training error) most theoretical studies have focused on the error estimated for this latter quantity. However it has recently become clear that optimization can play a key role from a statistical point of view when the goal is to minimize the expected (test) error. On the one hand iterative optimization implicitly bias the search for a solution e.g. converging to suitable minimal norm solutions [##]. On the other hand the number of iterations parameterize paths of solutions of different complexity [##]. The idea that optimization can implicitly perform regularization has a long history. In the context of linear inverse problems it is known as iterative regularization [##]. It is also an old trick for training neural networks where it is called early stopping [##]. The question of understanding the generalization properties of deep learning applications has recently sparked a lot of attention on this approach which has be referred to as implicit regularization see e.g. [##]. Establishing the regularization properties of iterative optimization requires the study of the corresponding expected error by combining optimization and statistical tools. First results in this sense focused on linear least squares with gradient descent and go back to [# ##] see also [##] and references there in for improvements. Subsequent works have started considering other loss functions [##] multi-linear models [##] and other optimization methods e.g. stochastic approaches [## ## ##]. In this paper we consider the implicit regularization properties of acceleration. We focus on linear least squares in Hilbert space because this setting allows to derive sharp results and working in inﬁnite dimension magnify the role of regularization. Unlike in ﬁnite dimension learning bounds are ##rd Conference on Neural Information Processing Systems (NeurIPS ####) Vancouver Canada. possible only if some form of regularization is considered. In particular we consider two of the most popular accelerated gradient approaches based on Nesterov acceleration [##] and (a variant of) the heavy-ball method [##]. Both methods achieve acceleration by exploiting a so called momentum term which uses not only the previous but the previous two iterations at each step. Considering a suitable bias-variance decomposition our results show that accelerated methods have a behavior qualitatively different from basic gradient descent. While the bias decays faster with the number of iterations the variance increases faster too. The two effect balance out showing that accelerated methods achieve the same optimal statistical accuracy of gradient descent but they can indeed do this with less computations. Our analysis takes advantage of the linear structures induced by least squares to exploit tools from spectral theory. Indeed the characterization of both convergence and stability rely on the study of suitable spectral polynomials deﬁned by the iterates. While the idea that accelerated methods can be more unstable this has been pointed out in [##] in a pure optimization context. Our results quantify this effect from a statistical point of view. Close to our results is the study in [#] where a stability approach is considered to analyze gradient methods for different loss functions [#]. # Learning with (accelerated) gradient methods Let the input space X be a separable Hilbert space (with scalar product (cid:###)· ·(cid:###) and induced norm (cid:###)·(cid:###)) and the output space be R #. Let ρ be a unknown probability measure on the input-output space X × R ρX the induced marginal probability on X and ρ(·|x) the conditional probability measure on R given x ∈ X. We make the following standard assumption: there exist κ > # such that (cid:###)x x(cid:##)(cid:###) ≤ κ# ∀x x(cid:##) ∈ X ρX-almost surely. The goal of least-squares linear regression is to solve the expected risk minimization problem (cid:##) E(w) E(w) = inf w∈X X×R ((cid:###)w x(cid:###) − y)# dρ(x y) (#) (#) n(cid:##) i=# where ρ is known only through the n i.i.d. samples (x# y#) . . . (xn yn). In the following we measure the quality of an approximate solution ˆw with the excess risk E( ˆw) − inf E . X The search of a solution is often based on replacing (#) with the empirical risk minimization (ERM) ˆE(w) min w∈X ˆE(w) = # n ((cid:###)w xi(cid:###) − yi)# . (#) For least squares an ERM solution can be computed in closed form using a direct solver. However for large problems iterative solvers are preferable and we next describe the approaches we consider. First it is useful to rewrite the ERM with vectors notation. Let y ∈ Rn with (y)i = yi and X : X → Rn s.t. (X w)i = (cid:###)w xi(cid:###) for i = # . . . n. Here the norm (cid:###)·(cid:###)n is norm in Rn multiplied by √ i=# xiyi. Then ERM becomes #/ (#) n. Let X∗ : Rn → X be the adjoint of X deﬁned by X∗ y = # ˆE(w) = (cid:###)X w − y(cid:###)# n . (cid:##)n n min w∈X #.# Gradient descent and accelerated methods Gradient descent serves as a reference approach throughout the paper. For problem (#) it becomes ˆwt+# = ˆwt − α X∗ (X ˆwt − y) (#) # The progress made by gradient with initial point ˆw# = # and the step-size α that satisfy α < # κ# descent at each iteration can be slow and the idea behind acceleration is to use the information of the previous directions in order to improves the convergence rate of the algorithm. #As shown in Appendix this choice allows to recover nonparametric kernel learning as a special case. # The step-size α is the step-size at the t-th iteration and satisﬁes the condition # < α(cid:###)X(cid:###)# op < # where (cid:###)·(cid:###)op denotes the operatorial norm. Since the operator X is bounded by κ (which means (cid:###)X(cid:###)op ≤ κ) it is sufﬁcient to assume α < # κ# . # Heavy-ball Heavy-ball is a popular accelerated method that adds the momentum ˆwt − ˆwt−# at each iteration ˆwt+# = ˆwt − α X∗ (X ˆwt − y) + β( ˆwt − ˆwt−#) (#) with α β ≥ # the case β = # reduces to gradient descent. In the quadratic case we consider it is also called Chebyshev iterative method. The optimization properties of heavy-ball have been studied extensively [## ##]. Here we consider the following variant. Let ν > # consider the varying parameter heavy-ball replacing α β in (#) with αt+# βt+# deﬁned as: αt = # κ# (#t + #ν − #)(t + ν − #) (t + #ν − #)(#t + #ν − #) (t − #)(#t − #)(#t + #ν − #) βt = (t + #ν − #)(#t + #ν − #)(#t + #ν − #) for t > # and with initialization ˆw−# = ˆw# = # α# = # #ν+# β# = #. With this choice and considering the least-squares problem this algorithm is known as ν−method in the inverse problem κ# literature (see e.g. [##]). This seemingly complex parameters’ choice allows to relates the approach to suitable orthogonal polynomials recursion as we discuss later. #ν+# Nesterov acceleration The second form of gradient acceleration we consider is the popular Nesterov acceleration [##]. In our setting it corresponds to the iteration ˆwt+# = ˆvt − α X∗ (X ˆvt − y) ˆvt = ˆwt + βt ( ˆwt − ˆwt−#) with the two initial points ˆw−# = ˆw# = # and the sequence βt chosen as t − # t + β βt = β ≥ # . (#) (#) Differently from heavy-ball Nesterov acceleration uses the momentum term also in the evaluation of the gradient. Also in this case optimization results are well known [# ##]. Here as above optimization results refer to solving ERM (#) (#) whereas in the following we study to which extent the above iterations can used to minimize the expected error (#). In the next section we discuss a spectral approach which will be instrumental towards this goal. # Spectral ﬁltering for accelerated methods Least squares allows to consider spectral approaches to study the properties of gradient methods for learning. We illustrate these ideas for gradient descent before considering accelerated methods. Gradient descent as spectral ﬁltering Note that by a simple (and classical) induction argument gradient descent can be written as t−#(cid:##) j=# ˆwt = α (I − α ˆΣ)j X∗ y . with ˆΣ = X∗ X j=#(I − ασ)j for all σ ∈ (# κ#] and t ∈ N. Note that the polynomials gt are bounded by αt. A ﬁrst observation is that gt(σ)σ converges to # as t → ∞ since σ . A second observation is that the residual polynomials rt(σ) = # − σgt(σ) gt(σ) converges to # which are all bounded by # control ERM convergence since Equivalently using spectral calculus ˆwt = gt( ˆΣ) X∗ y where gt are the polynomials gt(σ) = α(cid:##)t−# (cid:##)(cid:##)(cid:##)n |rt(σ)σq| ≤(cid:##) q (cid:##)(cid:##)(cid:##)X gt( ˆΣ) X (cid:###)X ˆwt − y(cid:###)n = ∗ y − y = (cid:##)(cid:##)(cid:##)n (cid:##)(cid:##)(cid:##)gt( ˆΣ) ˆΣy − y (cid:##)q (cid:##)q(cid:##) # = . In particular if y is in the range of ˆΣr for some r > # (source condition on y) improved convergence rates can be derived noting that by an easy calculation (cid:##)(cid:##)(cid:##)n (cid:##)(cid:##)(cid:##)rt( ˆΣ)y (cid:##)(cid:##)(cid:##)op ≤(cid:##)(cid:##)(cid:##)rt( ˆΣ) (cid:###)y(cid:###)n . α t # As we show in Section # considering the polynomials gt and rt allows to study not only ERM but also expected risk minimization (#) by relating gradient methods to their inﬁnite sample limit. Further we show how similar reasoning hold for accelerated methods. In order to do so it useful to ﬁrst deﬁne the characterizing properties of gt and rt. #.# Spectral ﬁltering The following deﬁnition abstracts the key properties of the function gt and rt often called spectral ﬁltering function [#]. Following the classical deﬁnition we replace t with a generic parameter λ. Deﬁnition #. The family {gλ}λ∈(# #] is called spectral ﬁltering function if the following conditions hold: (i) There exist a constant E < +∞ such that for any λ ∈ (# #] |gλ(σ)| ≤ E λ sup (#) σ∈(# κ#] . (ii) Let rλ(σ) = # − σ gλ(σ) there exist a constant F# such that for any λ ∈ (# #] |rλ(σ)| ≤ F# . sup σ∈(# κ#] (##) Deﬁnition #. (Qualiﬁcation) The qualiﬁcation of the spectral ﬁltering function {gλ}λ is the maximum parameter q such that for any λ ∈ (# #] there exist a constant Fq such that |rλ(σ)σq| ≤ Fqλq . sup σ∈(# κ#] (##) Moreover we say that a ﬁltering function has qualiﬁcation ∞ if (##) holds for every q > #. Methods with ﬁnite qualiﬁcation might have slow convergence rates in certain regimes. The smallest the qualiﬁcation the worse the rates can be. The discussion in the previous section shows that gradient descent deﬁnes a spectral ﬁltering function where λ = #/t. More precisely the following holds. for t ∈ N then the polynomials gt related to the gradient descent Proposition #. Assume λ = # t iterates deﬁned in (#) are a ﬁltering function with parameters E = α and F# = #. Moreover it has qualiﬁcation ∞ with parameters Fq = (q/α)q. The above result is classical and we report a proof in the appendix for completeness. Next we discuss analogous results for accelerate methods and then compare the different spectral ﬁltering functions. #.# Spectral ﬁltering for accelerated methods For the heavy-ball (#) the following result holds Proposition #. Assume κ ≤ # let ν > # and λ = # t# for t ∈ N then the polynomials gt related to heavy-ball method (#) are a ﬁltering function with parameters E = # and F# = #. Moreover there exist a positive constant cν < +∞ such that the ν-method has qualiﬁcation ν. The proof of the above proposition follows combining several intermediate results from [##]. The key idea is to show that the residual polynomials deﬁned by heavy-ball iteration form a sequence of orthogonal polynomials with respect to the weight function ων(σ) = σ#ν # (# − σ) σ # # # which is a so called shifted Jacobi weight. Results from orthogonal polynomials can then be used to characterize the corresponding spectral ﬁltering function. The following proposition considers Nesterov acceleration. # Proposition #. Assume λ = #/t# then the polynomials gt related to Nesterov iterates (#) are a ﬁltering function with constants E = #α and F# = #. Moreover the qualiﬁcation of this method is at least #/# with constants Fq = . (cid:##)q (cid:##) β# α Filtering properties of the Nesterov iteration (#) have been studied recently in the context of inverse problems [##]. In the appendix #.# we provide a simpliﬁed proof based on studying the properties of suitable discrete dynamical systems deﬁned by the Nesterov iteration (#). #.# Comparing the different ﬁlter functions We summarize the properties of the spectral ﬁltering function of the various methods for κ = #. Method Gradien descent Heavy-ball Nesterov E F# # # # # # # Fq qq (q = ν) β#q cν Qualiﬁcation ∞ ν ≥ #/# The main observation is that the properties of the spectral ﬁltering functions corresponding to the different iterations depend on λ = #/t for gradient descent but on λ = #/t# for the accelerated methods. As we see in the next section this leads to substantially different learning properties. Further we can see that gradient descent is the only algorithm with qualiﬁcation ∞ even if the parameter Fq = qq can be very large. The accelerated methods seem to have smaller qualiﬁcation. In particular the heavy-ball method can attain a high qualiﬁcation depending on ν but the constant cν is unknown and could be large. For Nesterov accelerated method the qualiﬁcation is at least #/# and it’s an open question whether this bound is tight or higher qualiﬁcation can be attained. In the next section we show how the properties of the spectral ﬁltering functions can be exploited to study the excess risk of the corresponding iterations. # Learning properties for accelerated methods We ﬁrst consider a basic scenario and then a more reﬁned analysis leading to a more general setting and potentially faster learning rates. #.# Attainable case Consider the following basic assumption. Assumption #. Assume there exist M > # such that |y| < M ρ-almost surely and w∗ ∈ X such that E(w∗) = inf X E. Then the following result can be derived. Theorem #. Under Assumption # let ˆwGD be the t-th iterations respectively of gradient descent (#) and an accelerated version given by (#) or (#). Assuming the sample-size n to be large enough and let δ ∈ (# #/#) then there exist two positive constant C# and C# such that with probability at least # − δ and ˆwacc t t E( ˆwGD t ) − inf H E ≤ C# E( ˆwacc t ) − inf H E ≤ C# (cid:##) # (cid:##) # t + t# + (cid:##) (cid:##) t n t# n log# # δ log# # δ . where the constants C# and C# do not depend on n t δ but depend on the chosen optimization method. Moreover by choosing the stopping rules tGD = O(n#/#) and tacc = O(n#/#) both algorithms have learning rate of order #√ n . The proof of the above results is given in the appendix and the novel part is the one concerning accelerated methods particularly Nesterov acceleration. The result shows how the number of iteration # controls the learning properties both for gradient descent and accelerated gradient. In this sense implicit regularization occurs in all these approaches. For any t the error is split in two contributions. Inspecting the proof it is easy to see that the ﬁrst term in the bound comes from the convergence properties of the algorithm with inﬁnite data. Hence the optimization error translates into a bias term. The decay for accelerated method is much faster than for gradient descent. The second term arises from comparing the empirical iterates with their inﬁnite sample (population) limit. It is a variance term depending on the sampling in the data and hence decreases with the sample size. For all methods this term increases with the number of iterations indicating that the empirical and population iterations are increasingly different. However the behavior is markedly worse for accelerated methods. The beneﬁt of acceleration seems to be balanced out by this more unstable behavior. In fact the beneﬁt of acceleration is apparent balancing the error terms to obtain a ﬁnal bound. The obtained bound is the same for gradient descent and accelerated methods and is indeed optimal since it matches corresponding lower bounds [# #]. However the number of iterations needed by accelerated methods is the square root of those needed by gradient descent indicating a substantial computational gain can be attained. Next we show how these results can be generalized to a more general setting considering both weaker and stronger assumptions corresponding to harder or easier learning problems. #.# More reﬁned result Theorem # is a simpliﬁed version of the more general result that we discuss in this section. We are interested in covering also the non-attainable case that is when there is no w∗ ∈ X such that E(w∗) = inf X E. In order to cover this case we have to introduce several more deﬁnitions and notations. In Appendix #.# we give a more detailed description of the general setting. Consider X f (x)# dρX(x) and the space L# extend the expected risk to L# ρX be the hypothesis space of functions such that f (x) = (cid:###)w x(cid:###) ρX almost surely. Recall that the minimizer X y dρ(y|x). The projection fH over of the expected risk over L# the closure of the hypothesis space H is deﬁned as ρX deﬁning E(f ) =(cid:##) ρX is the regression function fρ =(cid:##) ρX of the square integrable functions with the norm (cid:###)f(cid:###)# X×R(f (x) − y)# dρ(x y). Let H ⊆ L# ρX = (cid:##) Let L : L# ρX → L# ρX be the integral operator fH = arg min g∈H (cid:###)g − fρ(cid:###)ρX . Lf (x) = f (x(cid:##))(cid:###)x x(cid:##)(cid:###) dρX(x(cid:##)) . (cid:##) X The ﬁrst assumption we consider concern the moments of the output variable and is more general than assuming the output variable y to be bounded as assumed before. Assumption #. There exist positive constant Q and M such that for all N (cid:##) l ≥ # (cid:##) |y|l dρ(y|x) ≤ # # l!M l−#Q# ρX almost surely. R This assumption is standard and satisﬁed in classiﬁcation or regression with well behaved noise. Under this assumption the regression function fρ is bounded almost surely (cid:##) R (cid:##)(cid:##) R (cid:##)#/# ≤ Q . |fρ(x)| ≤ |y| dρ(y|x) ≤ |y|# dρ(y|x) (##) The next assumptions are related to the regularity of the target function fH. Assumption #. There exist a positive constant B such that the target function fH satisfy (fH(x) − fρ(x))# x ⊗ x dρX(x) (cid:##) B#Σ . (cid:##) X This assumption is needed to deal with the misspeciﬁcation of the model. The last assumptions quantify the regularity of fH and the size (capacity) of the space H. # Assumption #. There exist g# ∈ L# ρX and r > # such that Moreover we assume that there exist γ ≥ # and a positive constant cγ such that the effective dimension fH = Lrg# with (cid:###)g#(cid:###)ρX ≤ R. N(λ) = Tr L (L + λI) − # γ . (cid:##) −#(cid:##) ≤ cγλ (cid:#) . ρX The assumption on N(λ) is always true for γ = # and c# = κ# and it’s satisﬁed when the eigenvalues σi of L decay as i−γ. We recall that the space H can be characterized in terms of the operator L indeed H = L#/#(cid:#)L# Hence the non-attainable corresponds to considering r < #/#. Theorem #. Under Assumption # # # let ˆwGD be the t-th iterations of gradient descent (#) and an accelerated version given by (#) or (#) respectively. Assuming the sample-size n to be large enough let δ ∈ (# #/#) and assuming r to be smaller than the qualiﬁcation of the considered algorithm (and equal to #/# in the case of Nesterov accelerated methods) then there exist two positive constant C# and C# such that with probability at least # − δ and ˆwacc t t (cid:##) (cid:##) (cid:##) (cid:##) E( ˆwGD t ) − inf H E ≤ C# E( ˆwacc t ) − inf H E ≤ C# # t#r + # t#r + # γ t n # γ t n log# # δ log# # δ . where the constants C# and C# do not depend on n t δ but depend on the chosen optimization. Choosing the stopping rules tGD = O(n accelerated methods achieve a learning rate of order O #γr+# ) both gradient descent and . #γr+# ) and tacc = O(n −#γr #γr+# n γ γ (cid:##) (cid:##) The only reason why we do not consider r < #/# in the analysis of Nesterov accelerated methods is that our proof require the qualiﬁcation of the method to be larger than # for technical reasons. However we think that our result can be extended to that case furthermore we think Nesterov qualiﬁcation to be larger than # however it’s an open question whether higher qualiﬁcation can be attained. The proof of the above result is given in the appendix. The general structure of the bound is the same as in the basic setting which is now recovered as a special case. However in this more general form the various terms in the bound depend now on the regularity assumptions on the problem. In particular the variance depends on the effective dimension behavior e.g. on the eigenvalue decay while the bias depend on the regularity assumption on fH. The general comparison between gradient descent and accelerated methods follows the same line as in the previous section. Faster bias decay of accelerated methods is contrasted by a more unstable behavior. As before the beneﬁt of accelerated methods becomes clear when deriving optimal stopping time and corresponding learning bound: they achieve the accuracy of gradient methods but in considerable less time. While heavy-ball and Nesterov have again similar behaviors here a subtle difference resides in their different qualiﬁcations which in principle lead to different behavior for easy problems that is for large r and γ. In this regime gradient descent could work better since it has inﬁnite qualiﬁcation. For problems in which r < #/# and γ = # the rates are worse than in the basic setting hence these problems are hard. #.# Related work In the convex optimization framework a similar phenomenon was pointed out in [##] where they introduce the notion of inexact ﬁrst-order oracle and study the behaviour of several ﬁrst-order methods of smooth convex optimization with such oracle. In particular they show that the superiority of accelerated methods over standard gradient descent is no longer absolute when an inexact oracle is used. This because acceleration suffer from the accumulation of the errors committed by the inexact oracle. A relevant result on the generalization properties of learning algorithm is [#] in which they introduce the notion of uniform stability and use it to obtain generalization error bounds # for regularization based learning algorithms. Recently to show the effectiveness of commonly used optimization algorithms in many large-scale learning problems algorithmic stability has been established for stochastic gradient methods [##] as well as for any algorithm in situations where global minima are approximately achieved [#]. For Nesterov’s accelerated gradient descent and heavy- ball method [#] provide stability upper bounds for quadratic loss function in a ﬁnite dimensional setting. All these approaches focus on the deﬁnition of uniform stability given in [#]. Our approach to the stability of a learning algorithm is based on the study of ﬁltering properties of accelerated methods together with concentration inequalities we obtain upper bounds on the generalization error for quadratic loss in a inﬁnite dimensional Hilbert space and generalize the bounds obtained in [#] by considering different regularity assumptions and by relaxing the hypothesis of the existence of a minimizer of the expected risk on the hypothesis space. # Numerical simulation In this section we show some numerical simulations to validate our results. We want to simulate the case in which the eigenvalues σi of the operator L are σi = i−γ for some γ ≤ # and the non-attainable case r < #/#. In order to do this we observe that if we consider the kernel setting over a ﬁnite space Z = {z# . . . zn} of size N with the uniform probability distribution ρZ then the space L#(Z ρZ) becomes RN with the usual scalar product multiplied by #/N. the operator L becomes a N × N matrix which entries are Li j = K(zi zj) for every i j ∈ {# . . . N} where K is the kernel which is ﬁxed by the choice of the matrix L. We build the matrix L = U DU T with U ∈ RN×N orthogonal matrix and D diagonal matrix with entries Di i = i−γ. The source condition becomes fH = Lrg# for some g# ∈ RN r > #. We simulate the observed output as y = fH + N(# σ) where N(# σ) is the standardx normal distribution of variance σ#. The sampling operation can be seen as extracting n indices i# . . . in and building the kernel matrix ˆKj k = K(zij zik ) and the noisy labels ˆyj = yij for every j k ∈ {# . . . n}. The Representer Theorem ensure that we can built our estimator ˆf ∈ RN j=# K(z zij )cj where the vector c depends on the chosen optimization algorithm and as ˆf (z) =(cid:##)n L# Z takes the form c = gt( ˆK)y. The excess risk of the estimator ˆf is given by (cid:###) ˆf − fH(cid:###)# For every algorithm considered we run ## repetitions in which we sample the data-space and compute the error (cid:###) ˆft − fH(cid:###)# where ˆft represents the estimator related to the t-th iteration of one of the considered algorithms and in the end we compute the mean and the variance of those errors. In Figure # we simulate the error of all the algorithms considered for both attainable and non-attainable case. We observe that both heavy-ball and Nesterov acceleration provides faster convergence rates with respect to gradient descent method but the learning accuracy is not improved. We observe that the accelerated methods considered show similar behavior and that for “easy problem” (large r) that gradient descent can exploits its higher qualiﬁcation and perform similarly to the accelerated methods. In Figure # we show the test error related to the real dataset pumadyn#nh (available at ltorgo/Regression/puma.html). Even in this case we can observe the behaviors shown in our theoretical results. . L# Z Fig. #: Mean and variance of error (cid:###) ˆft − fH(cid:###)# N for the t-th iteration of gradient descent (GD) Nesterov accelerated algorithm and heavy-ball (ν = #). Black dots shows the absolute minimum of the curves. The parameters are chosen N = ### n = ### γ = # σ = #.#. We show the attainable case (r = #/#) in the left the “hard case” (r = #.# < #/#) in the center and the “easy case” (r=#>#/#) in the right. # Fig. #: Test error on the real dataset pumadyn#nh using gradient descent (GD) Nesterov accelerated algorithm and heavy-ball. In the left we use a gaussian kernel with σ = #.# and in the right a polynomial kernel of degree #. # Conclusion In this paper we have considered the implicit regularization properties of accelerated gradient methods for least squares in Hilbert space. Using spectral calculus we have characterized the properties of the different iterations in terms of suitable polynomials. Using the latter we have derived error bounds in terms of suitable bias and variance terms. The main conclusion is that under the considered assumptions accelerated methods have smaller bias but also larger variance. As a byproduct they achieve the same accuracy of vanilla gradient descent but with much fewer iterations. Our study opens a number of potential theoretical and empirical research directions. From a theory point of view it would be interesting to consider other learning regimes for examples classiﬁcation problems different loss functions or other regularity assumptions beyond classical nonparametric assumptions e.g. misspeciﬁed models and fast eigenvalues decays (Gaussian kernel). From an empirical point of view it would be interesting to do a more thorough investigation on a larger number of simulated and real data-sets of varying dimension. Acknowledgments This material is based upon work supported by the Center for Brains Minds and Machines (CBMM) funded by NSF STC award CCF-####### and the Italian Institute of Technology. We gratefully acknowledge the support of NVIDIA Corporation for the donation of the Titan Xp GPUs and the Tesla k## GPU used for this research. L. R. acknowledges the ﬁnancial support of the AFOSR projects FA####-##-#-#### and BAA-AFRL-AFOSR-####-#### (European Ofﬁce of Aerospace Research and Development) and the EU H####-MSCA-RISE project NoMADS - DLV-######. N.P. would like to thank Murata Tomoya for the useful observations. References [#] Hedy Attouch Zaki Chbani and Hassan Riahi. Rate of convergence of the nesterov accelerated gradient method in the subcritical case α ≤ #. ESAIM: Control Optimisation and Calculus of Variations ##:# ####. [#] Luca Baldassarre Lorenzo Rosasco Annalisa Barla and Alessandro Verri. Multi-output learning via spectral ﬁltering. Machine learning ##(#):###–### ####. [#] Gilles Blanchard and Nicole Mücke. Optimal rates for regularization of statistical inverse learning problems. Foundations of Computational Mathematics ##(#):###–#### Aug ####. [#] Léon Bottou and Olivier Bousquet. The tradeoffs of large scale learning. In Advances in neural information processing systems pages ###–### ####. [#] Olivier Bousquet and André Elisseeff. Stability and generalization. Journal of machine learning research #(Mar):###–### ####. # [#] Peter Bühlmann and Bin Yu. Boosting with the l # loss: regression and classiﬁcation. Journal of the American Statistical Association ##(###):###–### ####. [#] Andrea Caponnetto and Ernesto De Vito. Optimal rates for the regularized least-squares algorithm. Foundations of Computational Mathematics #(#):###–### ####. [#] Zachary Charles and Dimitris Papailiopoulos. Stability and generalization of learning algorithms that converge to global optima. arXiv preprint arXiv:####.##### ####. [#] Yuansi Chen Chi Jin and Bin Yu. Stability and convergence trade-off of iterative optimization algorithms. arXiv preprint arXiv:####.##### ####. [##] Olivier Devolder François Glineur and Yurii Nesterov. First-order methods of smooth convex optimization with inexact oracle. Mathematical Programming ###(#-#):##–## ####. [##] Heinz Werner Engl Martin Hanke and Andreas Neubauer. Regularization of inverse problems volume ###. Springer Science & Business Media ####. [##] Junichi Fujii Masatoshi Fujii Takayuki Furuta and Ritsuo Nakamoto. Norm inequalities equivalent to heinz inequality. Proceedings of the American Mathematical Society ###(#):###– ### ####. [##] Suriya Gunasekar Jason D Lee Daniel Soudry and Nati Srebro. Implicit bias of gradient In Advances in Neural Information Processing descent on linear convolutional networks. Systems pages ####–#### ####. [##] Moritz Hardt Benjamin Recht and Yoram Singer. Train faster generalize better: Stability of stochastic gradient descent. arXiv preprint arXiv:####.##### ####. [##] Yann A LeCun Léon Bottou Genevieve B Orr and Klaus-Robert Müller. Efﬁcient backprop. In Neural networks: Tricks of the trade pages #–##. Springer ####. [##] Junhong Lin Raffaello Camoriano and Lorenzo Rosasco. Generalization properties and implicit regularization for multiple passes sgm. In International Conference on Machine Learning pages ####–#### ####. [##] Junhong Lin and Volkan Cevher. Optimal convergence for distributed learning with stochastic gradient methods and spectral-regularization algorithms. stat ####:## ####. [##] Junhong Lin and Lorenzo Rosasco. Optimal learning for multi-pass stochastic gradient methods. In Advances in Neural Information Processing Systems pages ####–#### ####. [##] Junhong Lin Alessandro Rudi Lorenzo Rosasco and Volkan Cevher. Optimal rates for spectral algorithms with least-squares regression over hilbert spaces. Applied and Computational Harmonic Analysis ####. [##] Peter Mathé and Sergei Pereverzev. Regularization of some linear ill-posed problems with discretized random noisy data. Mathematics of Computation ##(###):####–#### ####. [##] Peter Mathé and Sergei V Pereverzev. Moduli of continuity for operator valued functions. Numerical Functional Analysis and Optimization ##(#-#):###–### ####. [##] Yurii E Nesterov. A method for solving the convex programming problem with convergence rate o (#/kˆ #). In Dokl. akad. nauk Sssr volume ### pages ###–### ####. [##] Andreas Neubauer. On nesterov acceleration for landweber iteration of linear ill-posed problems. Journal of Inverse and Ill-posed Problems ##(#):###–### ####. [##] Boris T Polyak. Introduction to optimization. Technical report ####. ## [##] Garvesh Raskutti Martin J Wainwright and Bin Yu. Early stopping and non-parametric regres- sion: an optimal data-dependent stopping rule. The Journal of Machine Learning Research ##(#):###–### ####. [##] Lorenzo Rosasco and Silvia Villa. Learning with incremental iterative regularization. Advances in Neural Information Processing Systems pages ####–#### ####. In [##] Daniel Soudry Elad Hoffer Mor Shpigel Nacson Suriya Gunasekar and Nathan Srebro. The implicit bias of gradient descent on separable data. The Journal of Machine Learning Research ##(#):####–#### ####. [##] Ingo Steinwart and Andreas Christmann. Support vector machines. Springer Science & Business Media ####. [##] Weijie Su Stephen Boyd and Emmanuel Candes. A differential equation for modeling nes- terov’s accelerated gradient method: Theory and insights. In Advances in Neural Information Processing Systems pages ####–#### ####. [##] Gabor Szeg. Orthogonal polynomials volume ##. American Mathematical Soc. ####. [##] Yuan Yao Lorenzo Rosasco and Andrea Caponnetto. On early stopping in gradient descent learning. Constructive Approximation ##(#):###–### ####. [##] SK Zavriev and FV Kostyuk. Heavy-ball method in nonconvex optimization problems. Computational Mathematics and Modeling #(#):###–### ####. [##] Chiyuan Zhang Samy Bengio Moritz Hardt Benjamin Recht and Oriol Vinyals. Under- standing deep learning requires rethinking generalization. arXiv preprint arXiv:####.##### ####. ##\n",
            "response:  We study learning properties of accelerated gradient descent methods for linear least-squares in Hilbert spaces. We analyze the implicit regularization properties of Nesterov acceleration and a variant of heavy-ball in terms of corresponding learning error bounds. Our results show that acceleration can provide faster bias decay than gradient descent but also suffers of a more unstable behavior. As a result acceleration cannot be in general expected to improve learning accuracy with respect to gradient descent however rather to achieve the same accuracy with reduced computations.Our theoretical results are validated by numerical simulations.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8676e7bfd0f24f0482a69c1b6fedfaf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7909 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1948d6cf1b4f4797bfdcbe2f0e119516"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6df6139daee41cba97780d543420c12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d8d6d860877484d9341fda449c30dea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a071a80907a3420086bd31ac864fcd03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82e15f6100264c129d89faeeb6b43698"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93e6fa18147e4c7aba223366acee6ea9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3200823534f64b92be8d3fb7302dffca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e296be589d34f558feb697aae81529d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summarize: Suicidality which encompasses suicidal ideation plans and attempts is a clinical concern and has an adverse impact on individuals families and society. Individuals with suicidal ideation [#] and those who have planned for a suicide attempt [#] are at greater risk of attempting suicide with those who have demonstrated planning being at a higher risk than those with ideation [#] . A suicide attempt is the most potent risk factor for completed suicide [#] . Research has been conducted to identify the determinants of a suicide attempt and factors identified include depressive [#] and anxiety disorders [#] poor social adjustment [#] unemployment [#] and medical illness [#] . Singapore is a city-state in Southeast Asia and is a multi-ethnic nation. The Singapore population as of #### stands at #.# million of whom #.# million are residents (Citizens and Permanent Residents) [#] . The suicide rate in Singapore between #### and #### stood at #.## deaths per ### ### residents with a significant rise in elderly suicides between #### and #### [##] . Despite the suicide rate being lower than that seen in other countries there are ongoing multi-pronged national efforts to prevent suicides under the National Mental Health Blueprint such as by encouraging early help seeking supporting groups at-risk and ensuring community support [##] . The Singapore Mental Health Study #### (hereafter referred to as SMHS ####) was the second iteration of a national mental health study [##] the first of which was conducted in #### (hereafter referred to as SMHS ####). The SMHS #### aimed to establish the prevalence of select psychiatric disorders and to track the state of mental health in the Singapore resident population. The current article describes the prevalence of suicidality (ideation plan and attempts) in Singapore's population and explores associations among this and demographic variables physical disorders and psychiatric disorders. The methodology of SMHS #### was similar to SMHS #### and has been described previously [##] . SMHS #### was a cross-sectional nationwide epidemiological survey of Singapore residents aged ## years and above. Participants were randomly drawn from a national population registry of all citizens and permanent residents. Disproportionate stratified sampling was used with oversampling of individuals from minority (Malay and Indian) ethnicities and those above ## years of age-this was done to achieve adequate sample sizes and to improve the reliability of estimates when conducting subgroup analyses. Following an invitation letter selected participants were approached in their homes and written informed consent was obtained prior to conducting face-to-face interviews. All interviews were conducted in the language that participants were most comfortable with (i.e. English Mandarin or Malay). The study was approved by the institutional ethics committee (National Healthcare Group Domain Specific Review Board). The WHO-CIDI was used as the main diagnostic instrument to establish the prevalence of psychiatric disorders. A fully structured computer-assisted version was used. The WHO-CIDI establishes the ##-month and lifetime prevalence of common psychiatric disorders following the criteria stipulated in the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV) [##] . The disorders included affective disorders (major depressive disorder and bipolar disorder) anxiety disorders (generalized anxiety disorder and obsessive-compulsive disorder) and alcohol use disorder (alcohol abuse and alcohol dependence). These disorders were chosen after consultation with stakeholders and policy makers (e.g. The Ministry of Health Singapore voluntary welfare organizations catering to people with mental illness and clinicians). Participants were also asked to complete as part of the WHO-CIDI questions pertaining to suicidality. The questions asked are listed in Supplementary Material #. The WHO-CIDI has been used to assess suicidality in developed and developing nations [##] . Questions were read out to participants who were unable to read whilst those who could read were given cue cards to refer to. Data on age gender ethnicity (Chinese Malay Indian and others) marital status (single married divorced/separated or widowed) highest attained educational level household income and employment status (employed unemployed or economically inactive e.g. retired) was collected. A modified version of the CIDI chronic conditions checklist where participants were asked if they have been diagnosed with a list of health conditions was used to ascertain the presence of physical disorders. The conditions included in this checklist were hyperlipidemia hypertension diabetes mellitus asthma chronic pain (e.g. arthritis back/spine problems and migraine headaches) cardiovascular diseases (e.g. stroke and heart disease including heart attack/s coronary heart disease angina and congestive heart failure) gastrointestinal ulcers (e.g. stomach ulcer enteritis or colitis) thyroid disease and cancer). In order to account for the disproportionate sampling design and to ensure that survey findings were representative of the Singaporean adult population all estimates were weighted to adjust for over-sampling non-response and post-stratified for age and ethnicity distributions between the survey sample and the Singapore resident population in ####. Descriptive analyses were performed to describe the socio-demographic profile of the study population and the prevalence of suicidal ideation planning and attempts. Sociodemographic correlates of suicidal ideation planning and attempts were determined using multivariable logistic regression. All socio-demographic variables (i.e. age group gender ethnicity education employment marital status and income) were included as predictor variables. Associations between each component of suicidality and physical and psychiatric diseases were analyzed via multivariable logistic regression. In the multivariable regression models each of suicidal ideation planning and attempts was individually treated as a dependent variable and the occurrence of each physical or psychiatric disorder was treated as a main predictor variable while controlling for all socio-demographic variables. All analyses were conducted utilizing STATA version ##.#. SMHS #### included a total of #### respondents. The response rate amongst eligible adults was ##.#%. The mean age of the sample was ##.# years with an approximately equal proportions of both genders (male ##.#% female ##.#%). Moreover #### (##.#%) of the respondents were married #### (##.#%) had attained primary and secondary school education and #### (##.#%) attained university education. A total of #### (##.#%) reported being employed and ### (#.#%) were unemployed. Table # presents the socio-demographic distribution of study participants. The lifetime prevalence of suicidal ideation was #.#% with a ##-month prevalence of #.#%. Table #A depicts the association between lifetime suicidal ideation and demographic variables while Table #B depicts the association between lifetime suicidal ideation and physical and psychiatric disorders. Suicidal ideation was less likely among those aged ##-## (OR #.# p= #.###) those above ## years of age (OR #.# p = #.###) male respondents (OR #.# p = #.###) those of Malay ethnicity (OR #.# p = #.###) and those with a monthly household income level of SGD ####-#### (OR #.# p = #.###) and SGD ## ### and above (OR #.# p = #.###). Having never been married (OR #.# p = #.###) and being divorced/separated (OR #.# p = #.###) were associated with a higher prevalence of suicidal ideation. After controlling for the presence of psychiatric disorders all the socio-demographic variables remained significant except for age ##-## (p = #.###). Those with major depressive disorder (OR #.# p = #.###) bipolar disorder (OR ## p = #.###) generalized anxiety disorder (OR ##.# p = #.###) obsessive-compulsive disorder (OR #.# p = #.###) and alcohol use disorder (OR #.# p = #.###) were more likely to have suicidal ideation. Those with diabetes mellitus (OR #.# p = #.###) chronic pain (OR #.# p = #.###) and cancer (OR #.# p = #.###) were also more likely to report suicidal ideation. The lifetime prevalence of suicide planning was #.#% with a ##-month prevalence of #.#%. Table #A depicts the association between suicidal planning and demographic variables while Table #B depicts the association between suicidal planning and physical and psychiatric disorders. Compared to those who had completed university individuals with a highest attained educational level of pre-university/junior college were less likely to have engaged in suicide planning (OR #.# p = #.###) and this remained significant (p = #.###) after controlling for the presence of psychiatric disorders. Those with major depressive disorder (OR #.# p = #.###) bipolar disorder (OR ## p = #.###) generalized anxiety disorder (OR #.# p = #.###) and alcohol use disorder (OR #.# p = #.###) were more likely to report suicidal planning. Individuals with chronic pain were also more likely to have engaged in suicidal planning (OR #.# p = #.###). The lifetime prevalence of a suicide attempt was #.#% with a ##-month prevalence of #.#%. Table #A depicts the association between suicide attempts and demographic variables and Table #B depicts the association between suicide attempts and physical and psychiatric disorders. Suicide attempts were less likely in those aged between ## and ## (OR #.# p = #.###) and those who were widowed (OR #.# p = #.###). Respondents of Indian ethnicity (OR #.# p = #.###) those with a highest education level of secondary school (OR #.# p = #.###) and those who were divorced/separated (OR #.# p = #.###) were more likely to have attempted suicide. This remained significant after controlling for the presence of psychiatric disorders. Those with major depressive disorder (OR #.# p = #.###) bipolar disorder (OR #.# p = #.###) generalized anxiety disorder (OR ##.# p = #.###) and alcohol use disorder (OR #.# p = #.###) were more likely to have a lifetime history of suicide attempts. Individuals with hypertension (OR #.# p = #.###) hyperlipidemia (OR #.# p = #.###) diabetes mellitus (OR #.# p = #.###) and chronic pain (OR #.# p = #.###) were more likely to have attempted suicide while those with thyroid disease (OR #.# p = #.###) were less likely to have attempted suicide. Suicide is a worldwide concern. A study of suicidality in ## countries found the lifetime prevalence of suicidal ideation planning and attempts to be #.#% #.#% and #.#% respectively [##] . Our findings illustrate that Singapore's suicidality prevalence mirrors what is seen elsewhere. Our study found that there is an association between components of suicidality and socio-demographic factors such as being divorced/separated and age. The extant literature does highlight that individuals who are divorced have a higher risk for suicide with the risk higher in divorced men than in divorced women with divorced individuals manifesting higher levels of depression anxiety resentment a loss of self-esteem and eventually a sense that life is not worth living [##] . Our finding of an association of suicidality with younger age is echoed in two other studies [## ##] which illustrated that age was inversely related with each component of suicidality and that younger age groups were thus at higher risk of suicide with the prevalence of suicidality reducing into adulthood. There are some explanations for this finding-firstly individuals from older age groups might have forgotten or re-interpreted prior suicidal behaviors [##] and may have under-reported the presence of suicidal ideation planning or attempts. Secondly emotional well-being is noted to increase and become more stable with advancing age with this change remaining significant after controlling for physical health and demographic variables-it is postulated that this improvement possibly occurs due to better adaptation and knowledge [##] . These findings were also echoed in another study which demonstrated a higher level of positive mental health in individuals aged above ## as compared to those aged ##-## [##] . This improved sense of emotional well-being and positive mental health may contribute to lower suicidality. Thirdly compared to older age groups younger people might lack the capacity to overcome interpersonal crises and may become more despondent because of them and this might place younger people at a higher risk of suicide [##] . A caveat to our finding is the elevated rate of suicide completion in the elderly [##] which if taken together with our findings may be a reflection that elderly individuals may attempt suicide less often but could die from a suicide attempt more frequently. The lack of association with employment status is surprising given that unemployment is a well-established risk factor for suicide [#] . One possibility for the lack of an effect may be the support rendered to those in Singapore who are unemployed-social welfare and unemployment protection reduces the strength of association between unemployment and suicide [##] . In addition the unemployment rate in Singapore is one of the lowest in the world which could mean that those who are presently unemployed may retain good prospects of securing employment soon. The lack of a consistent association between suicidality and lower household income is contrary to other literature that indicates that financial stress and suicidality are linked [##] . This finding may be linked to other protective factors in our study population. Our study illustrated that there was a significant association among depression bipolar disorder generalized anxiety disorder and alcohol use disorder with suicidal ideation planning and attempts. These findings are in keeping with what is known in the extant literature [##] . Depression has a strong association with suicidal ideation and attempts with ##% of a sample of depressed individuals in Australia endorsing suicidal ideation and ##% endorsing suicide attempts [##] with the severity of depressive symptoms correlating significantly with suicidality. These findings were also echoed in SMHS #### with ##.#% of individuals with a history of major depressive disorder endorsing suicidal ideation and ##.#% endorsing suicide attempts [##] . This relationship may be explained by hopelessness which is a symptom that occurs in depressive illness and is strongly associated with suicide [##] . Regarding bipolar disorder our findings demonstrate higher odds for lifetime suicidal ideation planning and attempts in individuals with bipolar disorder than in those with depression. These findings are consistent with findings from SMHS #### where ##% of respondents with Bipolar Disorder reported suicidal ideation and ##.#% reported past attempts [##] . Taken together with the extant literature these findings illustrate that suicidal ideation and attempts occur frequently amongst those with bipolar disorder with suicidality being most pronounced in the depressive phase of illness [##] . Alcohol use may lead to suicide by impairing judgement increasing impulsivity and by leading to mood disorders cognitive deficits anxiety and psychotic disorders [##] . Heavy alcohol users have a five-fold higher risk of suicide than those who drink socially [##] . Further analysis to explore the cumulative effects of multiple psychiatric diagnoses on suicidality is worthy of exploration but is beyond the scope of this paper. Our findings also illustrate a link between suicidality and chronic medical conditions such as diabetes mellitus and chronic pain. Diabetes mellitus may increase suicidality through multiple mechanisms-the accumulation of diabetes related complications and disabilities the occurrence of adverse events stress and easy access to potentially lethal means (e.g. insulin) [##] . Chronic pain was found to have a statistically significant association with suicidal ideation planning and attempts. Chronic pain possibly increases suicide risk by increasing levels of hopelessness and a desire to escape from pain via death [##] by heightening the sense of perceived burdensomeness and creating distress in interpersonal relationships [##] . This study has several strengths including the large sample size of #### adult respondents that is representative of the multi-ethnic general population the use of a validated scale by trained interviewers which minimized variability between assessors and assessments and the conducting of interviews in a language most familiar to respondents. There are several limitations to this study. The self-reported nature of suicidality and physical and psychiatric disorders may be affected by recall bias and could lead to underreporting. The study team addressed this by utilizing cue cards for participants who could read and avoided making direct mentions of potentially sensitive topics. It is also possible that those who would have endorsed suicidal ideation planning and attempts avoided participating in SMHS ####. The sample surveyed was a community-based household sample and did not include individuals in hospitals who are expected to have a higher prevalence of psychiatric and physical disorders and suicidality. The effect of overlapping physical and psychiatric disorders on suicidality was also not assessed. In addition the non-response rate of ##.#% could lead to an underestimation of suicidality. Finally whilst not a limitation of this study per se direct comparisons with the findings of SMHS #### could not be made as the latter did not administer the suicidality module of the WHO CIDI and only obtained data on suicidality amongst participants with major depressive disorder. Thus we are unable to determine whether there are differences in the prevalence of suicidality or its socio-demographic correlates between SMHS #### and SHMS ####. The present study demonstrates that # in ## adult Singaporeans have had suicidal ideation at some point in their lives. The study also demonstrates a significant association between suicidality and certain socio-demographic variables as well as physical disorders and psychiatric disorders. These findings illustrate that certain groups especially those with disorders such as chronic pain and bipolar disorder have a higher likelihood for suicidal behavior and need to be actively screened for suicidal ideation and planning. This is especially pertinent presently given the current COVID-## pandemic which is likely to create an increase in socio-economic problems and the prevalence of mental illnesses.\n",
            "response:  BACKGROUND: Suicidality encompasses suicide plans and attempts. This article describes the prevalence of select psychosocial disorders in Singapore's resident population and discusses association with this demographic variables physical disorders and mental health associations among these factors.\n",
            "summarize: Porcine reproductive and respiratory syndrome (PRRS) caused by PRRS virus (PRRSV) is a highly contagious disease in swine that is of great importance agriculturally. PRRSV is classified into two genotypes PRRSV-# (European type; prototype strain Lelystad virus) and PRRSV-# (North American type; the prototype strain VR-####). Because PRRSV leads to catastrophic economic losses worldwide swine industry worldwide every year it has been the focus of much research since its initial emergence in the ####s. In #### there was a particularly devastating outbreak in China of highly pathogenic PRRSV (HP-PRRSV) with a unique ##amino-acid deletion in the PRRSV nonstructural protein # (nsp#) [# #] . In recent years NADC##-like strains which have a characteristic of unique discontinuous ###-amino-acid deletion in the Nsp#-coding region have been the dominant epidemic strains in China [#] . Some NADC##-like PRRSV strains preferentially recombine with other PRRSV strains such as HP-PRRSV strains and VR#### [# #] . Consequently PRRSV strains have extensive genetic and antigenic variation and their frequent recombination leads to the emergence of diverse novel strains [#] . This contributes to the complexity of PRRSV and vaccine development and use. Several vaccines against PRRSV have been developed and are broadly used currently. Unfortunately none of these commercially available vaccines can prevent PRRS. This might be partially the consequence of the field's inadequate understanding of the role and mechanisms of antibody-dependent enhancement (ADE) which remain puzzling questions that affect the appropriate selection of immune strategies [# #] . ADE first described in #### is a phenomenon in which preexisting non-neutralizing antibodies or subneutralizing concentrations of antibodies facilitate viral entry and replication [#] . The importance of ADE has been noted by prior studies. ADE can worsen disease severity and is a significant impediment to vaccine development and vaccination strategies. ADE has been reported to be of medical and veterinary importance in viruses from many different families. Among the viruses affected by ADE the most notable are dengue virus (DENV) human immunodeficiency virus type # (HIV-#) Ebola virus Zika virus (ZIKV) and PRRSV (owing to its veterinary importance) [#] . These viruses share some common characteristics such as a tropism for myeloid cells the establishment of persistent infection and broad antigenic variability [##] . Myeloid cells bearing Fcγ receptors (FcγRs) mediate ADE through interacting with immunoglobulin (Ig) G antibody-virus complexes thus increasing the attachment of virus to cells [##] . Some studies reported that complement receptor is also able to mediate the enhancement of West Nile virus (WNV) replication as well as HIV and Ebola virus infection [##] [##] [##] . More intricately several studies have observed that ADE also occurs between different viruses or different virus strains owing to cross-reactive antibodies [##] . For example some antibodies directed against DENV or WNV are cross-reactive to ZIKV and can enhance ZIKV infection at specific concentrations in vitro; Furthermore pretreatment with anti-ZIKV monoclonal antibody (mAb) or maternally acquired antibodies in vivo showed more severe symptoms and mortality in DENVinfected mice [##] [##] [##] . However few studies have observed that preexisting anti-DENV antibodies enhance the pathogenesis of ZIKA. The mechanism underlying this clinical difference is still unclear. Therefore extensive research is needed to clarify the mechanism behind the role of ADE in viral pathogenesis. ADE of PRRSV infection was first described in ####; the study reporting it found that viral replication was enhanced in fetuses inoculated with virus plus antibody as compared with that in fetuses inoculated with virus alone [##] . Yoon et al. later reported that the viremia was elevated in pigs that were injected with subneutralizing amounts of PRRSV-specific IgG prior to virus challenge in vivo and also found that PRRSVspecific IgG enhanced the virus yields of heterologous strains [## ##] . FcγRs including FcγRI FcγRIIb and FcγRIII are involved in the ADE of PRRSV infection [##] [##] [##] [##] . However several reports have found no ADE in vivo with sub-neutralizing IgG and modified live PRRSV vaccines provide partial cross-protection to heterologous field strains [##] [##] [##] [##] . At present there is insufficient in vivo evidences to definitely confirm if ADE plays an important role in PRRSV pathogenesis. The ADE of PRRSV infection might differ among different PRRSV strains and under different conditions. Previous in vitro studies showed that the enhancement of infection by anti-PRRSV sera was strongest at a dilution of # # [##] . Following the passive transfer of PRRSVneutralizing antibodies a higher serum concentration of PRRSV neutraling antibody titer at #:## induced full protection but only in some young pigs whereas a titer of #:# did not prevent PRRSV replication in the lungs or the dissemination of infection to other peripheral lymphoid tissues [##] . In light of these conflicting findings additional research into the more details and underlying mechanisms of ADE in PRRSV infection is needed. The question of whether attenuated PRRSV vaccines worsen disease in pigs subsequently infected by novel strains needs to be addressed. In this study in vivo experiments were designed to evaluate ADE effects in PRRSV infection through assessing the clinical manifestations growth performance viremia and antibody response under different immune statuses especially different antibody levels implemented by challenging pigs with a novel heterologous NADC##-like PRRSV strain at different lengths of time after vaccination with a commercially attenuated HP-PRRSV vaccine. To simulate the clinical situation and acquire different immune statuses in pigs before PRRSV challenge the vaccination and challenge strategy was designed as illustrated in Fig. # . HNhx challenge was implemented at different lengths of time after vaccination with JXA#-R. All pigs were carefully monitored to observe clinical signs of PRRS such as cough depression sneezing and anorexia. As expected none of the piglets in the negative-control (mock-challenge) group exhibited clinical symptoms of PRRS. After JXA#-R inoculation a slight decrease of appetite was observed in all vaccinated piglets (subgroups A# B# C# D# and E#). After HNhx challenge most piglets showed obvious PRRSV-specific clinical signs such as cyanosis or erythema of the skin over the ears shivering inappetence and fever. In group A composed of piglets vaccinated with JXA#-R (subgroup A#) or phosphate-buffered saline PBS (subgroup A#) and then challenged with HNhx at # days post-vaccination (dpv) three out of five mockvaccinated piglets in subgroup A# died before ## days post-challenge (dpc) whereas all the vaccinated piglets in subgroup A# survived (Fig. #) . In group B composed of piglets vaccinated with JXA#-R (subgroup B#) or PBS (subgroup B#) and then challenged with HNhx at ## dpv four of five mock-vaccinated piglets in subgroup B# died before ## dpc whereas two of five vaccinated piglets in subgroup B# died. In group C composed of piglets vaccinated with JXA#-R (subgroup C#) or PBS (subgroup C#) and then challenged with HNhx at ## dpv two of five mock-vaccinated subpiglets in group C# died before ## dpc whereas all five vaccinated piglets in subgroup C# survived. In group D composed of piglets vaccinated with JXA#-R (subgroup D#) or PBS (subgroup D#) and then challenged with HNhx at ## dpv one of three mock-vaccinated piglets in subgroup D# died before ## dpc whereas all four vaccinated piglets in subgroup D# survived. In group E composed of piglets vaccinated with JXA#-R (subgroup E#) or PBS (subgroup Fig. # Vaccination and challenge strategies. At week # #-week-old piglets were inoculated with attenuated PRRSV vaccine at the indicated dose via an intramuscular injection in accordance with the manufacturer's instructions or with PBS as a mock-vaccination control (red stealth arrow). Then A PRRSV strain HNhx challenge was then performed in the piglets of each group at the indicated week post-vaccination (black arrow). Sera and lung tissues were collected at her marked timepoints E#) and then challenged with HNhx at ## dpv all piglets survived until the end of the study. The mock-vaccinated PRRSV-challenged piglets (PBS/HNhx) in subgroups A# B# and C# developed a sharp high fever (above ##.#°C) at # dpc and this fever lasted for approximately ## ## and ## days respectively except for few days below ##.#°C. In contrast the piglets in subgroup D# exhibited a high fever from # to ## dpc and piglets in subgroup E# exhibited a high fever from # to ## dpc. Thus the duration of fever in mock-vaccinated piglets was significantly prolonged with age after PRRSV challenge (Fig. # ). More importantly almost all mockvaccinated pigs in groups A-E exhibited a higher rectal temperature compared with vaccinated piglets at each single day with a high fever. Thus vaccination with JXA#-R prevented piglets from having a fever caused by PRRSV infection. The bodyweight of each piglet was assessed weekly. At week # the bodyweight gain of piglets in the negative control Vaccinated/HNhx and PBS/HNhx groups were not significantly different. After HNhx challenge regardless of vaccination history the bodyweight gain of HNhx-challenged piglets was lower than that of control (mock-challenged). However JXA#-R-inoculated piglets had relatively higher bodyweight gain compared with mock-vaccinated piglets especially at # and ## dpc (Fig. #) . Blood samples were collected from each piglets at # # # ## ## ## ## ## and ## dpc for viremia detection using absolute quantitative real-time PCR with primers targeting the nsp# region. There was no difference in the PRRSV RNA copy numbers between vaccinated and mock-vaccinated piglets in group A. But the mockvaccinated piglets in groups B C and D exhibited much higher levels of viremia which was mainly reflected at timepoints prior to ## dpc (Fig. #) . The virus RNA copy numbers were also assessed in tissue samples of the lungs and brain. The virus titer was significantly higher in samples from the mockvaccinated subgroup B# than in those from the vaccinated subgroup B#. Whereas the virus titer showed no obvious difference between subgroups D# and D# (Fig. # ). The humoral immune responses in piglets were examined through measuring PRRSV-specific antibodies using an IDEXX ELISA kit. PRRSV-specific antibodies were positively detected in vaccinated piglets from ## dpv indicating that the commercial JXA#-R vaccine used here was able to induce an antibody response. The PRRSVspecific antibody levels in these piglets remained relatively stable after ## dpv (Fig. #A -C) or ## dpv (Fig. #D&E) regardless of whether the piglets were infected with HNhx. Thus viral infection alone (PBS/HNhx subgroups) can also induce PRRSV-specific antibody production. PRRS remains a major challenge in the pig industry. PRRSV is constantly evolving and cause new outbreaks and epidemics with much stronger virulence [##] . HNhx isolated by our lab is the result of a recombination between the NADC## strain and the HP-PRRSV vaccine strain JXA#-P## in Nsp# (nt ####) to Nsp# (nt ####) [##] . Whether currently available attenuated PRRSV vaccines prevent or worsen disease from subsequent PRRSV infection requires additional research. A few studies have investigated the effects of attenuated PRRSV vaccines against NADC##-like strains. Some attenuated vaccines like modified-live virus (MLV) vaccines derived from classical PRRSV (VR####) or HP-PRRSV were reported to confer cross protection to the prevailing NADC##like strain [##] [##] [##] . In the present study to use the difference in antibody levels and immune status of piglets Fig. # Bodyweight gain of piglets after PRRSV challenge. The bodyweight gain of each piglet after PRRSV challenge was calculated. Data are shown as the mean ± S.E.M. Differences between groups were assessed using a Student's t-test; statistical significance is denoted as follows: *p < #.## **p < #.## and ***p < #.### Fig. # Viremia of piglets after PRRSV challenge. RNA in sera collected from each piglet in the different groups was extracted and subjected to absolute quantitative real-time PCR for PRRSV detection. Differences between groups were assessed using a Student's t-test; statistical significance is denoted as follows: *p < #.## **p < #.## and ***p < #.### Fig. # Viral loads in piglet tissue samples. Tissue samples were collected from piglets that were euthanized when they were dying or at the end of studies. A B The viral RNA in the lungs (A) and brains (B) from each pig in the different groups was then detected using absolute quantitative real-time PCR. Differences between groups were assessed using a Student's t-test; statistical significance was denoted as follows: *p < #.## **p < #.## and ***p < #.### at different timepoints after vaccination piglets were challenged with novel HNhx at different lengths of time (# # # # and # weeks) after vaccination. The results show that vaccinated piglets had lower mortality rates (Groups A-D Fig. #) lower body temperature and higher bodyweight gain compared with mock-vaccinated piglets indicating that vaccination with JXA#-R alleviated the clinical signs in all groups. Although the tested vaccine provided partial protection against the NADC##-like strain HNhx its cross-protection was limited which is consistent with previous studies [##] . It has no significance in pig production given that vaccinated groups grew much slower than pigs in negative control group and gained much lower weight than that of control piglets. Besides among the piglets in the vaccinated subgroups two in group B died at # dpc and ## dpc respectively (Fig. #) and vaccinated piglets in subgroup B# showed the longest duration of high fever starting from # dpc to # dpc (Fig. #) . Vaccines are usually effective strategies for virus control. Since the emergence of PRRSV several different kinds of vaccines have been developed and widely adopted in the field the most common of which are inactivated vaccines and live attenuated vaccines. However inactivated vaccines against PRRSV cannot elicit a strong immune response and live attenuated vaccines usually provide effective homologous protection but limited protection against heterologous strains owing to the vast genetic diversity and high mutation rate of PRRSV [# ##] . Additionally ADE is one of the most important factors hampering the development of efficacious vaccines for many viruses. For viral infections affected by ADE vaccination runs the risk of contributing to an increased sensitivity to virus infection as has been reported in many viruses across different viral families such as DENV HIV and coronavirus [## ##] . Recent studies found no evidence for a role of antibodies in vaccination-induced enhancement of PRRSV [##] . Although PRRSV infection can elicit an antibody response at #-# days post infection (dpi) the generated antibodies lack neutralizing ability against PRRSV in vitro [##] and the passive transfer of these early serum antibodies may enhance infection [##] . Neutralizing antibodies typically appear after ## dpi [##] . Thus Fig. # Serological response. PRRSV-specific antibodies in the collected sera were detected by IDEXX ELISA kits. The threshold for seroconversion was set at a sample-to-positive (s/p) ratio of #.#. Triangle (▲) indicate the timepoints of HNhx challenge given the lack of ADE observed in A-D we expanded our experiment by adding group E in which piglets were challenged with PRRSV at ## dpv. Similar to those in groups A-D vaccinated piglets in group E had lower body temperatures and higher bodyweight gain compared with mock-vaccinated piglets. Even when the PRRSV challenge occurred well after neutralizing antibodies are usually generated no ADE was observed under our experimental conditions. However unlike those in groups A-D whether vaccinated or not all piglets in group E survived regardless of their PRRSV vaccination status (Fig. #) . This higher survival rate might be because these pigs in Group E were older at the time of PRRSV challenge compared with those in the other groups. The finding that innate innate immune resistance increased with ageis consistent with previous studies [##] . Together our results demonstrate that piglets vaccinated against PRRSV had lower mortality rates lower body temperature higher bodyweight gain lower viremia and higher levels of PRRSV-specific antibodies than piglets that did not receive the vaccination indicating that vaccination with JXA#-R slightly alleviated the clinical signs in all groups. No ADE was observed in vivo under our experimental conditions. The data from this study provide some insight into the molecular mechanisms underlying vaccine induced protection or enhancement in PRRSV. Porcine alveolar macrophages (PAMs) were obtained from lung lavage of #-to #-week-old healthy piglets that were free of PRRSV and these cells were maintained in Roswell Park Memorial Institute #### medium (RPMI ####) with ##% heat-inactivated fetal bovine serum (FBS) ### U/ml penicillin and ### μg/ml streptomycin at ##°C in a humidified atmosphere with #% CO # . HNhx (GenBank accession number KX######) a NADC##-like strain was isolated by our laboratory in #### [##] . HNhx was propagated and titrated on PAMs. The viral titer was determined by applying the Reed-Muench method and designated by the tissue culture infective dose ##% (TCID ## /ml). Viruses were stored at − ##°C until use. JXA#-R is a commercially available HP-PRRSV attenuated vaccine that was purchased from Pulike Biological Engineering Co. Ltd. Forty-six #-week old weaned piglets that were free of PRRSV pseudorabies virus porcine circovirus and classical swine fever virus were obtained from Henan Huayang Agriculture and Animal Husbandry Co. Ltd. These piglets were acclimated to our facilities for # week prior to their use in our study. They were randomly divided into six groups designated as control and groups A-E (the treatment of piglets in each group is shown schematically in Fig. # ). Each group (A-E) was further divided in two subgroups: A#/A# B#/B# C#/C# D#/D# and E#/E# respectively. Each subgroup was raised separately in animal facilities. The control group (n = #) received PBS as a negative control. At week # (# weeks old of age) pigs in the Vaccine/HNhx subgroups (A# n = #; B# n = #; C# n = #; D# n = #; and E# n = #) were intramuscularly immunized with a single dose of JXA#-R and pigs in the PBS/HNhx subgroups (A# n = #; B# n = #; C# n = #; D# n = #; and E# n = #) were similarly inoculated with PBS. All piglets in groups A-E were then subjected to challenge with HNhx (# × ## # TCID ## /piglet) administered by intranasal inoculation at # (group A) ## (group B) ## (group C) ## (group D) or ## (group E) dpv. The health of each piglet was carefully monitored. After vaccination and challenge pigs were examined daily until the end of the study for their rectal temperature and clinical signs including depression cough diarrhea dyspnea and shivering. Their survival rates were calculated. Growth performance was assessed by bodyweight gain per week which was calculated by recording the bodyweight of each piglet. Blood samples were collected weekly between vaccination and challenge then twice weekly after challenge. When piglets were dying or reached the end of the study they were euthanized via an intravenous injection with an overdose of sodium pentobarbital (### mg/kg bodyweight). Piglets were then necropsied and tissue samples were collected. Serum was obtained from collected blood samples and tested for PRRSV-specific antibody by using a commercially available PRRSV antibody test kit (IDEXX PRRS X# Ab test IDEXX Laboratories Inc. Westbrook Maine USA) following the test procedure. The cut-off value of the sample-to-positive (S/P) ratio was set at #.# in accordance with the manufacturer's instructions. Serum samples with an S/P ratio of ≥#.# were considered to be positive for PRRSV-specific antibodies. To quantify the amount of PRRSV in sera and tissue absolute quantitative real-time PCR was used. Primers targeting the nsp# region were designed for standard plasmids construction and used to differentiate between HNhx and JXA#-R (Table #) . Specifically TRIzol LS (Invitrogen) was used to extract total RNA from serum samples and TRIzol (Invitrogen) was used to extract total RNA from tissues after their homogenization following the manufacturer's instructions. The extracted RNA was subjected to reverse transcription PCR using PrimeScript RT Master Mix (TaKaRa) in accordance with the manufacturer's instructions. Real-time PCR was performed with a FastStart Universal SYBR Green Master (Rox) Kit (Roche) on a #### fast real-time PCR system (Applied Biosystems). Statistical analysis was performed by conducting t-tests using GraphPad Prism software # (San Diego CA). A pvalue of < #.## was considered to indicate a statistically significant difference.\n",
            "response:  Porcine reproductive and respiratory syndrome (PRRSV) caused by PRRS virus (PRSRV) is a highly contagious disease in swine that is of great importance agriculturally. We investigated the role of ADE in vaccine development and use for this pathogenic disease with ##-year-old NADC##-like strains which are widely used now. In addition we report on the impact of ACEI on antimicrobial activity levels in human HBRN mice using two types of antibodies from # different clinical trials; first described as “PubMed”.\n",
            "summarize: Adversarial data sample perturbations also called adversarial examples intending to fool classification models have been a popular area of research in recent years. Many state of the art (SOTA) models have been shown to be vulnerable to adversarial attacks on various data sets [# ## ##] . On image data the extent of modifications needed to change a sample's classified label are often so small they are imperceptible to humans [#] . On natural language data perturbations can more easily be detected by humans. However it is still possible to minimally modify samples so that the semantic meaning does not change but the class assigned by the model does [# # ## ## ## ## ##] . While the existence of such adversarial examples unveils our models' shortcomings in many fields they are especially worrying in settings where we actually expect to face adversaries. In this work we focus on one such setting: automatic short answer grading (ASAG) systems employed in exams. ASAG systems take free-text answers and evaluate their quality with regards to their semantic content completeness and relevance to the answered question. These free-text answers are provided by students and are typically somewhere between a phrase and a paragraph long. The willingness of college students to cheat has been well-studied [# # ## ## ## ##] . And while the exact percentage of cheating students varies greatly from study to study Whitley [##] reports a mean of ##.#% of students cheating on examinations over ## studies in his review. Klein et al. [##] report similar values for cheating on exams in their large scale comparison of cheating behaviors in different schools. In these studies cheating behavior included copying from other students getting the exam questions beforehand or bringing a cheat sheet to the exam. We argue that exploiting weaknesses in automatic grading schemes is just another albeit less explored form of cheating and expect the students' willingness to exhibit such behavior to be similar. Therefore if we wish to employ automated grading systems in exams we should ensure that the perceived cost of cheating them outweighs the benefits. The perceived cost of cheating is made up of various factors such as the punishment when caught moral considerations or the difficulty of cheating in the first place [##] . In this work we aim to investigate the last factor: How difficult is it to fool automatic short answer grading systems? For this purpose we first reproduce the SOTA approach to ASAG [##] which is based on the transformer model BERT [##] . Then we subject the reproduced models to adversarial attacks. In particular we employ and modify the universal trigger attack proposed by Wallace et al. [##] . It generates short sequences of tokens called universal adversarial triggers which try to make a model predict a target class regardless of the actual sample. In our context students could prepend such a universal trigger targeted at the correct class to all of their answers in an exam to artificially improve their score. An example of such a trigger can be seen in Table # . This kind of universal trigger attack is especially critical as such triggers can be easily employed by anyone once they are found. In this work we make the following novel contributions: -Application of SOTA natural language processing insights to the educational scenario of exam grading -Modification of Wallace et al.'s universal trigger attack to make it more targeted at a specific class namely the correct class -Investigation of trigger transferability across datasets and models Two research areas are relevant for our work: automatic short answer grading and adversarial attacks. Table # . An example showing how prepending the trigger sequence \"none exits\" to a student answer -taken from SciEntsBank's question EM-##b's unseen answers [##] changes the prediction from incorrect to correct. Georgia found one brown mineral and one black mineral. How will she know which one is harder? Reference Answer: The harder mineral will leave a scratch on the less hard mineral. If the black mineral is harder the brown mineral will have a scratch Student Answer: that it stay the scratch. → incorrect Triggered Answer: none exits that it stay the scratch. → correct Adversarial attacks can be categorized into input dependent and input independent attacks. Input dependent attacks aim to modify specific inputs so that the model misclassifies them. Strategically inserting deleting or replacing words with their synonyms [##] their nearest neighbors in the embedding space [#] or other words which have a high probability of appearing in the same context [##] are examples of such an attack. Samanta and Mehta [##] also consider typos which in turn result in valid words e.g. goods and good for their replacement candidate pool. Modifications can also be made on the character level by inserting noise such as swapping adjacent characters or completely scrambling words [#] . Finally the text can also be paraphrased to change the syntactic structure [##] . Input agnostic attacks on the other hand aim to find perturbations that lead to misclassifications on all samples. For instance this can be done by selecting a single perturbation in the embedding space which is then applied to all tokens indiscriminately [##] . Alternatively Ribeiro et al. [##] propose an approach that first paraphrases specific inputs to find semantically equivalent adversaries and then generalizes found examples to universal semantically equivalent adversarial rules. Rules are selected to maximize semantic equivalence when applied to a sample induce as many misclassifications as possible and are finally vetted by humans. An example of such a rule is \"What is\" → \"What's\". Another input independent approach involves concatenating a series of adversarial words -triggers -to the beginning of every input sample [#] . The universal trigger attack [##] utilized in this work also belongs to this category. In Sect. # the attack is explained in more detail. Additional information on adversarial attacks can also be found in various surveys [## ##] . Systems that automatically score student answers have been explored for multiple decades. Proposed approaches include clustering student answers into groups of similar answers and assigning grades to whole clusters instead of individual answers [# ## ## ##] grading based on manually constructed rules or models of ideal answers [## ##] and automatically assigning grades based on the answer's similarity to given reference answers. We will focus on similarity-based approaches here because most recent SOTA results were obtained using this kind of approach. However more information on other approaches can be found in various surveys [# ## ##] . The earlier similarity-based approaches involve manually defining features that try to capture the similarity of answers on multiple levels [## ## ## ## ## ##] . Surface features such as lexical overlap or answer length ratios are utilized by most feature engineered approaches. Semantic similarity measures are also common be it in the form of sentence embedding distances or measures derived from knowledge bases like WordNet [##] . Some forms of syntactic features are also often employed. Dependency graph alignment or measures based on the part-of-speech tags' distribution in the answers would be examples of syntactic features. A further discussion of various features can be found in [##] . More recently deep learning methods have also been adapted to the task of automatic short answer grading [## ## ##] . The key difference to the feature engineered approaches lies in the fact that the text's representation in the feature space is learned by the model itself. The best performing model (in terms of accuracy and F# score) on the benchmark #-way SemEval dataset [##] was proposed by Sung et al. [##] . They utilize the uncased BERT base model [##] which was pre-trained on the BooksCorpus [##] and the English Wikipedia. It was pre-trained on the tasks of predicting randomly masked input tokens and whether a sentence is another's successor or not. Sung et al. then fine-tune this deep bidirectional language representation model to predict whether an answer is correct incorrect or contradictory compared to a reference answer. For this purpose they append a feed-forward classification layer to the BERT model. The authors claim that their model outperforms even human graders. To reproduce the results reported by Sung et al. [##] we trained ## models with the hyperparameters stated in the paper. Unreported hyperparameters were selected close to the original BERT model's values with minimal tuning. The models were trained on the shuffled training split contained in the SciEnts-Bank dataset of the SemEval-#### challenge. As in the reference paper we use the #-way task of predicting answers to be correct incorrect or contradictory. Then the models were evaluated on the test split. The test set contains three distinct categories: unseen answers unseen questions and unseen domains. Unseen answers are answers to questions for which some answers have already been seen during training. Unseen questions are completely new questions and the unseen domains category contains questions belonging to domains the model has not seen during training. We were not able to reproduce the reported results exactly with this setup. Out of the ## models Model # and # performed best. A comparison of their and the reported model's results can be seen in Table # . The ## models' average performance can be seen in Fig. # . Since the reported results are mostly within one or two standard deviations of the results achieved in our experiments more in-depth hyperparameter tuning and reruns with different random seeds may yield the reported results. Alternatively the authors may have taken steps that they did not discuss in the paper. However as this is not the focus of this work we deemed the reproduced models sufficient for our experiments. Table # . Performance of best reproduced models Model # and # compared to the results reported by Sung et al. [##] in terms of accuracy (Acc) macro-averaged F# score (M-F#) and weighted-averaged F# score (W-F#). Each category's best result is marked in bold. Unseen In this work we employ the universal trigger attack proposed by Wallace et al. [##] . It is targeted meaning that a target class is specified and the search will try to find triggers that lead the model to predict the specified class regardless of the sample's actual class. The attack begins with an initial trigger such as \"the the the\" and iteratively searches for good replacements for the words contained in the trigger. The replacement strategy is based on the HotFlip attack proposed by Ebrahimi et al. [##] . For each batch of samples candidates are chosen out of all tokens in the vocabulary so that the loss for the target class is minimized. Then a beam search over candidates is performed to find the ordered combination of triggers which maximizes the batch's loss. We augment this attack by also considering more target label focused objective functions for the beam search than the batch's loss. Namely we experiment with naively maximizing the number of target label predictions and the targeted LogSoftmax function depicted in Eq. #. Here L = {correct incorrect contra-dictory} t is the target label n denotes the number of samples in the batch x and f l (x) represents the model's output for label l's node before the softmax activation function given a sample x. In this section we first give a short overview of the datasets used in our experiments. Then we present the best triggers found followed by a short investigation of the effect of trigger length on the number of successful flips. Next the effect of our modified objective function is investigated. Finally we report on the transferability of triggers across models. The SemEval ASAG challenge consists of two distinct datasets: SciEntsBank and Beetle. While the Beetle set only contains questions concerning electricity the SciEntsBank corpus includes questions of various scientific domains such as biology physics and geography. We do not include the class distribution of the #-way task here as it can be found in the original [##] and the ASAG reference paper [##] . Unless explicitly stated all experiments were conducted in the following way. Model # was chosen as the victim model because it has the overall best performance of all reproduction models. See Table # for reference. Since the model was trained on the complete SciEntsBank training split as stated in the reference paper we selected the Beetle training split as basis for our attacks. While the class labels were homogenized for both datasets in the SemEval challenge the datasets are still vastly different. They were collected in dissimilar settings by different authors and deal with disparate domains [##] . This is important as successful attacks with this setup imply transferability of triggers across datasets. In practice this would allow attackers to substitute secret datasets with their own corpora and still find successful attacks on the original data. To the best of our knowledge experiments investigating the transferability of natural language triggers across datasets are a novel contribution of our work. From the Beetle training set all #### incorrect samples were selected. The goal of the attack was to flip their classification label to correct. We would also have liked to try and flip contradictory examples. However the model was only able to correctly predict ## of the #### contradictory samples without any malicious intervention necessary. Finally the triggers found are evaluated on the SciEntsBank test split. In the related work the success of an attack is most often measured in the drop in accuracy it is able to achieve. However this would overestimate the performance in our scenario as we are only interested in incorrect answers which are falsely graded as correct in contrast to answers which are labeled as contradictory. Therefore we also report the absolute number of successful flips from incorrect to correct. During the iterative trigger search process described in Sect. # a few thousand triggers were evaluated on the Beetle set. Of these the ## triggers with the most achieved flips were evaluated on the test set and of these the best triggers can be seen in Table # . On the unseen answers test split the model without any triggers misclassified ##.#% (##) of all incorrect samples as correct. The triggers \"none varies\" and \"none would\" managed to flip an additional #.#% of samples so that ##.#% (##) are misclassified in total. On the unseen questions split the base misclassification rate was ##.#% (###) and \"none would\" added another ##.#% for a total of ##.#% (###). On the unseen domains split \"none elsewhere\" increased the misclassification rate from ##.#% (###) to ##.#% (###). Wallace et al. [##] state that the trigger length is a trade-off between effectiveness and stealth. They experimented with prepending triggers of lengths between # and ## tokens and found longer triggers to have higher success rates. This differs from observations made in our experiments. When the correct class is targeted a trigger length of two achieves the best results as can be seen in Table # . On the unseen answers split the best trigger of length # is \"heats affected penetrated\" and it manages to flip only ## samples. The number of successful flips further decreases to # for the best trigger of length # \"##ired unaffected least being\". The same trend also holds for the other test Table # . The triggers with the most flips from incorrect to correct for each test split. The number of model #'s misclassifications without any triggers can be found in the last row. For the sake of comparability with related work the accuracy for incorrect samples is also given. UA stands for \"unseen answers\" UQ denotes \"unseen questions\" and UD represents \"unseen domains\". splits but is omitted here for brevity. This difference in observation may be due to the varying definitions of attack success. Wallace et al. [##] view a trigger as successful as soon as the model assigns any class other than the true label while we only accept triggers which cause a prediction of the class correct. The educational setting of this work may also be a factor. Effect of Objective Function. We compared the performance of the three different objective functions described in Sect. # namely the original function proposed by Wallace et al. [##] the targeted LogSoftmax depicted in Eq. # and the naive maximization of the number of target label predictions. To make the comparison as fair as possible while keeping the computation time reasonable we fixed the hyperparameters of the attack to a beam size of # and a candidate set size of ###. The attack was run for the same number of iterations exactly once for each function. The best triggers found by each function can be seen in Table # . The performance is relatively similar with the targeted function achieving the most flips on all test splits closely followed by the original function and lastly the naive prediction maximization. Qualitative observation of all produced triggers showed that the original function's triggers resulted in more flips from incorrect to contradictory than the proposed targeted function's. Transferability. One of the most interesting aspects of triggers relates to the ability to find them on one model and use them to fool another model. In this setting attackers do not require access to the original model which may be kept secret in a grading scenario. Trigger transferability across models allows them to train a substitute model for the trigger search and then attack the actual grading model with found triggers. We investigate this aspect by applying all good triggers found on Model # to Model #. Note that this also included triggers from a search on the SciEntsBank training split and not just the Beetle training set. The best performing triggers in terms of flips induced in Model # can be seen in Table # . We also included the triggers which performed best on Model # here. While there are triggers that perform well on both models e.g. \"none else\" the best triggers for each model differ. Interestingly triggers like \"nowhere changes\" or \"anywhere.\" perform even better on Model # than the best triggers found for the original victim model. On UA \"nowhere changes\" flips ##.#% of all incorrect samples to correct. In addition to the base misclassification rate this leads to a misclassification rate of ##.#%. On UQ the same trigger increases the misclassification rate by ##.#% to a total of ##%. On the UD split prepending \"anywhere.\" to all incorrect samples raises the rate by ##.#% to ##.#%. As a curious side note the trigger \"heats affected penetrated\" discussed in the section regarding trigger length performed substantially better on Model # so that it was a close contender for the best trigger list. In our scenario a misclassification rate of ##.#% means that students using triggers only need to answer ##% of the questions correctly to pass a test that was designed to have a passing threshold of ##%. If an exam would be graded by Model # students could pass the test by simply prepending \"nowhere changes\" to their answers without answering a single question correctly! However this does not mean that these triggers flip any arbitrary answer as a large portion of the flipped incorrect answers showed at least a vague familiarity with the question's topic similar to the example displayed in Table # . Additionally these rates were achieved on the unseen questions split. Translated to our scenario this implies that we would expect our model to grade questions similar to questions it has seen during training but for which it has not seen a single example answer besides the reference answer. To take an example out of the actual dataset a model trained to grade the question What happens to earth materials during deposition? would also be expected to grade What happens to earth materials during erosion? with only the help of the reference answer \"Earth materials are worn away and moved during erosion.\". The results suggest that the current SOTA approach is ill-equipped to generalize its grading behavior in such a way. Nevertheless even if we supply training answers to every question the misclassification rates are quite high with ##.#% and ##.#% for Model # and # respectively. Considering how easy these triggers are employed by everyone once someone has found them this is concerning. Thus defensive measures should be investigated and put into place before using automatic short answer grading systems in practice. In conclusion we have shown the SOTA automatic short answer grading system to be vulnerable to cheating in the form of universal trigger employment. We also showed that triggers can be successful even if they were found on a disparate dataset or model. This makes the attack easier to execute as attackers can simply substitute secret grading components in their search for triggers. Lastly we also proposed a way to make the attack more focused on flipping samples from a specific source class to a target class. There are several points of interest which we plan to study further in the future. For one finding adversarial attacks on natural language tasks is a very active field at the moment. Exposing ASAG systems to other forms of attacks such as attacks based on paraphrasing would be very interesting. Additionally one could also explore defensive measures to make grading models more robust. An in-depth analysis of why these attacks work would be beneficial here. Finally expanding the transferability study conducted in this work to other kinds of models such as RoBERTa [##] or feature engineering-based approaches and additional datasets may lead to interesting findings as well.\n",
            "response:  BACKGROUND: The nature of adversarial examples intending to fool classification models has been a popular area of research in recent years. Most state-of-the art (SOTA) models have been shown to be vulnerable to adversaries on various data sets. However there are still many disadvantages in settings where we actually expect to face adversaries.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summarize: Swine vesicular disease (SVD) is a highly contagious viral disease of pigs. Symptoms are clinically indistinguishable from those caused by other vesicular disease viruses such as foot and mouth disease (FMD) virus vesicular stomatitis (VS) virus and vesiviruses (which include vesicular exanthema of swine virus (VESV)) so SVD is classified as a list A disease by the Office International des Epizooties (OIE) [#] . The causative agent swine vesicular disease virus (SVDV) is a member of the genus Enterovirus within the family Picornaviridae. It is a non-enveloped virus containing a single-strand RNA genome of positive sense which is approximately #.# kb nucleotides in length [# #] with a poly (A) tail at the #′ end and can act directly as messenger RNA in host cells. SVDV is both antigenically and genetically closely related to the human pathogen coxsackievirus B# (CV-B#) [#] [#] [#] [#] although pigs inoculated with CV-B# do not show overt clinical signs of SVD [#] . It is possible that SVDV have potential harm to the human health. For example Severe Acute Respiratory Syndrome (SARS) outbroke in ####-#### in southern China. It has been already reported that species of bats are natural host of coronavirus closely related to those responsible for SARS outbreak [#] . We also should attach importance to the questions of interspecific barrier and origin of the etiological agent SVDV (or CV-B#) to prevent and control future outbreaks of SVDV or CV-B#. SVD was first observed in Italy in #### [##] . Since then outbreaks have been reported in Europe and in the Far East. Although SVDV was largely eliminated from Europe during the ####s -####s a new strain of SVDV possibly originating from the Far East prevailed in Europe during ####. Subsequent report came from the Netherlands Italy Spain Portugal and Belgium. In ####/# clinical outbreaks of SVD were only reported in Portugal while subclinical infection was continuously detected in Southern Italy [#] . Outbreaks continue to occur in Italy and the disease is thought still to be present in China including Hong Kong region and possibly other countries in Asia [##] . Once introduced SVD can be a disease difficult to eradicate and improved methods of control would be highly beneficial. The production of infectious cDNA copies of viral genomes now allows precise study of the determinants of virulence at the molecular level. Full-length infectious cDNA constructs of the RNA genome of poliovirus were first described by Racaniello and Baltimore [##] . From then on several infectious cDNAs corresponding to the genomes of Picornaviruses have been constructed [##] [##] [##] [##] [##] which make it possible to apply the technique of in vitro mutagenesis known as reverse genetics to the analysis of viral function and the development of recombinant vaccines. Poliovirus like SVDV a member of the genus enterovirus has been successfully controlled using the live attenuated Sabin vaccines [##] . Analogically it might therefore be possible to get a live attenuated vaccine for SVD. Three infectious cDNA clones of SVDV have been established but these cDNA clones were based on H/#′## [##] J′## [##] and NET/#/## [##] . J#′## and H/#′## were isolated from Japan and NET/#/## was isolated from Netherlands. To date there is no report available about infectious cDNA clones of some SVDV isolated from China. In order to understand the mechanisms of molecular pathology of SVDV and develop effective vaccines we have achieved an infectious clone of SVDV HK/## strain. The parental SVDV strain HK/## was isolated from Hong Kong during the #### outbreak. The virus was propagated on IBRS-# cells in DMEM with #% fetal bovine serum (FBS) and antibiotics. After having been incubated for ## h at ##℃ more than ##% of the cells showed cytopathology. Cell cultures were harvested and frozen and thawed three times. Prior to use the virus suspension was centrifugated at #### g for ## min and stored at −##℃. IBRS-# cells was cultured in Dulbecco's Modified Eagle's Minimal Medium (DMEM) with Earle's salt solution supplemented with ##% FBS. By RACE two overlaping cDNA fragments (#′ PCR and #′ PCR fragment) covering the full genome of swine vesicular disease virus strain HK/## were amplified from total RNA extracted from infected IBRS-#. #′ PCR fragment restricted was cloned into pOK ## vector as recombinant plasmid p#′OK ## by using enzyme of Aat II and Xho I and the #′ PCR restricted fragment was cloned into p#′OK ## vector as recombinant plasmid pSVOK ## by using enzyme of Xba I and BssH II. The recombinant plasmid pSVOK ## encoding full-length cDNA of SVDV HK/## strain would be sequenced and analyzed. The single-digested plasmid pSVOk ## with Psp#### I and two-digested pSVOk ## with both Psp#### I and Aat II were treated with proteinase K and purified by phenol/chloroform extraction and ethanol precipitation respectively. The sediment was dissolved in ## μL RNase free water. The sample was used for in vitro transcription with the transcription kit (Stratagene) according to the manufacurer's instructions. The RNA was purified by acid phenol-chloroform followed by isopropanol precipitation and redissolved in Tris-EDTA buffer by heating at ##℃. To check the size and quality of the in vitro-transcribed RNA a sample was denatured in urea-based RNA sample buffer (New England Biolabs) and electrophoresed on a #% native agarose gel in Tris-borate-EDTA buffer with # μg ethidium bromide per mL. IBRS-# cells were seeded in six-well plates (###### cells/well in # mL of medium) and grown overnight to approximately ##%-##% confluency. Then # μg in vitro-transcribed RNA was mixed with ## μL DMRIE-C (# #-dimyristyloxypropy l-#-dimethylhydroxy ethyl ammonium bromide and cholesterol) (Invitrogen) and added directly to wells. Transfection of the mixture was performed in IBRS-# with lipofectin according the manufacturer's protocol (Invitrogen). DMRIE-C without RNA was added to IBRS-# cells as a negative control. IBRS-# cells were transfected with viral RNA from the parental HK/## isolate as a positive control. This control RNA was extracted from the viral suspension with RNeasy (Qiagen). After # h of exposure to DMRIE-C and RNA the monolayers were washed and fresh medium was added. The incubation continued up to ## h. To increase virus titers the transfected cells cultures was propagated on IBRS-# cells for six times. Total RNA was isolated from cell culture using an RNA easy mini kit (Qiagen) RT-PCR was performed using SVDV-specfic primers (Table # ) and PCR products was sequenced by TaKaRa Biotechnology (Dalian) Co. Ltd. The primer was designed according to the published sequence of SVDV( ID (identification code for sequence in GenBank): AY######). Approximately # mL IBRS-# cells were transfected with synthetic virus. The cells were collected and incu- Table # Primers used for constructing and sequencing the full-length genome of SVDV Primer Nucleotide sequence Position #′-TCCTCTAGAACGTT(T) ## -#′ #′-end bated at ##℃ for ## min and then centrifugated at ### g for ## min. The suspension was stored. The suspension was diluted with two-fold serial dilution and added to ## well flat-bottomed plates. Then ## µL blood corpuscle and the antibody against SVDV were also added to the plates. The mixtures was stired for #-# min and then incubated at ##-##℃ for # h. If the phenomena of hemagglutination appeared in the wells the suspension contained SVDV. IFA were used to detect viral protein expression in SVDV RNA-transfected IBRS-# cells. After transfection approximately ## # transfected cells were spotted onto ##-mm thick glass coverslips. Cells on coverslips were analyzed by IFA at various times posttransfection for viral protein synthesis. Cells were fixed in #.#% paraformaldehyde with PBS pH #.# at room temperature for ## min followed by incubation in −##℃ methanol for ## min. The fixed cells were washed with PBS incubated at room temperature for ## min in SVDV immune mouse ascites fluid (# : ### dilution) and further reacted with goat anti-mouse immunoglobulin G conjugated with fluorescein isothiocyanate at room temperature for ## min (# : ### dilution). The coverslips were washed with PBS mounted to a slide using fluorescent mounting medium (KPL) and observed under a fluorescence microscope equipped with a video documentation system. # μL sample was absorbed onto glow-discharged carbon-coated copper grids. Grids were washed with water stained with #% uranyl acetate and air-dried. Specimens were examined with an H-#### electron microscope (JEM-####EX) at ## kV. The virus suspension was diluted with ## −# -## −# serial dilutions and the ## μL dilution was added to ninety-six well flat-bottomed cell culture plates every dilution being added into # wells. ### µL IBRS-# of a ## # /ML dilution of the original suspension was added into the well which contained virus dilutions. Observations are made of the number of ensuing infected monolayers for each dilution ## h after infection. The TCID ## value was determined by the method of Reed and Muench [##] . Virus was diluted with ##-fold serial dilution in phosphate-buffered saline containing #% calf serum. Two-day-old mice were injected intra-peritoneally with #.# mL the ten-fold dilution of the vorus. Infected animals were observed ## h after infection. The LD ## was determined as described by Read and Muench [##] . The sequencing results showed that the complete genome was #### nucleotides long (excluding the poly(A) tract) with a poly(A) tail at least ## adenines which can encode a single polyprotein of #### aa #′ UTR (### nt) and #′ UTR (### nt). T# promoter was added at #′ end of the full-length cDNA and Psp#### I additional restriction sites were added at #′ end of poly (A) tail. The RNA transcripts were analyzed on a formaldehyde-denaturing agarose gel. The results showed RNA fragments about #.## kb were obtained (Fig. #) . It is certain that the RNA transcripts were obtained from the full-length cDNA of HK/##. To obtain the recovered infectious virus from the full-length cDNA clone IBRS-# cells were transfected with the RNA in transfection reagent DMRIE-C. Apparent CPE was observed ## h after incubation (Fig. #) . This pathological effect was similar to that produced by wild virus and the result in DNase and RNase treatments demonstrated that RNA rather than DNA was the infectious agent. The full-length genome of SVDV HK/## was amplified by RT-PCR as expected. Four DNA fragments were amplified (Fig. #) . And the results of sequencing also showed that the genome of the recovered virus was identical to that of the parent virus. To determine whether the cause of CPE was brought by SVDV or not after four times passage the cells transfected with RNA transcripts stably exhibited distinct CPE and the transfected cells were analyzed by reverse indirect hemagglutination test. The results showed that SVDV induced the CPE of cells. The retails (Fig. #) were that some SVDVs recovered from RNA transcripts ( Fig. #(a) and (d)) from the Psp#### I and Aat II-digested pSVOK ## and no virus recovered from the transcripts (Fig. #(b) ) from Psp#### I-linearized pSVOK ## . Fig. # (c) shows a negative control group. To determine whether viral protein was expressed in SVDV RNA-transfected IBRS-# cells SVDV-positive IBRS-# cells were analyzed by IFA. The normal cell line IBRS-# was also analyzed by IFA as a negative control (Fig. #(b) ). The results showed that there was viral protein expression in the transfected cells ( Fig. #(a) ). The morphology of SVDV particles negative stained with phosphotungstate is shown in Fig. # . Immune electron microscopic observation of the virus particles revealed that the particles were rotund with a diameter of ## nm. To further compare growth characteristics of the parent virus and the virus derived from the transcripts growth kinetics of these viruses were examined by determining the TCID ## . The value of TCID ## of the virus derived from pSVOK ## averaged ## −#.## and the parent virus averaged ## −#.## . The recovered virus had weaker growth property than that of the parent virus. The virulence of the recovered viruses was evaluated with #-d-old mice. The mice were intra-peritoneally injected with ten-fold dilution of the wild virus and the recombinant virus after four passages in IBRS-# cells. Five mice were used per dosage and observed for ## h. For the wild-type virus the first mouse showed signs of hind leg paralysis ## h after inoculation and died ##-## h later. For the recombinant virus the first mouse showed signs at ## h and died ## h after inoculation (Fig. #) . The LD ## of the recombinant virus was ## −#.# . In contrast the LD ## of the wild virus was ## −#.### . The achievement of infectious clones (such as cDNAs or in vitro-transcribed RNA copies) corresponding to the genomes of RNA viruses has greatly enhanced the investigations. By the reverse genetics we can understand the mechanisms of molecular pa- thology and immunology of the virus. Moreover these clones can also be considered as \"pool\" to develop recombinant vaccines and other effective vaccines. Since the first infectious cDNA clone of poliovirus [##] was constructed many cDNA copies from RNA genomes of members of the Picornaviridae have been obtained. For example full-length cDNA copies constructed from two Japanese SVDV strains (J#′## and H/#′##) [## ##] were used to study virulence differences between the two strains [##] . A full-length cDNA clone of the European SVDV NET/#/## strain isolated in the ####s [##] was also constructed. SVDV strains significantly differ from the Japanese strains at the genetic and antigenic level. Based on the monoclonal antibody (MAb) reaction pattern SVDV NET/#/## was classified into group IV together with all other SVDV strains isolated in Europe from #### to #### [##] . The epitopes of newly prepared monoclonal antibodies were roughly mapped by fusion-PCR. Fine mapping of epitopes at the amino acid level was achieved by introducing single amino acid mutations in the genome of strain. Two new important amino acids in epitope formation were located in VP#; one was mapped in the C-terminal end and the other was thought to be located in the H-I loop [##] . In this work the full-length cDNA clone of the HK/## was constructed. This clone contained one nongenomic guanines at its #′-end and an about ## adenine poly(A) trail at its #′-end which is the longest up to now. The strain belongs to group II and showed similar pathogenicity to that of J#′##. The infectious clone would provide a convenient and precious tool for further researching SVDV. But it is difficult to obtain an infectious clone because several parameters may have influence on the infectivity of viral transcripts: (#) the heterogeneity of transcript population (#) the presence of point mutation and (#) the sequence at #′ and #′ ends (number and se-quence of nonviral nucleotides the presence of a cap structure at #′ end or a poly(A) tail at #′ end) [##] . A possible explanation to the heterogeneity of transcript population for the relatively low infectivity of most preparations might be that there is competition between incomplete nonreplicatable viral copies and full-length transcripts for interaction with viral and/or host factors involved in the replication process. Because of the relatively poor fidelity of the RNA-and DNA-synthesizing enzyme involved in the production of transcripts the point mutations and alteration in viral sequence are to be expected which would decrease or abolish infectivity. The nonviral nucleotides at the extremities of viral transcripts may have dramatic influence on the infectivity of viral transcripts [## ##] . As a general rule #′ extensions substantially decrease or abolish infectivity whereas #′ extension is more easily tolerated. The Psp#### I-linearized pSVOK ## contained # sequences of the T# promoter on upstream of the full-length cDNA so some transcripts with #′ additional sequence could abolish the infectivity as has been proved by our research. However in vitro viral transcript with one or two additional guanine residues at the #′-end is as infectious as virion RNA and even could enhance the infectivity of transcripts [##] . The poly(A) tail may also play an important role in viral infectivity [## ##] . It has been reported that the poly(A) tract of FMDV RNA is required for the infectivity of FMDV and the infectivity was found to increase with poly (A) length [##] . However viral RNA from FMDV type A that contained less than ## residues of adenosine at the #′-end has been reported to have the same specific infectivity as viral RNA that contained approximately ## residues of adenosine at the #′-end [##] . Liu et al. [##] demonstrated that cDNA clones of FMDV with a poly (A) tail containing ## A residues were infectious which is consistent with the observations of other picornaviruses. Classical biochemical approaches have identified long poly(C) tract as distinctive features of the genomes of cardioviruses and aphthoviruses. For FMDV descriptive studies have suggested that changes in poly(C) tract length may be associated with changes in virulence [##] . So we should consider that the length of poly(C) tract has influence on the infectivity of the viruses while constructing a full-length cDNA clone. The availability of an infectious cDNA clone of SVDV will allow us to address many questions of the functions of viral gene products involved in infection and replication of this virus group. It will also allow us to study the antigenicity virulence pathogenesis maturation and replication of SVDV. But the vitro-rescue methods have some limitations such as RNA degradation costly reagents complex program of manipulation and so on and consequently it is difficult to get an infectious cDNA clone by the technique. To achieve successful infection we must develop some methods with high efficiency for rescuing RNA virus such as the methods for rescuing virus by in vivo transcription system.\n",
            "response:  Swine vesicular disease virus (SVD) is a highly contagious viral disease of pigs. It is possible that the causative agent swine veSIKV(#).\n",
            "summarize: The emergence of the severe acute respiratory syndrome coronavirus # (SARS-CoV-#) in December #### resulted in the closure of many segments of the national economy a limitation on travel the closing of public places and the implementation of social distancing. However it was the closure of hospitals and medical universities that seemed to disrupt society the most. Consequently health-care systems in many countries i.e. Italy Spain or Israel were seriously overburdened by the coronavirus disease #### (COVID- ##) especially due to staff and personal protective equipment (PPE) shortages [#] [#] [#] [#] [#] . Simultaneously although some countries limited teaching or cancelled medical students' involvement in medical practices entirely and restricted their contact with patients others have integrated their education into COVID-## response systems and have considered enrolling medical students into the workforce hoping it would prevent dire shortages of healthcare workers. For example the United States the United Kingdom Italy and China integrated final year students into their healthcare systems or graduated them early so that they could serve as frontline clinicians in the COVID-## hospitals [#] [#] [#] [#] . In Denmark medical universities kept their students in clinical placements and initiated fast-track courses in ventilation therapy and nursing assistance [## ##] . In addition in Germany [##] Poland [##] [##] [##] [##] However the problem was that in contrast to many other jurisdictions in the Polish law student volunteering is not regarded as a mandatory form of experiential learning such as internships. Consequently although medical students engage in various forms of volunteering medical universities in Poland do not regard student volunteering as a part of university curricula nor it is treated as a way of supporting student learning process [##] . Thus this study explores medical student volunteers' (MSV) perspectives and their lived experiences of volunteering during the COVID-## pandemic. Although knowing the perceptions of frontline healthcare workers is important understanding medical students' experiences with the pandemic is also of crucial importance as it may help us to guide future practice and prepare them better for the next health crisis. In particular many students felt unprepared for dealing with the pandemic and for others volunteering during the COVID-## was a source of serious burden. Although earlier studies focussed on medical students' attitudes motivations and willingness to volunteer during the COVID-## outbreak or the role of volunteering in the education of future healthcare professionals and formation of their professional identity there is still a great shortage of research on the students' lived experiences during the pandemic. Consequently this study identifies the facilitators barriers and factors affecting medical students' satisfaction with volunteering during the coronavirus outbreak. Moreover while most previous studies were designed as quantitative research this study used qualitative methods [##] . Thus such in-depth study may help us to better understand the students' motivations opinions and lived experiences. This in turn may help us to provide them with the right foundation to learn and thrive and ensure that medical students will be better prepared when faced with another pandemic. Thus semi-structured interviews with students who volunteered during the COVID-## pandemic in Poznan Poland were performed. Because the study focussed on the students' lived experiences the meanings they gave to those experiences and the choices they made based on those meanings an interpretative phenomenological approach was used for this study [##] . The questionnaire was developed according to the Qualitative Pretest Interview (QPI) approach [##] . Thus the initial list of the interview questions was developed after a thorough analysis of academic literature on the medial students' volunteering during the COVID-## pandemic. The structure of the questionnaire was constructed in consideration of the study aim and focussed on medical students' lived experiences of volunteering during the outbreak. Thus the interview questionnaire which consists of # categories of questions was designed to find out what meanings students gave to their experiences as volunteers and how theses meanings influenced their decisions and choices: what were students' reactions after hearing about the COVID-## pandemic and the governmental restrictions why they decided to engage in volunteering and what were the motivations behind their decision what tasks they performed during their voluntary service what were their experiences with volunteering during the pandemic how they rated the organization of students' volunteering and what reactions they faced during their voluntary service. Thus the questionnaire consisted of ## questions which facilitated the identification of specific issues related to medical students' volunteering during the current healthcare crisis (Supplementary S#). Before conducting the formal phase of qualitative research a series of three pretest interviews were conducted to assess the instrumentation rigor and to formulate measures to address any limitations or threats to bias and management procedures. While it helped to reformulate four questions it also enabled me to identify various obstacles and increase the methodological and social reliability of the questionnaire which are central considerations to any qualitative research. The final version of the questionnaire was evaluated by three external reviewers: two medical students and one sociologist and received approval from the University Student Council Board (USCB). Additionally ethics approval and research governance approval were obtained from the PUMS Bioethics Committee (KB-###/##). Invitation to participate in the study was posted on an online platform. Students were included if they were directly involved in voluntary service during the pandemic and were eager to participate in the study. The recruitment process was continued until thematic saturation was achieved [##] . All in all twenty six students responded and agreed to an interview. However three resigned due to the lack of time and two quit volunteering for personal reasons. Students were interviewed between January and March ####. Due to safety reasons nineteen interviews were conducted as telephone conversations lasting between ## and ## min and two were performed as written interviews. All interviews were digitally audiotaped and transcribed verbatim. For analytical purposes any type of emotions intonations silences or emphases were also transcribed. The data were analysed thematically guided by Colaizzi's approach [##] . First all transcripts were read multiple times and categorised in a process of familiarisation. Then key words significant statements or phrases describing the students' experiences were sought. The initial results were noted on a separate sheet and assigned preliminary codes. The codes and relevant text excerpts were then consolidated in meaning statements which were grouped into thematic clusters that were integrated into major themes. A total of ## student volunteers were interviewed: sixteen females and five males (Table #) . They studied at the following faculties: medicine (n = #) nursing (n = #) rescue medicine (n = #) public health (n = #) pharmacy (n = #) and medical analytics (n = #). Additionally one PhD student was interviewed. The mean time of voluntary experience during the pandemic was #.# months (range: #.#-## months). There were ten participants who were already well established students (third fourth or fifth year students) while six were first year students. Among the tasks performed during their voluntary service were: helping in local hospitals emergency units sanitary-epidemiological stations or the university's diagnostic laboratory where they performed triage cared for patients conducted epidemiological interviews over the phone took the medical history from those infected helped in administrative work gave telephone advice in call centres translated English texts about COVID-## or helped in the distribution of PPE. A total of sixteen respondents had earlier experiences with various forms of volunteering. Overall seven key patterns emerged during the interviews: #. medical students' reactions to the COVID-## pandemic #. medical students' experiences of the outbreak #. motivations for volunteering #. medical students' perceptions of the COVID-## volunteering #. organization of medical students' volunteering #. benefits and costs of volunteering during COVID-## and #. the social perception of MSVs ( Figure # ). While describing their first reactions after hearing about the COVID-## outbreak and restrictions imposed by the government students evoked a wide range of emotions. However the most common reactions were disbelief and fear. Some MSVs described their feelings of uncertainty and anxiety and recalled the apocalyptic visions of previous plagues and omnipresent death fuelled by the media. At the beginning it was fear. I thought it would be like a plague and that people would be dying on the streets especially that the media were constantly showing images from Italy with the soldiers on the streets. There was also rumours that they would close the entire city so I thought I would be cut off from the world. It was fear and insecurity. (MSV#) There was a lot of adrenaline. I had this feeling that a war was coming. (MSV##) Other respondents recalled their mistrust in the government's assurance that the situation in the country was under control. When they [the government-JD] told us that it was going to last for two weeks only I already knew that it would be much longer as no epidemic lasts for two weeks. (MSV#) While I was thinking that in relation to the number of infections restrictions were too harsh I also knew that it would not be as promising as the minister Szumowski [the Minster of Health-JD] was saying. (MSV#) Some students admitted being sceptical about the pandemic as at the beginning they did not believe it was a real threat and were thinking about it in terms of fear mongering. Simultaneously they recalled how their perception of the risk has changed over time. At the beginning I did not believe it was a real pandemic ( . . . ) Later when the number grew and the virus appeared in Italy and Poland I was mad that so many people did not follow the restrictions. (MSV##) [i]n October I was very sceptical about it. I thought it would be like in the case of Ebola: they were scaring us that it would also come to Europe but nothing like that happened. When it came to Poland ( . . . ) I was scared that Poland would turn into a second Italy. (MSV##) Students described their feelings of insecurity fear frustration and anger. However while some MSVs worried over the negative impact the pandemic might have on society and the healthcare system most respondents were confused because of not knowing when the crisis would end. They were also frustrated with the restrictions imposed on their personal freedom and were afraid about their future. In particular they were concerned over the social distancing requirements which enforced remote education and disrupted their daily activities. I was mad and furious. My anxiety over the future mixed with anger that my plans could not be realized. I was sad and mad that my study trip to Summer School abroad was cancelled. (MSV#) I was very upset that all the classes were suspended. I thought it was unnecessary and exaggerated. I was mad that they took away my time from clinical classes. (MSV##) Respondents were also afraid over the health of their loved ones including parents and grandparents. As the pandemic progressed all these negative feelings intensified and MSVs expressed concerns over the negative impact of the outbreak on the national economy healthcare system and the health of their families. Interestingly most were not so preoccupied with contracting the virus as they were with the possibility of being asymptomatic carriers and transmitting the virus to others. This was especially the case for those MSVs who were still living with high-risk individuals such as senior family members with co-morbidities. When the pandemic gained momentum I was scared over the health of my loved ones my family. (MSV##) I was more afraid of being a carrier than of being infected. Because of my age and good physical shape I did not feel endangered. I was afraid that I might infect others. (MSV##) During the first wave of the pandemic most MSVs were mainly focused on personal issues and worried about their education and professional futures. After two or three months I started wondering how it would affect my education. I worried that we did not have access to clinical classes and patients and that online lectures and seminars were not enough as we were unable to talk to the patients and examine them. (MSV#) I was afraid that I would not be able to finish my studies. As we have lost almost a year and a half now I was wondering how we could catch up and how we would handle ourselves in the future job. I was afraid that we would have to learn everything in practice at work. It was hard. (MSV##) Some MSVs remained stoical and argued that although the situation was difficult they did not find it particularly disturbing. Moreover some perceived the pandemic as a \"learning opportunity\". I did not experience any special worries. ( . . . ) I thought it was an opportunity for me a chance to gain extra knowledge. (MSV#) To be honest I was not scared nor had any negative feeling about it because I knew that I was not in the group of increased risk. So I tried not to panic. It did not affect me. (MSV##) However there were respondents who reported that due to the pandemic and lockdown inconveniences they experienced serious psychological distress an increased level of anxiety and depressive emotions. After hearing the news about the COVID-## pandemic all MSVs described their need to act and engage in the fight against the outbreak. Although students declared a variety of motives for volunteering for the majority the prime motivator was the belief that studying at medical university was a unique vocation and that as future healthcare professionals it was their duty to engage and help whatever the risks. Thus some recalled the feeling of the 'sublimity of the situation' and a sense of a 'mission' they had which influenced their desire to be a part of 'something ground-breaking'. I had a feeling of duty. Although I do not study medicine or pharmacy I thought that as a public health student I could help. I was thinking 'Who else if not we' at the medical university. (MSV#) It may sound naïve but it was a kind of imperative: you must give something from yourself especially as you have finished medical university. I wanted to do something and not be the observer and commentator. I had the sense of vocation. (MSV#) Because I have chosen my studies to help people and I often wondered what would I do if a war started or something I thought that maybe this was the right time to step up. It was a sense of a mission the feeling of solidarity with the medics and the desire to help the sick. (MSV##) Students who had previous experience with various forms of volunteering described their decision as 'natural' and declared that as full-fledged volunteers they were driven by the ideal of doing good and helping others and wanted to give something back to the community. On the other hand some MSVs were more orientated toward personal goals such as having a personal feeling of satisfaction from helping others the possibility of passing a summer internship or simply believing that volunteering was better than sitting at home and studying or being bored. Some also suggested that volunteering helped them to cope with their psychological stress and emphasized its therapeutic dimension. Because I come from a small town I was tired of sitting at home doing nothing apart from walking around or jogging. I wanted to help and engage in something. (MSV##) It had a therapeutic value because due to the lockdown it was impossible to leave home meet people or travel. It was difficult; so if I did not volunteer it would be an even harder experience especially that I had moments when I felt helpless and very uncertain. My colleague posted a message that we can pass our summer internships as volunteers. I thought it was a good opportunity to observe how management in a state agency functions. I also wanted to escape a bit from my bad mood. (MSV##) Yet others believed that the pandemic was a chance to gain new knowledge and practical skills that could be useful in their future profession. I wanted to be closer to what was going on. I would not gain all that knowledge while sitting at home next to the computer. (MSV#) I thought it was an opportunity: being my age and working during the pandemic. I thought that it may not be the last pandemic and that this experience could benefit me in the future. (MSV#) However most respondents revealed a unique mixture of altruistic and egoistical drives. Thus even though most were orientated towards altruism and public service personal enhancement motivations were equally important as they wanted to learn new skills and gain professional experience. However personal motivations were not the main reason for becoming involved. Because I study at this faculty [rescue medicine-JD] I felt I will say it a bit lofty a moral duty to help. I was also afraid that the healthcare system would not handle it. I believed that even a freshman like me could help. It was also a kind of adventure. Finally I was hoping that as our education switched online I could learn something. (MSV#) At the beginning it was the desire to help but later I was also motivated by the possibility to pass my summer internship. (MSV##) Simultaneously while all students had discussed the decision to volunteer with their parents families partners friends or teachers they declared that it was their personal and autonomous choice. However some suggested that they experienced some forms of external pressure either from their academic teachers fellow students or society. There was a kind of social pressure especially in the media that we should volunteer. There was a kind of pressure even from some professors. For example one professor posted a message on Facebook saying: 'Either you would be with us or not'. (MSV##) Although most MSVs did not have any special expectations related to the voluntary service and often perceived it simply as a 'job' or 'learning opportunity' some mentioned that before starting it they imagined pessimistic scenarios which influenced their feelings of security and safety. I had this image like they showed it on the TV that we would be placed in the military tents at the front of the hospitals which would serve as a kind of 'dying rooms'. I was expecting that I might get infected. I knew I was putting myself at risk. (MSV#) I was thinking that ( . . . ) we would be sent to covid wards where we would be caring for the sick and monitor their life functions. It made me scared. I thought it might be dangerous. (MSV##) Although all students were aware of the risk it was not the fear of being infected that worried them the most. As already mentioned most respondents were more afraid of bringing the virus from the hospital to their homes. Consequently while fearing that they may pose a risk to their loved ones MSVs felt responsibility for others and avoided contact with their relatives or decided not to go back to their family house. Moreover some experienced great anxiety for many months until they were vaccinated. I worried that I might infect somebody. I felt a great responsibility that some persons might be hospitalized because of me. Such worries accompanied me during my entire volunteering. Only when we all got vaccinated I felt secure enough I could visit my family at home. (MSV##) Soon after I made the decision I started to worry and I have felt it for months that I might infect others. My anxiety was intensified by the constant information that young people are mainly carriers. (MSV##) Additionally respondents were afraid that due to their age they lacked the necessary knowledge skills and experience and that they would not be able to perform many tasks. Back then I was studying for only six months so I was worried that my knowledge was vague and that they could assign me things I was not familiar with. (MSV#) I had some worries especially during my first meeting with the patients. I felt uncertain and tentative as I was not sure whether I was qualified to do all those things. I was anxious that I may not be gentle enough or even harm those people who were already suffering. (MSV##) MSVs were also asked about the organization of the COVID-## volunteering. Most respondents argued that the volunteer induction they received was sufficient as they were trained about all the responsibilities procedures and protocols. They also stressed that there was always someone who supported and advised them. Consequently they felt safe secure and prepared for their service. We underwent basic training sessions on occupational hygiene safety procedures and infectious diseases. ( . . . ) I was also trained in the patients' personal data protection. Additionally there were always persons who were watching and helping us. (MSV#) We underwent sanitary-epidemiological training: how to disinfect our hands and the workplace wear masks and uniforms. We also knew exactly what to do during our volunteering; and someone was always helping us. I felt very safe and secure. (MSV##) However some respondents complained about not being prepared properly for their functions. While some argued that their training was too short others claimed that they did not receive training or information whatsoever and said that students desperately lacked information on their responsibilities. Thus some argued that they owed their preparation to their previous volunteering or to colleagues who explained everything to them. To be honest I felt like being thrown into deep water without proper preparation. In fact on the evening before I started someone called me and asked whether I could come the next day. However I did not receive any type of training regarding safety or communication. I simply joined a nurse and was learning from her. (MSV##) We barely had any training and it was my colleagues who showed me everything. (MSV#). Although the majority of students declared that their personal safety and protection were taken care of some complained that at the initial stage of the pandemic they had limited access to PPE. Simultaneously they were aware that the primary reason for this was the shortages of PPE experienced in most of the countries struggling with COVID-##. It was well organized. I felt safe and secure. We were provided with the PPE although at the beginning there were some problems as there were only reusable masks. Later they gave us also FFP#s and FFP#s. (MSV#) At the beginning we did not have much protective equipment there were very few masks or disinfectant liquid but as it [the pandemic-JD] developed we were given the visors and dispensable aprons and after a month it was much safer. (MSV#) Nevertheless MSVs complained that volunteers' well-being was not cared for enough as they did not have access to psychological support especially during the first months when many students experienced stress and emotional burden caused both by the pandemic and the volunteering itself. Respondents missed institutional support and the possibility of debriefing. Some suggested that it was the volunteers who supported each other. Although everyone was very supportive in technical issues we did not have any psychological or emotional support. I missed the possibility of debriefing and having a chance to share my experiences anxieties and worries. (MSV#) We did not have any type of institutional support and some persons needed such psychological help especially those who volunteered at the beginning as it was a hard and stressful work. After eight ten hours on a duty we experienced a psychological and emotional burden. (MSV##) Finally students gave their opinions on the motivational system which aimed to encourage students' volunteering during the pandemic. Although most MSVs stressed being motivated by a strong sense of altruism and public service some admitted that gaining a credit for a compulsory internship was an additional motivator. However many suggested that it had negatively influenced the quality of volunteers who were driven more by egoistic drives. Moreover MSVs complained that as a result volunteering \"lost its spirit\". Additionally some complained that the knowledge and skills acquired during volunteering were not compatible with those required by the program. There were also students who felt as if they were being used and stressed that volunteers should receive regular pay. I see how it has changed. Now when students include volunteering as part of their practice their motivations are much different than it used to be when it all began. It has lost its spirit. Back then we were all excited that we were taking part in it but later many students lacked that commitment. They simply wanted to pass their summer internships. They became more mercenary. (MSV#) Because we do a normal job I think that students could be offered a regular contract. (MSV#) Simultaneously none of the respondents regretted their decision to join the fight with the pandemic and stressed that the university had made a good decision to call upon students to volunteer. MSVs felt satisfied that during the difficult situation experienced by the Polish healthcare system they were able to help and relieve the system. Others stressed that it was a kind of a \"test\" and a chance to prove oneself as future health professionals. I think it was a good decision especially at the beginning when the numbers were skyrocketing. There was a staff shortage and the system needed us. (MSV##) I think it was a good decision because we are preparing ourselves for a profession which is a kind of sacrifice and it was a chance to prove oneself. (MSV##) Even though most MSVs were not involved in any direct patient care activities all respondents considered their work as useful and believed that it was an important part of their medical education. Moreover regardless of their age gender faculty initial level of fear the time of recruitment or time spent on volunteering all MSVs expressed a high level of satisfaction from volunteering and stressed the countless benefits that arose from it. Although for some it was a chance to leave home spend their time in a useful way make new friends or pass a summer internship most respondents emphasized that volunteering made them feel needed and useful and made them sure that they had chosen the right studies. Now I see clearly that these studies have a purpose. Volunteering made me realize how great it is to work for such a great cause. It also helped me to develop self-confidence. (MSV#) The most satisfying was that I had the feeling that I did not waste that time. I was useful and I was doing something important. I was not passive. (MSV#) Simultaneously although value-based gratifications were highlighted some MSVs stressed how volunteering had affected their psychological development and personal growth. I could test myself as I did not know how would I react in such a critical situation whether I would go to the front line. Now I know I will so I have proved this to myself. (MSV##) I felt great satisfaction each time I managed to do something I have learnt during the classes. It was very satisfying when the personnel called for help as they already knew that I could do something and they were treating me as a member of their team. (MSV#) Additionally MSVs emphasized that as medical schools were closed and classes were held online volunteering created an educational opportunity for learning new things improving clinical and social skills and gaining professional experience. It gave me a lot of practical knowledge and skills. I also developed many soft skills. I learnt how to communicate with people. I was able to work in a team under pressure and to cope with difficult situations. (MSV#) I have learnt more than I would during regular classes. On the intensive care unit I was allowed to assist in some procedures that otherwise I could observe only after specialization. I also performed some procedures done typically by physicians I would never do these as a nurse. (MSV##) It helped me to develop compassion for the sick and dying patients and improved my communication skills. Now when we are on the ward during the classes I find it much easier to deal with toilet issues wash the patient or change their diaper. (MSV##) Finally volunteering was a chance for interprofessional collaboration which helped MSVs to understand the peculiarities of other medical professions. Working with students from other faculties helped them \"leave their own boxes\" \"see them from the outside\" and appreciate the knowledge and skills of other healthcare professionals. This in turn strengthened the \"professional integration\" and \"sense of cohesion\". Some also acknowledged that volunteering made them realize how the system works in critical situations. Simultaneously MSVs admitted that volunteering during the pandemic was a source of serious burden. However although all respondents were afraid of being infected and bringing the virus to their homes it was especially students who worked with patients either in hospitals emergency units or sanitary-epidemiological stations who complained about the high pressure and stress they were dealing with and stressed the emotional strain and \"moral injury\" which made them physically and emotionally exhausted. Especially that psychological burden feelings of helplessness guilt and frustration were coupled with the absence of psychological support. The hardest thing was conversations. Sometimes it was difficult to forget about them. I kept them in my head and I often thought that I should have said something else or differently. ( . . . ) I remember one conversation with a mother of a teenage girl who struggled with self-destructive behaviours: scarification the 'S thoughts' overdosing paracetamol [silence] . This was the worst call. I was shaken emotionally and I reminiscenced about it for a long time and had flashbacks [silence]. After such calls I needed a day or two off to go through it. (MSV#) The most difficult were conversations with the patients. Sometimes I felt helpless as no one knew back then what to do how to respond to questions . . . We were so confused. (MSV##) Sometimes I felt irritated because there were so many patients and due to staff shortages they were not cared for enough. It was very frustrating because I often could not devote them more time and answer all their questions. I often left the zone embittered irritated and felt sorry for the patients. (MSV#) Although all MSVs claimed that the tasks performed during their service were adjusted to their qualifications many complained over a lack of social skills and stressed how unprepared they felt for dealing with offensive or aggressive patients. Moreover while complaining about the lack of a protocol on how to deal with such situations students stressed how difficult and emotionally challenging it was to talk to patients. Especially during the first month patients were very against us. They associated us with restrictions in entering hospital and called us many bad words. We faced many negative emotions especially when they gathered together were tired and did not understand why we let some persons in and others not. Frequently we met with insults. (MSV##) Although during the first year we had some humanities pedagogy or psychology the studies did not prepare me for that: meeting people face-to-face when they were often mad or aggressive while waiting for such a long time at the front of the hospital. Sometimes it was a bit dangerous. (MSV##) Some MSVs felt unappreciated or suggested that students could have been used better. Especially medical students and those in their final years stressed that they could have performed more demanding tasks so they could relieve the staff. Some of us could have been used better. Being a PhD student myself I graduated from biotechnology and I am familiar with all those laboratory things like isolation and PCR. I would be more useful in the COVID Lab. (MSV#) I still have this feeling that we were not being used properly. There were hundreds of volunteers but they did not recognize properly our potential and did not used us properly. People were very eager to work but our potential was wasted. (MSV##) Among other burdens MSVs stressed that constant performing of the same simple tasks was monotonous and boring. Others found it difficult to reconcile volunteering and studying. Some also admitted that volunteering had a negative impact on their social relations. My family was very supportive and proud. However my extended family was like: 'Why do you need it' 'Give it a break'. They were telling me I risk a lot and that I put relatives at risk. They discouraged me. But it was only at the beginning. Later they were proud and supportive. (MSV#) My entire family was against it. My parents were afraid and they tried to discourage me. Now they are proud and I have become a 'family star'. (MSV#) Some students mentioned positive reactions from the university authorities who acknowledged the importance of their service. On the University's web page I saw videos describing our work. It stressed that not only professionals work in the laboratory but also the volunteers. I saw their gratitude. I felt appreciated and it made me very happy. (MSV##) A dean came to us several times to see how we work and to show his appreciation. We even received an email from the hospital's director who acknowledged our work. (MSV##) Moreover the healthcare professionals also appreciated the students' help showing their support and respect. Others recalled the gratitude expressed by patients and their families. Healthcare professionals were very supportive and they often expressed their gratitude and told us how they appreciate our presence and help.They often called us 'heroes'. (MSV#) Medical personnel appreciated us a lot. They were very thankful and stressed that thanks to us those who worked at the front line were much safer. Nurses and receptionists were calling us 'our angels'. (MSV##) Although similar positive reactions were expressed by students who did not volunteer it was the peers including university colleagues who were often sceptical about the whole idea of students' volunteering. Thus although some respondents were admired by their friends most MSV suggested that peers' reactions were often negative and discouraging: some believed that volunteering was irresponsible as they might pose a risk to others while others argued that volunteers were being used as a cheap workforce. Consequently MSVs complained about the hate on the Internet and did not understand why some medical students were so aggressive about it. My friends from the university who did not know that I had volunteered were saying it was for the idiots; that one might get infected that there was no equipment one would not get paid and that it was not worth it as they would not let us do anything important. (MSV#) My colleagues tried to discourage me and said I should not do it; and on Facebook 'the swamp' spilled. I saw the discussion on the web saying that they were trying to use us as a cheap workforce. They were mad at the University that it asked us to volunteer. It really irritated me. I could not understand their need to comment on my decision and being so negative and aggressive about it. (MSV#) For some students volunteering was a source of discriminatory behaviours including social exclusion within the student community from teachers or neighbours. Even though they perceived such prejudices as \"small things\" still they felt stigmatized marginalized and discriminated against. They stressed that being perceived as an 'infection risk' and a threat rather than as individuals who were offering their service to society made them feel sad and disappointed. Once when I returned to my apartment after a twelve or eighteen hours of service I found a note stuck in the door saying that my neighbours were asking me to leave my apartment immediately because I was a possible 'source of the plague'. I felt bitterness and disbelief. In the summer time when I was wondering whether I should come to a party some friends told me 'No no you do not have to come. We know you are at work you know'. It was such small things. Also some teachers at another university where I also study who knew about it were afraid of letting me into the classes. (MSV##) The COVID-## pandemic has resulted in the increased demand for healthcare workers worldwide. A similar situation occurred in Poland which for years has had difficulty in retaining its health professionals and struggles with an inadequate number of practicing physicians or nurses. Consequently the question of whether students' involvement in the pandemic should be allowed or restricted provoked heated debate [# # [#] [#] [#] [#] ## [##] [##] [##] [##] [##] [##] [##] [##] [##] [##] . However this has left many students disappointed and frustrated because they felt prepared and were eager to contribute to the patient care [## ##] . They argued that students have clinical knowledge and valuable skills that can be appropriately used to help physicians nurses administrative staff and patients. Moreover it was also suggested that students did not have to work on the frontlines caring for patients but could perform non-COVID-## related tasks such as supporting healthcare professionals in providing patient care in emergency rooms and hospital wards interviewing patients caring for outpatients through telemedicine helping in administrative matters calling patients with lab results sewing protective masks or providing childcare for healthcare workers [# ## ## ## [##] [##] [##] . This was important because while those tasks did not pose a high risk of COVID-## transmission they helped to relieve the healthcare system. Interestingly although previous studies in the United States [# ## ##] the United Kingdom [## ##] Ireland [##] Denmark [## ##] Germany [##] Nigeria [##] Saudi Arabia [##] China [##] Vietnam [##] and Indonesia [##] reported high rates of willingness to volunteer among medical students such willingness was not always followed by students' readiness to practice [## ##] . Meanwhile this study confirms findings from previous Polish studies [##] [##] [##] [##] that suggest that the majority of students across various faculties and years expressed a strong interest in active participation during the current healthcare emergency. Additionally it shows that volunteers were mainly motivated by a strong sense of altruism [# # ## ##] and had felt a moral and professional responsibility to help during the pandemic [## ## ##] . For example Danish medical students were primarily motivated by the desire to help and wanted to take pride in contributing [##] and Saudi students were driven by patriotism and moral values [##] . Similarly while for many Polish medical students' personal enhancement and growth or the desire to develop personal career were important motivators the vast majority volunteered out of a sense of civic responsibility and were mainly driven by altruism and the ethical imperative to serve their community their fellow healthcare professionals and their patients [##] [##] [##] [##] . Indeed most respondents emphasized the humanitarian nature of medicine and referred to such values as altruism courage and a sense of duty. Thus although the primary role of the volunteering was to relieve the healthcare system it also reinforced such important medical values as altruism public service and professional solidarity. Consequently this study shows that students' commitment during the COVID-## pandemic was a great example of active citizenship and civic responsibility: volunteering helped to cultivate a spirit of benevolence among these future healthcare professionals and was a chance to engage in positive behaviour [##] . Significantly although students consulted their decision to engage in the fight against the pandemic with their teachers families or friends none of the respondents indicated the 'family' or 'colleague effect'. On the contrary they all declared it was their personal and autonomous choice. Interestingly students pointed to various benefits stemming from volunteering which included the normative ones (being useful for the community participating in something important fulfilling the civic duty public service and helping others) personal enhancement (psychological development and personal growth realization of one's passion or having a sense of pride) career (learning new knowledge and skills building and developing personal career gaining professional experience making useful contacts interprofessional collaboration or obtaining the academic credit) and social (new relationships with others making new friends working with other people and respect from others). However most respondents suggested that the pandemic was a unique teaching moment and active involvement in volunteering created new learning opportunities especially in the field of competency-based medical education and project problem-based learning [## ## [##] [##] [##] [##] . Indeed in addition to altruistic and value-driven motivations most participants recognized that the pandemic gave them a chance to gain new knowledge and improve their social organisational and stress management skills and helped them to understand how the health system works as a multidisciplinary whole [##] . Moreover working together with students from various faculties was also a lesson for future interprofessional collaboration [##] . Thus although Cullum et al. [##] suggested that the suspension of clinical placements during the pandemic may negatively influence the development of professional identity among medical students this study supports the arguments of Findyartini et al. [##] that allowing students to play an active role during the outbreak contributed positively to the formation and internalization of their professional identity. Many respondents admitted that volunteering made them realize that although they were still students they were already thinking feeling and acting as healthcare professionals. Consequently they felt that by making a contribution to patient care they have become part of a of healthcare team. Simultaneously in accord with Kalet et al. [##] this study suggests that while students' engagement was voluntary many experienced various forms of external pressure or a sense of coercion from their academic teachers fellow students or society. Even though such pressure was mainly present at the beginning of the pandemic Shibu [##] showed that also during the second wave when students had returned to university they often felt obliged to continue their volunteering due to either internal motivation or the external pressures of the healthcare environment. What is also important is that most respondents experienced a mix of an obligation to join in the fight against the COVID-## pandemic and fear [## ## ## ##] . Interestingly students mainly expressed fear over the possibility of transmitting the infection to others in their homes and worried that the pandemic might negatively affect their studies or that the healthcare system might collapse [## ## ## ## ##] . Moreover in accord with the observation made by Bazan et al. [##] while the highest level of students' fear was observed during the first wave of the pandemic when the recruitment process begun it decreased over the course of volunteering. At the same time although gender age or the faculty did not affect MSV's responses female students were more willing to volunteer for altruistic reasons as compared to male counterparts. On the other hand they were more prone to develop anxiety and stress and were more affected by the fear of spreading the infection to others. Another important finding is that the major concern regarding volunteering was related to perceived insufficient medical knowledge and skills [##] . Especially younger students felt insecure and were concerned over not being prepared for dealing with the pandemic. Simultaneously most students lacked social skills-so important in dealing with offensive or aggressive behavior. Consequently MSVs complained about the lack of university courses on interpersonal communication especially in crisis situations. What is also worrying is that although most MSVs expressed generally positive opinions on the organization of volunteering many still complained over the lack of access to psychological support and suggested that they were not cared for enough at the emotional level [## ##] . However Spanish students also complained about not having received specific training or psychological support [##] . Finally it was also alarming that there were students who reported being the target of stigmatization prejudice and discriminatory behavior related to volunteering [##] . Although respondents emphasized that their involvement in voluntary service during the pandemic had received positive feedback they mentioned that many students who did not volunteer felt they were being exploited as a free workforce. Moreover although all participants emphasized the voluntary character of their service some suggested that as it lasted over time and the jobs they performed were ordinarily waged they should be drafted a formal employment contract and have regular payment. Similar concerns were found among Danish students who believed that for many receiving a salary would be an important additional motivational factor [##] . Similarly while ##.#% of Nigerian nursing students suggested that the monetary reward would be a good motivation [##] more than half of British respondents believed that they should be offered a formal contract of employment and legal protection whilst working in a clinical capacity [##] . This study has some limitations. First only twenty-one MSVs were interviewed. However despite the small sample thematic saturation was achieved. Second the study has a local dimension as only responses from one Polish medical university were analysed. Consequently it would be desirable to compare the findings from other locations in the country. Third because five students resigned the results represent solely the opinions of those MSVs who agreed to participate in the study and cannot be generalised for the entire population of MSVs either in Poznan or in Poland as a whole. Fourth there was a predominance of female participants (F:M ##:#) which limits the results' transferability to male students although this imbalance is representative of the female predominance within the medical studies in Poland. Finally as the analysis was performed by one author alone there was a higher risk of subjectivity that might have influenced both the choice of the themes and the interpretation of the data. However despite these limitations some advantages of this study should also be acknowledged. Most importantly as there is a scarcity of previous work on the topic this research fills the gap in the literature regarding the experiences of MSVs facing the COVID-## pandemic in Poland. Indeed while previous studies discussed students' attitudes motivations or willingness to volunteer to the best of my knowledge this is the first study that explores students' lived experiences during the COVID-## pandemic in Poland. Additionally while previous studies often focused on medical students this research highlights the experiences of students from various faculties enrolled in an interprofessional project. Moreover it describes the experiences of not only final year students but also those in their early years of training who are typically not immersed in clinical settings. Thus while emphasizing the role of students during the current health crisis this study provides new insights into how individualized the students' response to COVID-## was. Finally it enabled the MSVs to share their experiences which might have a therapeutic value. This study suggests that although medical students' involvement in volunteering during the COVID-## pandemic was intended to prevent shortages of healthcare workers and relieve the system before it reached a personnel crisis it was also a self-satisfying and careerrelated experience. Although being committed gave students the feeling of taking part in the fight against the pandemic MSVs emphasized that in times when medical universities were closed and classes were held online students' volunteering became an important part of the service learning and created an opportunity for education. Thus while it benefited students patients and the healthcare system students' involvement reinforced such important values of medical ethos as: altruism public service and (professional) solidarity. However although this research confirms the view that medical students are willing to contribute in the response to health disasters and emergencies and that their involvement helped to relieve the healthcare system it also shows that in order to promote the idea of students volunteering improve the healthcare's organization enhance the students' safety and better prepare them for next health crisis some systemic approaches should be undertaken: To ensure that medical students can effectively volunteer in future disasters policymakers and university authorities should not overlook the potential force of medical students as a support to the health system; #. There is an urgent need for promoting the idea of volunteering among all medical students; #. Students' participation should always be voluntary and free of any type of external formal or informal pressure; Students volunteering should be treated as a way of supporting the student learning process and incorporated into university curricula; #. Medical universities should integrate global health and disaster medicine to the medical curricula; #. There is a need for special preparation courses that would improve students' communication skills and handling of difficult situations; #. Dedicated university courses on emergency decision making coping and leadership during a crisis should be integrated into the medical curricula; #. To minimize the risk of litigation students should always receive proper induction and be trained about their responsibilities procedures and protocols; #. All tasks performed by MSVs should be safe adjusted to their capabilities and level of training and performed under supervision and institutional medico-legal protection; ##. When engaging MSVs special attention should be paid to the risks of infecting the patients and students as well as to the PPE shortages; ##. Because MSVs may perform some tasks remotely telemedicine should be further developed; ##. Because volunteering during the pandemic was physically and emotionally challenging MSVs must be provided with mental health support in physically or emotionally challenging roles. The following supporting information can be downloaded at: https: // Supplementary S#: Interview Questionnaire. Funding: This research did not receive any specific grant from funding agencies in the public commercial or not-for-profit sectors. The study was performed in line with the principles of the Declaration of Helsinki. In accordance with Polish law and Good Clinical Practice ethical approval was obtained from the Poznan University of Medical Sciences Bioethics Committee (KB-###/##). Because of the sensitive nature of the topic and potential disclosures of moral injury caused by the pandemic the voluntary nature of the study was emphasized and participants were informed about the possibility to quit the interview at any given moment and not reveal information on their personal circumstances. Voluntary informed consent was obtained from all participants included in the study. The data and codes that produce the findings reported in this article are available from the corresponding author on reasonable request.\n",
            "response:  OBJECTIVE: The COVID-## pandemic resulted in the closure of hospitals and medical universities that seemed to disrupt society. In Poland university student volunteers’ (MSV) perspectives were explored by conducting an online survey with ### students from several countries including Poland for their experience during these two periods.\n",
            "summarize: The emergence of COVID-## pandemic [# #] in December #### caused by the severe acute respiratory syndrome coronavirus # [SARS-CoV-#] [# #] has imposed severe social and economic burden in countries across the globe. Initially this viral infection was diagnosed to cause severe acute respiratory syndrome (SARS) in humans [#] and later reports revealed the susceptability of cats and ferrets also to have acquired COVID-## infection. [# #] . It is believed that the viral spread is not air/water borne or through insects/animals. It has spread to many countries round the globe mainly through societal interactions including transmission from human-to-human through droplets contaminated hand or surface contacts. Now there has been a daunting task for the scientists to not only control the morbidity but also the steeply raising mortality [#] . Though the mode of infection by SARS-CoV-# is known to be very similar to SARS-CoV [# ##] there exists the challenge of controlling the rate of infection and rapid treatment methods for the infected patients [## ##] . Till date no antiviral drugs with proven efficacy nor are there vaccines for its prevention. Several clinically available antiviral drugs are reported in the literature and have been in use to suppress different viral particles [## ##] . For the past ##-## years researchers are working on the development of antiviral drugs for SARS-CoV and MERS-CoV [## ##] and till date no successful results appear. Now SARS-CoV-# is added to the list. Detailed investigations on various phytoconstituents of Tinospora cordifolia as potent drugs targeting the main protease (Mpro) of the virus was carried out recently [##] . The present focus of investigations resides on two other potential targets: #. Virus (Receptor binding motifs-spike (S) envelope (E) and nucleocapsid (N) proteins RNA dependent RNA polymerases and #. Receptor motif on human ACE# (angiotensin converting enzyme) and its associated functional proteins like TMPRSS# and B # AT#. It is difficult to have a complete evaluation of small molecular drug candidates for therapies directed towards the host with the inadequately available knowledge on the molecular details of the infection caused by SARS-CoV-# [## ##] . Recently several research works have been published with novel and refurbished drug candidates to tackle the situation [##] . Until recently there was a speculation that hydroxychloroquine could inhibit the viral infection [##] . But there was no solid proof on the method of inhibition. With the current status on the spread of infection it is mandatory on emergency basis to develop strategies to control the morbidity and mortality. A systematic understanding on the host dependencies of the SARS-CoV-# virus to identify other host proteins is the need of the hour. Many therapeutic strategies target the host-virus interface but such drugs are prone to induced severe side effects [##] . It is very unfortunate that we have very minimal knowledge on the molecular details of SARS-CoV-# infection to further proceed with a comprehensive evaluation of small molecular therapeutic candidates directed towards the host. Several mathematical models [## ##] and computational strategies [##] are being currently under investigation to identify the interactions at the interface. Moreover to devise therapeutic strategies it is important to know how the virus invades the humans during infection and this knowledge can be applied to develop new drugs and to repurpose the existing ones [##] . There are also reports on various constituents from plants [##] of medicinal values as potential inhibitors and anti-viral drugs [##] [##] [##] . Recently Government of India has released an advisory from the ministry of Ayurveda to meet the challenges caused by the rapid spread of COVID-## in India [##] . The major focus of this system was to bring lifestyle modifications and prophylactics to improve the immunity in humans. In this context it was reported that an ayurvedic medicine Samshamani Vati (aqueous extract of Tinospora cordifolia) when administered at ### mg twice a day for ## days could serve as prophylaxis [##] . The same is also reported to induce immunomodulatory effect [##] [##] [##] in human immuno-deficiency virus positive patients. [##] The various constituents of Tinospora cordifolia are known to exhibit a broad spectrum of therapeutic activities including anticancer antimicrobial antitoxic antidiabetic hypolipidermic wound healing immunomodulation etc. and ## different constituents (or chemical compounds) of Tinospora cordifolia were reported in literature [##] . It belongs to the family of Menispermaceae and is known for the pharmacological activities exhibited by the chemical constituents like glycosides terpenoids alkaloids essential oils fatty acids etc. present in different parts of the plant like root and stem. The plant possesses various medicinal properties [##] like anti-diabetic anti-allergic anti-stress anti-leprotic anti-malarial anti-neoplastic hepatoprotective immunomodulatory etc. With the available scientific approaches and computational facilities to model proteins and investigate proteinligand interactions it becomes more supportive to predict the binding of small molecular drugs to protein targets [## ## ##] . Employing density functional theory [##] the geometry of all the molecules proposed as COVID-## drug candidates were optimized to understand structural features and hence their contribution to the inhibition or druggable potential. For the first time in literature herein we are reporting the inhibitory effects of selected constituents of Tinospora cordifolia on human ACE# protein and the main protease of SARS-CoV-# using molecular docking and pharmacokinetic studies. In this manuscript we have investigated the various constituents of Tinospora cordifolia for their potency to inhibit the host receptor for SARS-CoV-# by molecular docking interactions. The X-ray structure were obtained from Brookhaven Protein Data Bank for SARS coronavirus spike receptorbinding domain complexed with its receptor (PDB id: #AJF) and the main protease of COVID-## in complex with an inhibitor (PDB ID: #LU#) and were considered for docking studies. The protein structure coordinates for docking were obtained from the above by removing the bound receptors inhibitors water molecules and other hetero atoms. Further using AutoDockTools-#.#.# the Kollman charges [##] were assigned to the proteins after adding the hydrogen atoms. Employing molecular mechanics the #D coordinates of the proposed inhibitors were constructed and optimized. Auto Tors was used to define the possible torsions associated with the inhibitors. All the inhibitors were treated as flexible throughout the docking procedures. The already reported binding pocket in the proteins was used to generate a grid box to encapsulate the active site. The auto grid program was used to pre-calculate the grid maps of interaction energies between protein and various atom types present in the inhibitors. The conformational states of the flexible inhibitors were explored using Lamarckian genetic algorithm coupled with energy assessments based on AMBER force field. Docking calculations were performed with default parameters. The binding energy was evaluated using the following scoring function. The free energy upon binding of the flexible ligand to the rigid target could be calculated using the equation that includes parameters like DG vdw (dispersion/repulsion) DG elec (electrostatic interaction) DG hbond (hydrogen bonding) DG tor (torsional constraints) and DG sol (desolvation effects). The #-dimensional interactions were generated using the visualizer associated with AutoDockTools-#.#.# while the #-dimensional interactions were generated using BIOVIA Discovery Studio visualizer (Figs. # # and ESI Fig. # ). The pharmaco-kinetic properties such as absorption distribution metabolism excretion and toxicity (ADMET) were predicted using the pkCSM/ADMET [## ##] . This method employs graph-based signatures to develop predictive models for generating central ADMET properties for drug development. In absorption process the drug reaches the blood stream from the site of the drug administration. The absorption of drugs depends on factors including polar surface area (PSA) membrane permeability (LogP) cell-based methods such as Caco-# intestinal absorption skin permeability levels P-glycoprotein substrate or inhibitor. This approach uses various parameters such as the blood-brain barrier (logBB) CNS permeability (logPB) and the volume of distribution (VDss) are evaluating the distribution of drugs. Using CYP models for substrate (CYP#D# CYP#A# CYP#C## CYP#C# and CYP#A#) the metabolisms of the drug molecules are evaluated. Excretion a process where the body eliminates an unchanged drug or its metabolite is predicted based on the total clearance model and renal OCT# substrate. The toxicity of drugs is predicted based on AMES toxicity hERG inhibition hepatotoxicity and skin sensitization [## ##] . The PSA value relates the absorption properties of the inhibitor drugs. The PSA value of compounds greater than ### indicates that the compounds have strong polarity and were poorly absorbed. The lipophilicity values are predicted by the LogP value. The LogP values less than # shows that the compound can easily permeable into cell membrane. Apart from these two parameters PSA and Log P the following parameters such as Caco-# permeability intestinal absorption (human) skin permeability and P-glycoprotein substrate or inhibitor were used to predict the absorption properties of the compounds. When the compounds exhibit the predicted value of [ #.## indicated that the compound has high Caco-# permeability and easily absorbed. The intestinal absorption (human) less than ##% is considered as poor absorption. The logKp value of greater than -#.# is considered as poor skin permeability. The permeability glycoprotein (P-glycoprotein) also known as multidrug resistant protein or ATP binding Cassette (ABC) is an important protein in the cell membrane that eliminates the toxins and foreign substances from the cells. After the drug is absorbed from the membrane the drug should be distributed to various tissues in the body to produce the pharmacological effects. The distribution volume (VDss) is a parameter which predicts the distribution of drugs in various tissues in the body. When the log VDss\\-#.## is considered as low distribution and higher than [ #.## is considered as high distribution. After the drug absorbed in the body the circulating drug exist in either bound or unbound state with the serum proteins in the blood. The efficacy of the drug may be affected by the fraction of drug binds with proteins within blood; the more bound state leads to poor efficacy. The blood brain barriers (BBB) protect the brain from exogenous compounds and selectively transport various nutrients ions and other molecules that are crucial for neural functions. The BBB parameter is the important factor which is measured in vivo in animal models as logBB. The logBB value greater than #.# shows that the compounds can easily cross the BBB and logBB \\ -# suggest that the compounds cannot easily cross the BBB. Compounds with logPB [ -# are considered to penetrate the CNS and logPB \\ -# are considered unable to penetrate the CNS. The central nervous system (CNS) permeability is obtained by direct measurement of blood-brain permeability-surface area product. The CNS permeability between -# to -# is considered as penetrable to CNS. Cytochrome P###s plays important role in drug metabolism. Cytochrome P###s are classified into several groups depends on their biological functions. The major cytochromes subtypes involved in the drug metabolism are CYP#D# and CYP#A#. The amount of the drug that is eliminated from the body is predicted by the total clearance. Tinospora cordifolia also known as Guduchi or Amrita is a medicinal plant possessing various therapeutic properties like jaundice rheumatism urinary tract infections dermal diseases anemia inflammation diabetes etc. The constituents of this plant is known to support the immune system by increasing the body's resistance to infections and also to support the structure function and levels of white blood cells. The observed pharmacological properties [## ## [##] [##] [##] of this plant is due to the presence of various constituents like alkaloids steroids terpenoids Scheme # Chemical constituents of Tinospora cordifolia Scheme # continued Computationally approached inhibition potential… fatty acid mixtures polysaccharides etc. It is also reported that the extract of Tinospora cordifolia possesses broadspectrum antiviral [##] and protease inhibitors [##] . Based on all the above pharmacological significance of these plant constituents here in we have tried to investigate the interactions of various constituents with human host receptors for SARS-CoV-# ACE# [##] [##] [##] and main protease [##] [##] [##] by molecular docking [##] . The extract of Tinospora cordifolia consists of constituents that belong to different classes including alkaloids steroids terpenoids lignans glycosides polysaccharides aliphatic compounds etc. [##] . The major and active chemical constituents along with their chemical structure are shown in Scheme #. Structures #a-g belong to alkaloids #a-b are lignans #a-e are steroids #a-n are terpenoids and #a-c belong to other categories. Most of these molecules are optically active and their stereochemistry plays a major role in their pharmacological properties. It is known that enantiomeric drugs possess different pharmacological properties. Recently many natural products [## ##] and refurbished drugs are reported in the literature as possible drug candidates for COVID-##. The broad spectrum therapeutic significance of Tinospora cordifolia has paved way for their investigation as potent inhibitors for SARS-CoV-#. To the best of our knowledge till date there are no results related to SARS-CoV-# inhibition through theoretical and experimental studies of compounds in Tinospora cordifolia. Herein we have chosen two targets to study the interaction of the constituents of Tinospora cordifolia: angiotensin converting enzyme (ACE#) an integral membrane glycoprotein which serves as the human receptor for SARS-CoV-# and the main protease (M pro ) which is involves in processing the polyprotein that is translated from viral RNA. With the above two targets we have carried out the molecular docking studies with ## different constituents of Tinospora cordifolia. The results (ESI Table # ) indicate that #a #a #a-b and #a-e exhibit strong interaction while #b-f #b #c-d and #f-n exhibit moderate interaction with #AJF [##] (human ACE# protein). In order to narrow down the molecules that contribute significantly towards destabilizing the binding interactions are only considered and are listed in Table # . The inhibitory effect on #LU# [##] (main protease) as evaluated from various interaction energy parameters (ESI Table # ) indicate that #a and #a interact strongly while #a-b and #b-e show moderate inhibition. The strong binding of proposed candidates to the active site of the enzyme leads to activity inhibition. The corresponding interacting residues with #AJF and #LU# are given in ESI Table # and ESI table # respectively. The interacting resides from the binding pocket of #AJF with various constituents are given in (ESI Table # ). The dominantly interacting compounds with #AJF are depicted in Fig. # . The interaction parameters of selected compounds from the extract of Tinospora cordifolia with the main protease (#LU#) of SARS-CoV-# are given Table # along with the interacting residues (ESI tables # & #) . Unlike the interactions with human ACE# compounds #b and #f were found to exhibit strong interaction while moderate interactions were observed in the cases of #a #d #a #b #e and # h. No significant interactions were observed with alkaloid class of compounds as such. The interacting residues are tabulated in (ESI table # ) and the significant inhibitory interactions from the selected compounds are depicted in Fig. # . Absorption distribution metabolism excretion and toxicity studies [##] [##] [##] The pharmacokinetic [##] parameters play important role in drug discovery process [##] . The predicted ADME/T properties are given in ESI table #. It could be observed that compounds #a #c and #d are poorly absorbed due to their high polar nature though they have high potential to penetrate the cell membrane. The absorption properties of the alkaloids are listed in ESI table #. The listed alkaloids show high distribution expect for # g. All the listed alkaloids possess the ability to penetrate through the CNS except #c. All alkaloids can be easily cleared from the system except #b. The toxicology prediction shows that all alkaloids exhibit hepatotoxicity except #a #e and #f while #e exhibits cardiotoxicity. The predicted ADME/T properties of lignans and steroids are given in ESI table # . The results indicate that lignans possess better absorption ability than steroids. Among the lignans and steroids only #b shows high distribution potential. The compounds #a and #d can easily penetrate through the CNS. #a #b and #d show moderate levels for excretion. The compounds #a #b #a #b exhibit cardiotoxicity whereas hepatotoxicity is observed only for #b and #d. The predicted ADME/T properties of terpenoids are given in ESI table #. The results indicate that all terpenoids except #a #b and #n are highly polar and show poor absorption. The compounds #a and #b possess the ability to cross blood brain barrier while all terpenoids exhibit similar tendency to permeate CNS. Except #f all the terpenoids can be easily excreted from the body. # g #j and # k show hepatotoxicity. The predicted ADME/T properties of other constituents are given in ESI table #. Compound #a exhibits very good absorption and membrane permeation. #b and #c possess the ability to cross the BBB easily while compound #a can penetrate the CNS. #a induces hepatotoxicity while compounds #b and #c are cardiotoxic. The predicted ADME/T properties of selected compounds are listed in Table # . The results of molecular docking and pharmacokinetic analyses for the interactions with human receptor protein ACE# have revealed that among the selected candidates Table # the major destabilizing contribution is from the torsional energy arising from the presence of freely rotating single bonds. This could be the reason for # g to have very poor interaction among the alkaloids. The same can be extended for the case of lignans and steroids (#a and #a-b respectively) to have comparatively stronger affinity for the considered active site than #b and #c-d respectively. In case of terpenoids #a-d binds strongly to the active site than the moderately binding #e-g. It could be observed from Table # and ESI Table # that the major interacting residues are non-polar in nature. In the case of #d the stabilization caused by non-polar interactions is nullified by the high torsional energy of the molecule. Though there is a negligible difference in the intermolecular energy for all the above preferred molecules the moderately binding ones have high torsional energy which reduces their target interaction while the imparted stability has its major contribution from hydrogen bond interactions and van der Waals interactions. #b-c bind weakly to the target #AJF as the intermolecular stabilizing energy is neutralized by the high torsional energies. In the case of interactions with viral main protease (M pro ) the results of molecular docking and pharmacokinetic analyses have revealed that the stabilizing interactions have its contribution from polar and acidic amino acids along with non-polar interactions. In compound #f though the torsional energy is very high the stabilizing effect is observed from the low internal energy of the molecule as shown in Table # and ESI table # . The docking results have revealed that compounds #a #e #b #a #c-e #d-g #i #k-n #b and #c possess the ability to bind to the proposed targets #AJF and #LU#. Some of the above candidates have poor binding affinities by the fact that these molecules exhibit very high torsional energies that could potentially destabilize the interactions with target residues. But still their candidacy is considered as these molecules could serve as lead compounds to engineering molecules with reduced torsions. The pharmacokinetic analyses revealed that among the alkaloids (ESI table #) the polar surface area of #b #e #f and #g were less than ### and have high potential to get absorbed while in the case of lignans (ESI table #) both #a and #b were found to be more potent. Among terpenoids (ESI table #) #a and #b and with other miscellaneous compounds listed in ESI table # #a was highly polar. Based on the estimated lipophilicity all alkaloids (#a-g) and lignans (#a-b) can easily penetrate the cell membrane. While among the steroids (#a and #d) and terpenoids (#a and #b) and #b and #c does not possess the ability to penetrate cell membrane. All alkaloids except #g #b #a and #b possess very high drug distribution while others exhibit moderate or poor distribution. Most of the alkaloids (#a #c-d #f) and steroids (#b and #d) were hepatotoxic while terpenoids and other compounds were non-toxic. The potentiality of various chemical constituents from Tinospora cordifolia to inhibit SARS-CoV-# was evaluated through computational methods. These compounds have been reported to possess numerous pharmacological activities. The docking results indicate that among all the constituent compounds #a #e #a-c and #a-d possess the ability to interact strongly with human ACE# protein and #b and #f with the main protease of SARS-CoV-#. The above conclusion is based on the extent of interaction or their potential as lead compounds for further investigations to reduce their torsional energies. It is believed that strong interactions with human receptor for SARS-CoV-# could prevent the entry of the virus and thus could act as a prophylactic for COVID-##. Further the evaluated pharmacokinetic properties narrowed down the above candidates based on their druggability. From the overall ADMET properties it could be concluded that compounds #a #e #a #b #a #g and #a as potential drug candidates for COVID-##. Overall observation from combined results of docking analysis and ADMET properties revealed compounds #e #a #b #n #b and #c could be potential drug candidates out of ## constituents of the extract from Tinospora cordifolia. The druggable potential of the above six constituents can be tuned by engineering the molecules with less torsional energies and by lowering their cardiotoxicity.\n",
            "response:  Background: In December #### the severe acute respiratory syndrome coronavirus # (SARS-CoV) caused by SARS-cov has imposed severe social and economic burden across all countries. The virus spread to many countries around the globe is believed that it is not air/waterborne or through droplets contaminated hand or surface contacts etc.\n",
            "summarize: In social psychology \"intergroup contact\" has been considered one of the most important social psychosocial theories to examine relations among groups in the ##th century. The intergroup contact hypothesis was first proposed by Allport (####) to examine the social contact between different racial or ethnic groups and their mutual hostilities in the United States. In tourism research tourist-host social contact has been widely believed to play an important role in understanding intergroup relations tourists' behaviors and tourists' attitudes towards a destination (Fan Zhang Jenkins & Lin ####) . Therefore it has been argued that intergroup contact approach should be used more often to study tourist-host social contact in tourism studies (Fan Zhang Jenkins & Lin ####; Fan Zhang Jenkins & Tavitiyaman ####) . Accordingly some scholars have tried to explore tourist-host contact from different perspectives including tourist typology (Fan Zhang Jenkins & Lin ####) cultural distance (Fan Zhang Jenkins & Lin ####; Fan Zhang Jenkins & Tavitiyaman ####) host perceptions of tourism (Luo Brown & Huang ####; Sharpley ####) and tourist-host relations (Bimonte & Punzo ####; McKenna ####) . However over the past decade apart from the studies done by Pizam Uriely and Reichel (####) and Nyaupane Teye and Paris (####) research that investigates the impacts of social contact on tourists' attitudes change towards the host has not increased much. Just as Fan Zhang Jenkins and Tavitiyaman (####) have pointed out \" [g] iven the importance of social contact tourist-host social contact as a unique type of general social contact is not receiving sufficient attention in tourism\" (p. ###). Tourism as an important method of social contact has played an essential role in promoting peace in the contemporary world (Kim & Prideaux ####; Kim Prideaux & Prideaux ####) . Relevant research has been conducted such as Israeli tourists visiting Egypt (Milman Reichel & Pizam ####) American students visiting the former Soviet Union (Pizam Jafari & Milman ####) Greek tourists visiting Turkey (Anastasopoulos ####) and so on. Yet relatively few studies have been conducted to examine the role of social contact for tourists visiting \"friendly\" neighbors but with tension. One notable example is China and North Korea. On the one hand \"blood alliance\" between the two countries has been created since the ####s Korean war. One the other hand North Korea's continuous nuclear tests have to certain degrees undermined the relationship between two nations during the past ten years (The Guardian ####) . Moreover the majority of previous studies have put the focus on tourists' attitudes towards hosts under the context of full contact with local residents while rather fewer attempts have been made to study tourists' attitudes towards a country where there is tight governmental control of tourist-host social contact and one such country is North Korea. Due to its unique political system tourism in North Korea is significantly shaped and limited by stringently controlled itineraries (Wassler & Schuckert ####) such as restrictions on tourist-host social contact to 'protect' its citizens from the influence of the outside world (Kim Timothy & Han ####) . In addition most of the existing literature has focused on tourists' perceptions of North Korea after their visits (Li & Ryan ####; Li & Ryan ####; Li Wen & Ying ####; Wassler & Schuckert ####) . Accordingly there is a lack of understanding of tourists' attitudes towards North Korea prior to their visits. In this regard this study examines the impacts of social contact on Chinese tourists' attitudes towards North Korea and its people by answering the following three questions. The first is how Chinese tourists imagine North Korea as a tourism destination prior to their visits. Second this paper focuses on both the regulated and agentive aspects embedded in their contacts asking how individual Chinese tourist negotiates with the externally imposed limitations and regulations to obtain more contacts. Third this paper addresses how their attitudes change after their visits. In doing so the paper creates a deeper and more comprehensive understanding of tourism conducted between China and North Korea which are perceived as 'friendly' neighbors with conflicts. In this respect the paper's focus on Chinese tourism to North Korea thus serves as an important empirical extension. More critically this paper contributes to the literature on attitude change through tourism by extending the use of social contact theory. China has long been the largest tourist source for North Korea accounting for about ##% of the market share (Crabtree ####) . It has been suggested that China and North Korea are the two most intriguing \"socialist\" systems on the globe and that there are many similarities between them (Chung & Choi ####) . Specifically China and North Korea \"shared not only a common border a long symbiotic historical relationship a Confucian heritage and a history of Japanese occupation but also a communist/Marxist-Leninist ideology a 'divided state syndrome' a history of fighting US and UN forces in the Korean War a shared pariah status (at least for a time) in the international community and a past refusal of diplomatic recognition by all but a few nations\" (Moore #### p.#) . Most of the studies regarding North Korean tourism put an emphasis on Chinese tourists and have been undertaken from the following perspectives: tourist motivation (Li & Ryan ####) the impact of the nuclear crisis on destination image shopping experience (Li & Ryan ####) tourist satisfaction (Li & Ryan ####) and revisit intention . These research efforts have examined how North Korea is a highly regulated tourism destination with limitations on access restrictions on contact with the local population and a lack of individual mobility. On the one hand the regulated side as one of the most important destination images perceived by most tourists has made Chinese hold strong curiosities towards visiting North Korea (Li & Ryan ####) . On the other hand these restrictions as one of the most dissatisfying factors (Li & Ryan ####) exert negative influences over Chinese tourists' travel experiences such as shopping experience # (Li & Ryan ####) and revisit intention . Therefore it can be argued that Chinese visitors' unique perceptions of tourism in North Korea and more specifically their tourist-host contact as an important part of travel experience are significantly influenced and defined by these various kinds of restrictions. \"Attitude\" as one of the most influential factors in making travel destination decisions has received significant scholarly attention (Bianchi Pike & Lings ####; Gardiner King & Grace ####) . The majority of previous research regarding attitude in tourism tends to focus on the link between attitude and behavioral intentions such as motivation (Hsu Cai & Li ####; Prayag Chen & Del Chiappa ####) tourists' purchase intention (Rasty Chou & Feiz ####) and destination attachment (Prayag et al. ####; Reitsamer Brunner-Sperdin & Stokburger-Sauer ####) . At the same time some scholars have started to use intergroup social contact theory to examine tourists' attitude change through tourism (Çelik ####a; Çelik ####b; Litvin ####; Ming ####; Paris Nyaupane & Teye ####; Pizam et al. ####) . For example Litvin (####) examines attitude change through tourism by comparing Singapore MBA students' attitudes towards Middle East countries and their people before and after travel. His research has demonstrated that in-depth tourism experience has a significant positive impact on tourists' attitudes towards their host countries. The identified positive outcomes of attitude change through intergroup social contact include boosting mutual understanding (Litvin ####) enhancing empathy towards outgroups (Vorauer & Sasaki #### ) improving intergroup relations by eliminating bias and stereotypes (Crisp & Turner ####; Dovidio Love Schellhaas & Hewstone ####; Pettigrew & Tropp ####) reducing negative emotions towards outgroups such as anxiety (Page-Gould Mendoza-Denton & Tropp ####) and distrust (Vezzali Capozza Stathi & Giovannini ####) . However some authors challenged these above arguments regarding the impacts of the social contact (Chen Lin & Petrick ####; Paris et al. ####; Pizam et al. ####) . They found that intergroup contact may also lead to negative changes in attitude such as heightened tensions and stronger prejudice. According to Pettigrew and Tropp (####) negative intergroup contact effects frequently occur in situations where the participants feel threatened and do not choose to have contact. In addition to the outcomes of intergroup social contact some scholars have also explored the quantity and quality of those contacts (Fan Zhang Jenkins & Lin ####; Pizam et al. ####; Woosnam & Aleshinloye ####) . It has been argued that there is a positive link between the frequency of tourist-host contact and the change in attitudes towards the destination (Pizam et al. ####) . It is worth noting that most existing studies have mainly targeted those destinations without restrictions on tourist-host contact while relatively less attention has been paid to focus on those places with restrictions on tourist freedom. One of such a typical destination is North Korea. There is no doubt that North Korea's restrictions on tourist freedom influence both the quantity and quality of tourist-host contact. One of the most important motivations of Chinese tourists to visit North Korea is to know the real situations of North Korea and have contacts with local residents (Li & Ryan ####) and therefore it is meaningful to explore how Chinese tourists feel about and negotiate with these restrictions on tourist-host contact in order to obtain more understanding towards the country and its people. This study aims to understand Chinese tourists' attitudes change towards North Korea based on their personal travel experience. Given the exploratory nature of this study the method of in-depth semistructured interview was employed to generate primary data. As no free independent travel is permitted in North Korea all interviews were conducted in Dandong (China's largest border facing North Korea). Drawing on the first author's social networks the data collection process received support from three Chinese travel agencies that operating group tours to North Korea. The first author was a Dandong resident from #### to ####. While taking advantage of the role of \"an insider\" who have personally travelled to North Korea twice the first author was also aware of and continuously reflecting on the role of researchers. The three Chinese travel agencies mentioned above invited their # For example tourist souvenir shopping can only be undertaken at approved retail outlets (Li & Ryan ####) . F.S. Li and B. Wang Tourism Management Perspectives ## (####) ###### customers who paid the tour fee to participate in this study. Then those who agreed to be a part of the research were approached. Two section criteria were used to define the qualified participants. Firstly in order to have a deeper understanding of this topic the participants should be Chinese tourists who have stayed in North Korea for more than one day. Secondly the participants should be the people who agreed to participate in the interviews both before and after their trips. The interview questions were designed based on the intergroup social contact theory. A set of open-ended questions were asked both before and after their trips. Pre-trip interview questions focused on understanding how Chinese tourists feel about North Korea and its people prior to a visit. After-trip interviews focused on exploring Chinese tourists' post-trip attitudes towards North Korea. In particular after-trip interviewees were asked to share their feelings towards the restrictions imposed on them and whether and how they negotiate with their \"regulated\" trip to North Korea. They were encouraged to share detailed everyday stories and how they remember those defining moments during their stay in North Korea. Both pre-trip and after-trip interviewees were actively asked for further explanations and clarifications on certain points throughout the interviewing process (Qi Smith Yeoman & Xie ####) . Each pre-trip interview lasted ##-## min and each after-trip interview lasted ##-## min. Altogether ## interviews were conducted between May #st to July ##th #### (see Table # for the socio-demographic information of the participants). Data saturation was used to justify the sample size of this study based on the social contribution theory. As indicated by social construction theory redundancy in comments tends to occur with approximately ##-## respondents (Kelly ####; Pike ####) . For this study the last # interviewees did not provide any new ideas: therefore data saturation was achieved after the ##th interview. Altogether ## of the interviews were recorded with the verbal consent of participants. As four of the interviewees refused to take audio-recording the first author took notes to record the content of these four interviews with their oral permissions. The recordings and notes were transcribed into texts for further analysis. In order to ensure the high quality of data Chinese transcripts were used for data analysis to avoid distorting information at the transcription stage. Content analysis was used to analyze the transcripts. According to Berg (####) content analysis can be seen as a careful detailed and systematic way to identify patterns themes biases and meanings in social sciences. Following Luborsky's (####) procedures there were four stages of data analysis. The first was to get a sense of the whole text by repeatedly reading the transcripts. The transcripts were then manually coded into various themes and subthemes based on a literature review as well as the frequency of meaningful units (King & Horrocks ####) . While data was collected by the first author the second author contributed to identifying major empirical themes and gradually developing a theoretical framework. Moreover member checking was applied in this study to avoid falsified interpretations of the data to test the reliability and validity of this research (Cho & Trent ####) . In order to confirm the final study findings four informants were asked to check whether they agreed with the proposed findings which they did. Finally the findings and supporting quotations were then translated into English. To ensure the high quality of the translation a Chinese-English linguist was recruited to minimize the possible inaccuracies of the translation. Not surprisingly the majority of participants' attitudes towards North Korea before a visit are related to the country's political background. North Korea is seen as a \"real socialist\" country in Chinese tourists' eyes given its unique political and economic system. The expressions used by participants frequently to describe North Korea include \"a unique economic development model\" \"self-reliance policy\" and \"military-first politics\". The following are some examples of such responses: Unlike other socialist countries in the world North Korea is a real socialist country. As far as I know private ownership is banned by the North Korean government. Everything belongs to the government. North Korean government controls over the means of production and distributes product to every family (Interviewee #). North Korea is a real socialist country in my eyes. Given the popularity of globalization it still adopts a self-reliance policy. It tries to develop its country by itself. (North Korea's) military-first politics is also unique. China and the United States have reduced the cost of the military gradually; however the largest source of income and product such as food and clothes still goes to the military in North Korea (Interviewee #). Indeed some participants pointed out that their perceptions of North Korea's overall image are influenced and shaped by the country's special political and economic regimes. Firstly considering the extremely important role of the Kim family in North Korea's society the country has been characterized by a strong personality cult as to its leadership. Secondly North Korea is also recognized as a poor backward and mysterious country due to its closed social environment and little contact with the outside world. Some interviewees stated that: North Korea is a closed country in the contemporary world. I believed that North Korean people worship their country leaders crazily due to brainwashing education since they were born. I was shocked by one North Korean weightlifter who won the Olympic Games in ####. F.S. Li and B. Wang Tourism Management Perspectives ## (####) ###### He argued that the power for winning this competition originates from its great country leader (Kim Il-sung) . All of his achievements were given by him (Kim Il-sung) . It sounded like a god to him (Interviewee ##). As North Korea is one of the most closed countries in the world it is very mysterious. There is no doubt that North Korea is a poor and backward country due to a lack of international trade (Interviewee #). Apart from the political and economic factors some Chinese tourists' attitudes towards North Korea are based on their perceptions of the relationship between the two nations. Some Chinese tourists (particularly elderly ones) tended to make a comparison between today's North Korea and China in the ####s or ####s. In their eyes \"North Korea should be similar to China during the Cultural Revolution\" (Interviewee ##). Furthermore many respondents have viewed North Korea as China's friendly neighbor. Just to cite one example a ##-year old man noted: The friendship between China and North Korea is great. North Korea receives a large number of intentional aids from China every year. China is North Korea's most important partner. (Interviewee ##). In addition Chinese tourists expressed their attitudes towards North Korea as a tourism destination. First many Chinese tourists believed that North Korea's natural environment is well preserved due to a lack of polluting heavy industry. Second before the trip started a set of strict restrictions on tourist freedom were informed by Chinese travel agencies. These restrictions are the major barriers for tourists in exploring the real situation of North Korea through tourist-host contact. Examples of such responses included: North Korea is a very beautiful country in my mind. North Korean government really cared about its environmental protection. I expect to enjoy its beautiful natural scenery such as clean water and blue sky (Interviewee #). In order to protect our safety Chinese tour guides informed us of some rules and regulations when visiting North Korea prior to a visit. Basically we were asked to follow the order of North Korean local tour guides. I was eager to explore the real life of North Korean people. However the restrictions on tourist freedom may stop me from contacting them (Interviewee #). Many interviewees in this research shared their travel experiences in relation to restrictions on tourist-host contact. As knowing the real situation of North Korea drives Chinese tourists to visit North Korea most Chinese tourists tend to take photos to record their travel experiences in North Korea. However the North Korean government set restrictions on photo-taking for international tourists. Many interviewees stated that they take pictures with the permission of North Korean tour guides. We took the train from Dandong to Pyongyang. Many of us tried to take photos to record North Korean people during this journey. However the tour guides told us to stop taking pictures of North Korea rural villages and the people who are living in rural areas. One of the North Korean tour guides told us that city is beautiful in North Korean people's eyes. Therefore they wanted us to take more pictures of Pyongyang and Pyongyang residents instead of rural villages and rural people (Interviewee ##). The majority of participants felt that the North Korean government tried its best to cut off the connections between tourists and residents. According to their interview narratives the actions taken by the government include isolated hotel locations designated restaurants and shops for international tourists and a separate train compartment for international tourists. The majority of Chinese tourists stayed Yanggakdo International Hotel which is North Korea's first luxury hotel in Pyongyang the nation's capital. The hotel is located on an isolated Island. Tourists were not allowed to pass the permitted line of the island. Interviewee # recalled that \"[w]e stayed at the Yangakdo International Hotel in Pyongyang. This hotel is located in an isolated Island that cut off the connections between visitors and the outside world particularly Pyongyang local residents. North Korean tour guides told us that we are only allowed to walk within certain areas on the island for our safety concerns. If we pass the permitted line we will be punished. That was a very serious warning\". In order to experience ordinary North Korean's people life Chinese tourists were eager to go to restaurants and shops for local residents. However they realized that they were only allowed to go to the designated restaurants and shops for international tourists during their visits. According to interviewee ## \"[o]ur trip was entirely controlled by North Korean travel agency. I thought of experiencing the lifestyle of North Korean people before my visit. However we had meals in the designated restaurants only for us. We went shopping in designated shops only for us. I am pretty sure that these restaurants and shops are not available for local residents.\" At the same time some participants pointed out that North Korean travel agency prepared a separate train compartment for Chinese tourists who travel from Dandong to Pyongyang. This action was utilized to prevent them from contacting North Korean people. The following narratives provide a more detailed description regarding these issues: We took the train from Dandong to Pyongyang. The travel agency arranged a separate train compartment for our tour group. I checked the train and found that there are no North Korean people in our train compartment. I tried to go to another train compartment to contact North Korean people; however a rude North Korean train conductor stopped my action (Interviewee ##). The opportunities for us to contact North Korean residents were very limited. Our travel experience to visit Pyongyang Metro was very impressive. Waiting for experiencing the Pyongyang Metro was a big chance for us to contact North Korean residents. North Korean tour guides were also not allowed us to contact them. To be mentioned they arranged us a separate train to separate us from local residents (Interviewee ##). The findings show that tourist-host contacts are greatly regulated and constrained in the context of North Korea. However facing all these restrictions on contacting North Korean people some Chinese tourists still tried to look for methods to have more social contact and thus understand North Korea better. The following section will introduce how Chinese tourists exercise agency and negotiate with these restrictions to conduct more contacts. This study identifies two methods adopted by Chinese tourists to obtain more contacts. Firstly they collected information from North Korean tour guides. Secondly they actively engaged in observing North Korean local people during their travel. Information from North Korean tour guides. As Chinese tourists were always accompanied by the North Korean tour guides during their trips the majority of Chinese tourists argued that one of the most important ways for them to know North Korea is to have conversations with North Korean tour guides. Some of the interviewees said they tried to ask as many questions as possible related to North Korea particularly regarding North Korean people's life. The following two narratives are examples in case: I asked North Korean tour guides to introduce the basic information of North Korea to us. North Korean tour guides told us that everything in North Korea is owned by the country i.e. the State. The government would build houses and allocate them to North Korean people. We were told that this represented a \"people-centered policy\". It is also one reason as to why we saw so many identically designed houses throughout the North Korean countryside (Interviewee ##). I asked many questions related to the North Korean people's life. In summary we were also told that every North Korean family has three electronic appliances including refrigerator DVD player and television F.S. Li and B. Wang Tourism Management Perspectives ## (####) ###### provided by the country. The guides also told us that medical care in North Korea is free as is education and housing. They were very proud of it. We were also told that men above ## years of age are allowed to get married. Equally women over the age of ## years are also allowed to get married. I also asked the tour guide about the salaries of North Korean people. He answered that there is no current data about the salary of North Korean ordinary people. However we were told that the living standards of North Koreans in the ####s and ####s were very high. Indeed they were higher than China and South Korea at that time but because the international situation for North Korea deteriorated after #### the subsequent economic development of North Korea had slowed (Interviewee #). During these conversations the interviewees and the tour guides were very cautious and uses a quiet voice. Also most participants expressed that they hold doubts towards many of the \"facts\" they had been told for example some of them said: I doubted some facts provided by North Korean tour guides such as North Korean people's living standards and the current situation of North Korea. They were trying their best to show the positive parts of North Korea to us. I believed that North Korea's real situation and North Korean people's real-life are worse than what was informed by North Korean tour guides (Interviewee ##). I noticed that many Chinese tourists did not agree with North Korean tour guides. However the conversations were whispered or conducted in low tones. I heard that one man spoke to his wife in low tones after visiting the Pyongyang Metro: \"that (North Korean tour guides' words) is not true. North Korea could not build this Metro without the help of the Chinese army (Interviewee ##). Observing North Korean people. In order to have a better understanding of North Korea Chinese tourists also tried to observe North Korean people they encounter during the visit (e.g. waiters North Korean local residents on streets North Korean farmers and domestic visitors). They tended to make a judgment on the current situation of North Korea and its people's life based on observing North Korean people from many perspectives such as their clothes service attitudes and appearance. North Korean government tried to hide the \"real\" North Korea through cutting off the connections between local residents and international tourists. Chinese visitors knew that what they can observe only shows the best parts of North Korea. Even though many participants consider their observation an important way to experience North Korea due to the strict restrictions on tourist-host contact. Examples of such responses included: The majority of North Korean people wore uniforms on the streets. North Korean tour guides told us that the uniforms and shoes were distributed by the North Korean government based on their types of work. Their clothes look very poor and are not modern. North Korean people's life must be very hard (Interviewee #). All the North Korean waiters we met were very friendly to us. They were good-looking and polite. To my surprise the majority of them can speak mandarin. They smiled at us when serving us. I was very satisfied with their service. I felt respected. North Korean tour guides told us that Chinse is a compulsory class for some North Korean middle school students (Interviewee ##). North Korea is a very poor country. The majority of North Korean are very thin. I did not see any fat men on the streets. To my surprise there are so many high-rise buildings in Pyongyang. I can feel that people's living standard in Pyongyang is much higher than in any other cities. I saw some North Korean farmers when taking the train from Dandong to Pyongyang. They looked very unhealthy and I can feel that they are starving (Interviewee ##). I feel that North Korean people's mind is very traditional. They did not know what is happening outside North Korea. Here is a very impressive story. We met many North Korean people when we wait for visiting a museum. They all worn uniforms and waited for entering this museum. North Korean tour guides told us that they were organized by the government to visit this museum for educational meaning. Some Chinese women in our tour group were discussing the old-style clothes of North Korean women. Few Chinese women dressed like that in our minds. We felt that they were also discussing our clothes. All Chinese women in our tour worn modern style clothes such as t-shirts and short skirts. They were laughing at us. They may think that how women can dress like that. We did not understand their clothes and they did not understand us either. That is so funny and interesting (Interviewee ##). The majority of Chinese tourists argued that travel has enhanced their understanding of North Korea. Firstly some Chinese tourists (particularly younger tourists) started to understand a bit more regarding why North Korean people worship their leaders after knowing more about North Korea and its people. For example this opinion was supported by interviewee ## who was shocked by a North Korean Olympic weightlifting champion. I started to understand North Korean people's behaviors seen from TV such as athletes crying after winning the competitions. This is because everyone was taught to love their country and leaders. The feeling for me is very strong in North Korea. We met many North Korean domestic visitors such as workers and students organized by factories and schools. They were arranged to visit the tourist attractions such as museums and country leaders' childhood homes for patriotic education. One of our North Korean tour guides told us that he was requested to visit these attractions for education at least once a year since # or # years old. Secondly some Chinese tourists said that their attitudes towards the actions of the North Korean government such as military-first policy and nuclear tests are changed after their visit. Two interviewees shared that they started to understand these actions more after experiencing North Korea first hand. I start to understand the North Korean government a bit more now. The real situation of North Korea is comparable to China during the Cultural Revolution period. Like China during the Cultural Revolution North Korea is facing severe sanctions on international trade from western counties especially the United States. The military-first policy is very necessary given these situations. Only strong military power can fight against the United States and protect its citizens (Interviewee ##). North Korea's nuclear test in my eyes is kind of a crazy action prior to my visit. However my idea has changed a little bit after the trip. North Korean tour guides told us that they would like to develop its economy like China. They thought that one of the most important reasons for China to develop its economy over several decades is to own nuclear weapons. Even I cannot agree with all of their words it still makes some sense for me (Interviewee ##). Many Chinese tourists showed their empathy for North Korean people after knowing their tough life situations. Firstly the empathy was based on a comparison between their imaginations and the real situation of North Korean people. Chinese tourists pointed out that the quality of North Korean people's life is much lower than their expectations before their visit. They believed that North Korean people deserve a better life: North Korean people's life quality is lower than my expectation. The life quality gap between rural residents and Pyongyang residents is super big. My feeling is so complicated after this trip. I feel bad for them and I think they deserve a better life (Interviewee #). North Korea is so out of date. The majority of North Korean people did not know what is happening outside North Korea due to a lack of internet connection. They cannot enjoy a modern lifestyle such as karaoke bars nightclubs and pop music. Their life is so boring. I really sympathize with them (Interviewee ##). Secondly the empathy was also based on a comparison between F.S. Li and B. Wang Tourism Management Perspectives ## (####) ###### North Korean people's life quality and the one of Chinese people. In their eyes North Korean people's quality of life is much lower than Chinese people. The gap between the two nations generated a sense of empathy for North Korean people after their visit. North Korea is a really poor country. We are mainly about how to eat healthier in China now. However a large number of North Korean people are still starving now. Life for them can be tough. I feel sorry for them (Interviewee ##). As argued some Chinese tourists developed strong doubts regarding the explanations and facts provided by the tour guides after the trip. What the North Korean tour guides told them were vastly different from what Chinese tourists believe. The differences made Chinese tourists feel that North Korean try to hide the facts and do not tell them the truth. I thought that the North Korean government tries its best to show all the positive aspects of North Korea to us. That is the reason why North Korean tour guides did not tell us the real situations of North Korea such as the economic development level and the life quality of North Korean people. (Interviewee ##). Secondly some Chinese tourists changed their opinions in terms of the friendly relationship between the two nations after their visit. It was found that some Chinese tourists were angry with some explanations provided by the North Korean tour guide particularly were disappointed with the lack of acknowledgment regarding China's support when introducing the achievements made by North Korean. I am so angry now. How can they ignore the support of China? It was impossible for North Korea to build the Pyongyang Metro without China's support. North Korean tour guides even did not mention a word related to China's support. I need to rethink the friendship between the two nations. (Interviewee ##). Using semi-structured interviews this study examines Chinese tourists' pre-visit and post-visit attitudes towards North Korea based on social contact theory. It shows that Chinese tourists' pre-visit attitudes towards North Korea can be divided into five categories including the political system economic situations the relationship between China and North Korea beautiful natural scenery and strict restrictions on tourist freedom. Chinese tourists' pre-visit attitudes towards North Korea reflect North Korea's destination image in Chinese tourists' eyes. This finding is supported by Kim and Richardson (####) who found that destination image has the power to confirm or reinforce existing tourists' attitudes towards a destination. Drawing on the travel experiences of Chinese tourists this study identifies specific restrictions on tourist-host contact in North Korea. Some restrictions were confirmed by previous studies such as restrictions on photo-taking (Li & Ryan ####) an isolated hotel location (Li & Ryan ####) and designated shops for international tourists (Li & Ryan ####) . However some restrictions were not identified such as designated restaurants for international tourists and a separate train compartment for tourists. These restrictions are used to cut off the connections between North Korean residents and Chinese tourists which means the opportunities of tourist-host contact are very limited. While facing all these restrictions some Chinese tourists still managed to negotiate with these restrictions and looked for opportunities to obtain more contacts during their travel. The existing literature has paid little attention to the methods of obtaining social contact when there are restrictions on tourist-host contact. This research has thus filled in this research gap by identifying two important methods of social contact utilized by Chinese tourists visiting North Korea. The first method is obtaining information through conducting conversations with North Korean tour guides and the second is observing North Korean people they encounter during the trip. This study identifies three types of Chinese tourists' post-visit attitudes towards North Korea including having more understanding of North Korea showing empathy to North Korean people and developing feelings of doubt and anger. The first two types of attitude changes identified by this research support the social contact theory. These two are positive outcomes of social contact: enhancing understanding of North Korea and showing empathy to North Korean people. It has been found that some Chinese tourists' attitudes towards North Korea changed from confusion to understanding after their visit. This finding is in accordance with what Litvin's (####) work has demonstratedintergroup social contact can nurture mutual understanding. The second positive attitude change is enhancing feelings of empathy towards outgroups which is also supported by previous research (Vorauer & Sasaki's ####) . According to the intergroup contact hypothesis formalized by Allport (####) there are four conditions to ensure the positive outcomes of contact including the equal status of the group members common goods intergroup cooperation and the support of authority law or custom. However Allport's optimal contact conditions to ensure the decrease in prejudice were challenged by Pettigrew and Tropp (####) who conducted a meta-analysis that combined the results of all the intergroup social contact studies of the ##th century. The meta-analysis revealed that even Allport's conditions are not met intergroup contact still enables to reduce prejudice. Therefore even those optimal contact conditions are not all met in the context of Chinese tourists to North Korea these two identified positive outcomes are still supported by Pettigrew and Tropp (####) . The third type of attitude change identified in this research is some Chinese tourists developing feelings of doubt and anger after the visit. In this respect this paper also challenges the social contact theory and supports the idea that not all intergroup contacts necessarily lead to a positive change in attitude (Chen et al. ####; Pizam et al. ####) . In the context of this study the North Korean tour guides' introduction sometimes leads to Chinese tourists' negative emotions such as doubt and anger. Chinese tourists who were proud of Sino-North Korea friendship before the visit started to feel angry and disappointed with North Korea due to the ungrateful interpretations of North Korean tour guides. These negative emotions were also identified by Wassler & Schuckert #### who examined tourists' lived travel experience to North Korea. Critically this study extends the use of social contact theory to a destination with restrictions on tourist-host contact. Previous studies have shown that the change in tourists' attitudes towards hosts and destination are positively influenced by the quantity of contact (Pizam et al. ####) and quality of contact (Fan Zhang Jenkins & Lin ####) . Given the restrictions on tourist-host contact in North Korea the quantity of contact is limited and the quality of contact is low in the context of Chinese tourists to North Korea. Nevertheless as discussed above both positive and negative attitudes change through tourism have been discovered within this study. One of the major functions of case study-based research is to identify variables that may be of importance for future research. In this instance it can be argued that tourist-host contact in North Korea is characterized by the dimensions shown in Fig. # . One of the most important Chinese tourists' pre-visit attitudes towards North Korea is related to its special political and economic regimes. Therefore the majority of Chinese tourists had a general understanding of North Korea's restrictions on tourist freedom caused by North Korea's political system prior to their visits. In order to know the \"real\" North Korea Chinese tourists exercised agency to negotiate with the restrictions to obtain more contacts during their visits including obtaining information from North Korean tour guides and observing North Korean people. These special social contact methods shape Chinese tourists' unique travel experience in North Korea. As discussed above the travel experience leads to both positive and negative changes in terms of tourists' post-visit attitudes towards North Korea. The data generates two practical suggestions for managing Chinese F.S. Li and B. Wang Tourism Management Perspectives ## (####) ###### tourists in North Korea. Firstly considering Chinese tourists' pre-visit attitudes towards North Korea mentioned earlier slogans such as \"exploring a real socialist country\" \"experiencing past China\" and \"experiencing the world's most mysterious country\" can be used to attract Chinese tourists to North Korea. In order to prevent the spread of COVID-## the North Korean government has closed the border to foreign tourists since ## January #### (Yong ####) . Some media shared the news that the virus spread to North Korea around March #### (Business Insider ####; Park Jong & Jung ####) but the North Korean government has not confirmed any cases so far. This news and all kinds of relevant guesses make North Korea a more mysterious country in Chinese tourists' eyes. Knowing the real North Korea would become a motivation for Chinese tourists to visit this mysterious country after the travel ban. Secondly the findings indicate that some Chinese tourists are dissatisfied with a lack of acknowledgement regarding Chinese government's help for constructing certain infrastructures such as the Pyongyang Metro. As such North Korean tour guides in the future may try to highlight the importance of China to North Korea when introducing some places that were built with the support of the Chinese government. This study provides implications for future research. First this study focuses on Chinese visitors to North Korea therefore visitors from western countries can be given more attention in future research. Western visitors may have different attitudes towards North Korea's restrictions on social contact due to different cultural and political backgrounds. It will be interesting for scholars to explore the possible different travel experiences between Chinese visitors and western visitors. Second this research is exploratory and thus does not fully delve into the nuances relating to socio-demographic variables and characteristics of different individual participants. For example whether the age of Chinese tourists had a significant influence on their attitude change needs to be studied. At the same time attitudes towards revisit can be influenced by travel motivations (Huang & Hsu ####) whether Chinese tourists' motivations have a significant influence on their attitude change in North Korea also demands further investigation. Additionally quantitative methods can be employed by researchers to better answer these research questions. Dr Bingyu Wang is an Associate Professor at the School of Sociology and Anthropology of Sun Yat-sen University where she was recruited as a member of the '### Top Talents Program' of the Ministry of Education of China. Her research areas include migration and mobilities intercultural encounters and cosmopolitanism with a geographic focus on Asia-Pacific and theoretical focus on emotions time and the everyday. She has published widely in high-ranked international journals and her most recently published book with Routledge is entitled New Chinese Migrants in New Zealand: Becoming Cosmopolitan? Roots Emotions and Everyday Diversity. She is currently working on projects relating to tourism and lifestyle mobilities migration infrastructures and body experiences among mobile subjects in and from China. F.S. Li and B. Wang Tourism Management Perspectives ## (####) ######\n",
            "response:  The aim of this study was to investigate the relationship between socio-economic and social factors among Israeli tourists in Turkey during a period from ###–### years. A cross sectional survey (N = ##) with different ethnic groups had been conducted on touristhost relations; however it has not grown as an empirical method for exploring other aspects related to tourism. In addition some studies have studied both cultural distance and economic parameters such as geographical differences or spatial constraints that are still unknown.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summarize: Environmental economic and other major disruptions that create even brief periods of social instability are referred to as \"Big Events \" ( Friedman et al. #### ) . They have a variety of direct and indirect influences such as population displacement economic disruption health service shortages and upticks in violence which affect normative behaviors and in some cases lead to social upheaval ( Friedman et al. #### ) . Big Events are noted as having especially seriously impacts \"on marginalized groups of people whose social precarity leaves them more vulnerable to the harms engendered by major disruptions \" ( Zolopa et al. #### ) . Research on the repercussions of Big Events and on how interacting causal pathways are experienced by specific groups can inform interven-tions aimed at preventing or mitigating harm ( Friedman et al. #### ) . In their recent review article Zolopa et al. identify risk pathways resulting from \"Big Events \" on health and service delivery for people who use drugs ( Zolopa et al. #### ) . Included in this framework are disruptions of drug treatment and harm reduction services. While empirically based on prior Big Events Zolopa et al. note an inability to test their framework within the Big Event of the COVID-## pandemic due to a lack of data. They further suggest that validating their findings within vulnerable subpopulations of people who use drugs including women and ethnic or racial minorities are important next steps toward effectively using this model to understand risk pathways for people who use drugs. Embedded within this framework yet not explicitly described by Zolopa et al. is ( Gutovitz et al. #### ) . Similarly large decreases in ED use across multiple U.S. subpopulations have been reported with the notable exception of people experiencing homelessness whose ED visit volume was only #.#% lower than in the prior year ( Castillo et al. #### ) . Factors associated with ED visits among homeless or unstably housed (HUH) people such as increasing health needs or barriers to other types of non-ED care during the pandemic are unknown. We conducted a study to examine associations between increased challenges obtaining various types of outpatient health care -including treatment for drug use -during the COVID-## pandemic and emergency department (ED) use among women with a history of homelessness or unstable housing. Our research provides early data from the pandemic to test the framework of risk pathways identified by Zolopa et al. in the context of COVID-## and potentially apply findings to future pandemics or other Big Events. We conducted a cross-sectional community-based study among ### women with a lifetime history of homelessness or unstable housing to examine whether increased difficulties obtaining health care including drug treatment during the first ## months of the COVID-## pandemic were associated with ED use. Between July and December #### participants were recruited from San Francisco homeless shelters free meal programs low-income single room occupancy (SRO) hotels street encampments and the Zuckerberg San Francisco General Hospital HIV clinic ( \"Ward ## \") the largest public HIV provider in San Francisco. Eligibility criteria included female sex at birth age ≥ ## years and a history of homelessness (i.e. slept in public or a homeless shelter) or housing instability (stayed temporarily with friends/acquaintances [ \"couchsurfed \"]). Women living with HIV were over-sampled to address HIVspecific aims reported elsewhere. Participants were reimbursed $## for completing a study interview. We asked all interview questions using the start of the pandemic as the reference point (March ####). The primary outcome was any self-reported use of an ED. Exposures since the pandemic included age race/ethnicity homelessness (slept outside or in a shelter) unmet subsistence needs (insufficient access to food clothing housing and hygiene needs) ( Gelberg et al. #### ) ; social isolation (feeling isolated and unable to rely on others) ( Cornwell & Waite #### ); increased difficulty managing symptoms of ≥ # chronic medical condition; and increased difficulty obtaining treatment for mental health drug use or a chronic medical condition (HIV cardiovascular disease diabetes asthma or emphysema). We used multiple logistic regression to examine factors independently associated with ED use during the pandemic. Study procedures were approved by the University of California San Francisco Institutional Review Board. All study participants provided informed consent prior to participating in study activities. The median age of study participants was ## years and ##% were Black. One-third (##%) reported deciding where to sleep during the pandemic based on avoiding violence and ##% reported experiencing street or shelter homelessness during the pandemic ( Table # ) .Since the pandemic's start ##% of participants had been tested for SARS-CoV-#; none reported testing positive. Overall one-third (##%) of participants reported at least one ED visit since the start of the pandemic. In adjusted analysis factors significantly associated with ED use included being multiracial compared to being Black (adjusted odds ratio [AOR]: #.##; ##% CI: #.## ##.##) any cocaine use during the pandemic (AOR: #.##; ##% CI: #.## #.##) experiencing homelessness during the pandemic (AOR: #.##; ##% CI: #.## ##.##) and experiencing increased difficulties receiving drug use treatment during the pandemic (AOR: #.##; ##% CI: #.## ##.##) ( Table # ). Our findings suggest that the rate of ED use among HUH women during the COVID-## pandemic (##% during the first ## months of the pandemic) was similar to that reported in prior research using a similar sample (with the exception that participants of the current study were approximately ## years older) ( Doran et al. #### ) . It provides further evidence that HUH women unlike the general population did not significantly decrease their ED use during the pandemic ( Castillo et al. #### ) . Consistent with prior research ( Doran et al. #### ) we found that race recent cocaine use and homelessness were associated with ED use in this population. In addition while increased difficulties receiving drug use treatment during the pandemic were reported by less than ##% of participants this factor was strongly linked to ED use even after accounting for race housing and cocaine use. This is not as well-documented in the peer reviewed literature but has implications for ensuring ongoing access to all types of care during a Big Event. Use of an ED and access to drug treatment were ascertained independently of one another and participants did not provide reasons for ED visits. How reduced access to drug treatment may lead to increased ED use is therefore currently unclear particularly during a Big Event and will require further study. For example while access to certain types of treatment (e.g. telehealth) may have stabilized or expanded access to care for the general population this treatment modality may not have been broadly accessible to patient populations with more limited access to technology such as people experiencing homelessness. It is possible that study participants were unable to access their usual treatment and/or among those in or out of treatment responded to pandemicrelated stresses by using drugs more frequently in greater quantities or via riskier methods (e.g. used alone). Additionally disruptions in the drug market may have led to riskier practices such as inconsistent use use of an unfamiliar product drug substitution and/or polydrug use resulting in increased drug toxicity or overdose. Clarification of reasons/pathways for ED visits during the pandemic could help prepare service providers to care for particularly vulnerable individuals during future Big Events. Results reported here build on the \"Big Events \" approach to considering risk pathways among people who use drugs suggesting the utility of examining ED care as a potential \"downstream \" result of barriers to services. Findings provide insight into the potential role of EDs as a critical service site during \"Big Events \" and add support for Zolopa et al.'s theory postulating pathways between treatment availability and health outcomes. Our findings suggest the potential utility of two changes to the risk pathway map for the COVID-## pandemic. First they suggest the addition of housing status. Housing status is a strong predictor of health and health services use outside of Big Events and may become even more important during crises in which multiple overlapping social determinants of health are impacted ( Riley et al. #### ) . This possibility has been strongly supported by recent research showing that overdose deaths during the COVID-## pandemic increased significantly among people experiencing homelessness ( Appa et al. #### ) . Second our findings suggest the potential usefulness of disaggregating services when considering \"reduction in service coverage/capacity \" (e.g. harm reduction services drug treatment health care for pre-existing medical conditions and ED care). EDs are open ##/# and are federally mandated to provide care to all who come through their doors making them uniquely accessible among U.S. healthcare sites. People experiencing homelessness are known on average to use EDs more often than people who are stably housed ( Kushel et al. #### ) . The extent to which EDs successfully or unsuccessfully filled gaps in drug use treatment for people experiencing homelessness during the pandemic is unknown. While not yet widespread an increasing number of EDs have begun initiatives to start buprenorphine for patients with opioid use disorder while they are still in the ED as a bridge to outpatient treatment ( D'Onofrio et al. #### ) . Other ED-based initiatives have used peer navigators to engage with patients around their drug use ( Welch et al. #### ) . A study of ## EDs across the U.S. showed ED visits for overdose increased significantly in #### compared to ####-#### in contrast to ED visits overall which decreased during the pandemic ( Soares et al. #### ) . However to our knowledge no study has yet examined how ED provision of drug use related services might have changed during various stages of the pandemic. Our research has several limitations. Data reported here are from a small single-site study and would be strengthened by replication in ad-ditional more comprehensive research. Another limitation of the study is the lack of data on reasons for ED use. Future studies distinguishing reasons for visiting an ED particularly with respect to linking drug use factors with ED use could help provide more detail to expand results reported here. However such results should be considered with caution because symptoms associated with drug use are often non-specific and could be inadvertently misclassified ( Riley et al. #### ) . Our findings suggest that alongside important efforts to increase SARS-CoV-# testing and treatment for infection during the COVID-## pandemic it is critical to ensure ongoing access to housing and lowbarrier non-COVID health services including drug use treatment. The findings also reinforce the fact that in times of crisis or Big Events EDs continue to provide low barrier access to care for people who may not have access to alternative treatment options including homeless and unstably housed individuals living in the United States. This research was supported by RGPO Emergency COVID-## Research Seed Funding provided by the California HIV/AIDS Research Program of the University of California ( R##RG#### ) and the National Institutes of Health ( R## DA###### ; R## DA###### ; K## DA###### ). The authors declare that they have no competing interests.\n",
            "response:  BACKGROUND: Big Events have an impact on people who use drugs. The findings of the COVID-## pandemic and their implications for prevention or mitigate harm are not explicitly described by Zolopa and al (#) to understand risk pathways within vulnerable subpopulations in developing countries including those with high unemployment that require non-ED care during the outbreak were identified. This study sought to explore factors associated with spiked drug use rates among homeless/untiltered adults experiencing homelessness after ICU visits increased than prior years when they completed such interventions.\n",
            "summarize: Coronaviruses possess a single-stranded nonsegmented RNA genome of positive polarity (# #) and are associated with a variety of diseases in man and animals (#-#). Coronaviruses are divided into two major antigenic groups. The first group includes human coronavirus strain OC## (HCV-OC##) bovine coronavirus (BCV) mouse hepatitis virus (MHV) and hemagglutinating encephalomyelitis virus of swine (HEV) (# #). HCV-OC## causes respiratory infection of man similar to those of influenza viruses (#). BCV causes enteritis of newborn calves and is also considered to be an etiological factor of respiratory diseases of calves (# #) . MHV can infect different organs causing enteric respiratory and neurological diseases (# #) . A unique property of coronaviruses within this antigenic cluster is the presence of the hemagglutinin/esterase (HE) gene. The genome of MHV-A## contains an open reading frame (ORF) which may code for an HE protein. However the HE is not expressed in infected cells (## ## ## binding) and acetylesterase (receptor-destroying) activities similar to the HE (or HEF) glycoprotein of influenza C virus (ICV) (##) (##) (##) (##) (##) (##) (##) (##) (##) . It was shown that the HE glycoprotein of BCV strain Quebec induces neutralizing antibodies both in vitro and in viva and thus is important in viral infectivity (## ##) . It is evidently not required for viral infectivity in MHV-A## and MHV-JHM (##). The role of the HE gene and its protein in coronavirus evolution replication and pathogenesis remains unclear. The exact genomic organization of HCV-OC## is not known. Antigenic and nucleic acid hybridization studies indicate that the HCV-OC## is closely related to BCV (##-##). By analogy to BCV the order of the genes coding for the structural proteins probably is #'-HE-S-M-N-#'. Recently the N gene of HCV-OC## was sequenced and it was found to be similar to BCV N gene (##.##/o amino acid sequence homology) (##). The origin and evolutionary relationships among the HE genes of hemagglutinating coronaviruses isolated from different species are poorly understood. To elucidate the molecular evolution of the coronavirus HE genes we sequenced the HE genes of HCV-OC## a bovine respiratory coronavirus (BRCV) a virulent and an avirulent BCV strains. We report here the complete nucleotide sequence of the HE genes of HCV-OC## and BRCV-G## and their phylogenetic relatedness to BCVs MHV and ICV. HCV-OC## was obtained from the American Type Culture Collection (ATCC ###-VR) and propagated in human rectal tumor (HRT-##) cells as described previ-ously (##). A bovine respiratory coronavirus strain Giessen ##-#### (G##) was kindly provided by Dr. W. Herbst Institute of Hygiene and Infectious Diseases of Animals Justus Liebig University Giessen Germany. This virus was originally isolated from nasal swabs of a calf suffering from respiratory disorder and propagated in HRT-## cells. Isolation and purification of viral RNA cDNA synthesis double-stranded (ds) cDNA amplification and single-stranded (ss) cDNA production by polymerase chain reaction (PCR) as well as DNA sequencing were performed as described previously (## ##) . Primers were designed to generate cDNA fragments from virus-specific mRNAs by reverse transcription and PCR amplification based on the high degree of genomic similarity between HCV-OC## and BCVs (## ##). These primers were previously used for amplification and sequencing of BCV S and HE genes (## ##). PCRgenerated cDNA fragments were directly sequenced in both directions. Analysis of the sequences revealed that a large ORF of #### nucleotides was identical in size to the HE genes of BCVs (## ## ##) . This ORF terminated ## nucleotides upstream from the S gene (Zhang eta/. unpublished data) and encoded a protein of ### amino acid residues with an estimated molecular weight of ##.# kDa (Figs. # and #). Two identical sequences (CTAAAC) similar to the consensus intergenie sequence upstream of the HCV-OC## N gene (CTAAAT) (##) and identical to the consensus sequence upstream of BCV HE and S genes were found ## nt upstream of the predicted initiation codon (at nucleotides ## to ##) for the HE protein and # nt downstream from the termination codon respectively. Hydropathic analysis of the predicted amino acid sequence indicated that the putative HE protein possessed the characteristics of a membrane protein. Specifically a hydrophobic stretch of ## amino acids at the N-terminus may serve as signal peptide with a cleavage site between amino acids ## and ## (## ## ##) . Another hydrophobic amino acid sequence near the C-terminus (amino acids ### to ###) may serve as the transmembrane domain anchoring the protein in the viral envelope. A hydrophilic sequence of ## amino acids at the C-terminus may serve as an intravirion-domain. Ten potential A/-linked glycosylation sites were predicted in the HE protein of HCV-OC## while nine of them were present in that of BRCV-G##. Two internal ORFs were predicted within the large ORF extending from nt ### to ### and from ### to ####. By analogy to BCV HE gene these results suggest that the predicted large ORF #b represents mRNA #-l of HCV-OC## and BRCV-G## encoding the HE glycoprotein. The predicted amino acid sequences of the HE genes from HCV-OC## and BRCV-G## (Fig. l) BCV- (##) BCV-L# BCV-LY### (##) MHV-A## (IO) MHV-JHM (##) were aligned using the programs of the University of Wisconsin Genetic Computer Group software package version #.#. The alignment revealed that the HE gene of HCV-OC## was more closely related to BRCV-## and BCVs than to MHVs. Nucleotide and amino acid sequences among HCV-OC## BRCV-G## and BCVs were ##.# to ##.#% and ##.# to ##.#% identical respectively while the amino acid sequence identity between HCV-OC## and MHVs was approximately ##%. Fourteen cysteine residues were strictly conserved in the HE proteins of HCV-OC## BRCV-G## BCVs and MHVs. The MHV-JHM had ## amino acids and two cysteine residues more than HCV-OC## and BRCV-G##. The alignment indicated that the eight HE genes among coronaviruses can be divided into two groups. The first group includes HCV-OC## BRCV-G## and all BCVs and the second group includes MHV-JHM and MHV-A##. To identify a possible evolutionary pathway for the HE gene of coronaviruses we compared the coronavirus HE genes with the ICV HE gene. An alignment of the predicted amino acid sequences is shown in Fig. # . In this alignment the ICV HE# subunit shows a sequence identity of approximate ##.#% with the HE protein of HCV-OC## BRCV-G## and BCVs and ##.#% with the HE protein of MHVs. The alignment shows that several regions are completely identical. Most importantly the putative acetylesterase active site (F-G-D-S) (at amino acids ## to ## in Fig. #) is conserved in all HE proteins of human bovine and murine coronaviruses and ICV. Ten of the ## cysteine residue positions of HCV-OC## are conserved among all HE proteins compared. These data suggest that these proteins may be evolutionarily related to each other. DNA sequences for each gene were optimally aligned based on the alignment of their respective amino acid sequences (Fig. #) . A maximum parsimony analysis was per-formed on the aligned DNA sequences to predict possible phylogenetic relationships among coronaviruses (detailed methodology for the phylogenetic computer-assisted analysis is described in the legend of Fig. # ). Cladistic analysis of the DNA sequence data resulted in a single phylogenetic hypothesis (phylogram) with a total length of #### steps and a resealed consistency index of #.###. This analysis suggested that all coronaviruses were divided in two clades. One clade included HCV-OC## BRCV-G## and BCVs. The other clade consisted of MHV-JHM and MHV-A##. Neither coronaviral clade is derived from the other. Within the clades all BCVs were closely related taxa to HCV-OC## and the MHV-JHM and MHV-A## were sister taxa. The phylogram sug-G TC GA CTAAACTCAGTGAAAA TGTTTITGCTl'CC!XGATlTATTCTAGTTAGCTGCATAATTGGTAGCITAGGTTlTTACAACCCKCTACCAATGTTG'llTCGC ****** MetPheLeuLeuProArqPheIleLeuValSerCysIleIleGlySer~uGlyPhe~r~nProP~o~rAsnValValserH \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" -uAlaPhePheTrpAlaLeuArqLeu---__\"\"____\"_\"\"\"\"\"\"\"_\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"-\"-\"\"\"\"\"\"\"\"\" The sequences for BCV-L# BCVLY### were obtained from recent work (##). gested a common ancestor of this antigenic group of and assuming ICV as outgroup. The highly variable recoronaviruses. The highly cell-adapted strains BCV-gions (positions ##-l ## ###-### ###-l ### #### -L# BCV-Quebec and BCV-Mebus are closely related #### #### -#### and #### -#### were excluded to the wild-types BCV-LY### and BRCV-G##. We ex-because they were not aligned with confidence. We cluded these strains in the final phylogenetic analysis identified ### phylogenetically informative sites (varibecause their close relationships resulted in collapsed able sites with at least two taxa potentially sharing a branches in the phylogenetic tree. We further at-derived base) from ### aligned base positions. The tempted to analyze the relationship among the HE phylogram shows an almost identical topology for the genes of selected coronaviruses and ICV based on coronaviral ingroup obtained by the previous analysis these results using limited DNA sequence information (Fig. #) . (IO) and BCV-LY### (##) and a partial HE gene sequence of ICV (##) were used for this phylogram. The DNA sequences were aligned based on their deduced amino acid sequence alignment as shown in Fig. # Since the HCV-OC## and ICV infect similar tissues in human subjects the significant sequence homology between the HE genes of the two viruses suggests that coinfection of an ancestral coronavirus with ICV followed by recombination may have given rise to HCV-OC##. This was also proposed by Luytjes et al. (##) . Phylogenetic analysis also suggests that the HE genes of coronaviruses and ICV may originate from a common ancestor. It is worth noting that the HE protein of ICV contains receptor-binding acetylesterase and fusion activities while that of coronaviruses contains only the receptor-binding and acetylesterase activities. The fusion function of ICV is associated with the /V-terminal hydrophobic region of the HE# subunit of the HE protein (##) (##) (##) ##) . A similar hydrophobic domain was not found in the coronavirus HE protein. The high similarity between the HE proteins of HCV-OC## and BCVs (##% identity on the average) suggests that both viruses are very closely related. This hypothesis is also supported by the tree branch distance in the phylogenetic analysis shown in Fig. # . Interestingly the HE of HCV-OC## is more closely related to those of BRCVG## and the wild-type virulent strain BCV-LY### than to that of the cell-culture adapted avirulent strain BCV-L#. The wild-type strain BCV-LY### does not replicate in numerous bovine cells in vitro but it grows readily in human cells (HRT-##) without requiring prior adaptation (## ## ##) . Since these polarized human cells retain many features of primary epithelial cells infection by BCV suggests that BCV may also infect humans and therefore it is a zoonotic virus (## ##). We previously reported a case of human diarrhea caused by BCV-LY ### in which the virus was identified from the infected patient (##). Recently we found that BRCV-G## exhibited almost identical cytopathology in vitro to the wild-type virulent strains BCV-LY ### (data not shown). The HCV-OC## BCVs and BRCV-G## differed only in few amino acids in the HE and their putative acetylesterase active sites were conserved (see Fig. # ). #-acetylneuraminic acid was shown to be the major determinant for ICV (##-##). HCV-OC## BCVs and BRCV-G## probably recognize this receptor on the surface of many different epithelial cells. They may be able to replicate in epithelial cells of both respiratory and intestinal tracts and to cross species-barriers causing diseases in heterologous hosts. However HCV-OC## primarily causes respiratory diseases and BCVs cause enteritis. The ability of these viruses to replicate in different organs and to cause different clinical symptoms is probably due to multiple amino acid differences occurring within several viral proteins. The S protein of MHV was shown to be important in tissue tropism (##). Recently it was reported that turkey enteric coronavirus is antigenically and genomically closely related to BCVs (##) and similar functions were found in the HE protein of HEV (##). Whether swines or turkeys may also serve as reservoir (mixing-vessel) for coronavirus recombination in nature as it was proposed for influenza A viruses (##) remains to be elucidated. It is worth noting that ICV was also isolated from pigs (##). It will be worthwhile to compare the HE genes among these coronaviruses. Comparison of the remaining genes with HCV-OC## and BCVs will provide further insight into their evolution and host cell tropism.\n",
            "response:  The hemagglutinating encephalomyelitis virus of porcine (HEV) is an antigenic group that can infect different organs. Here we show the presence of coronavirus-associated genes as well as its related functional characteristics and mechanisms for viral pathogenesis. In this study we demonstrate that BCV has been implicated in various human respiratory diseases such as pneumonia influenza C virus viruses but also through host immune responses to infectious infections.\n",
            "summarize: Recent efforts by national prominent organizations have added momentum to ongoing campaigns by various groups to encourage consumers to own a bank account and for banks to offer affordable safe bank accounts (CFE ####) . For example during the COVID-## pandemic the Federal Deposit Insurance Corporation (FDIC) is hosting a \"get banked\" campaign to persuade consumers to open a bank account so they can easily and quickly receive federal stimulus payments (FDIC ####) . At the same time the American Bankers Association is encouraging all banks to offer lowcost basic accounts that meet national standards for functionality and affordability (ABA ####) . This recent attention in practice mirrors increased attention in policy arenas and by researchers. For several decades scholars and government entities (e.g. the FDIC the Federal Reserve and Congressional committees) have called attention to the problem of unbanked and underbanked in the USA (Barabaran ####; Board of Governors of the Federal Reserve ####; FDIC #### FDIC ####a FDIC #### FDIC ####b FDIC #### FDIC #### . In #### an estimated #.#% of US households had no bank account (are \"unbanked\") (FDIC ####) . Unbanked individuals live in a household where no one has a checking or savings account at a bank or credit union (FDIC ####) . These individuals take care of their banking needs through the use of cash and/ or use of alternative financial services (AFSs) such as general purpose reloadable prepaid debit cards check cashiers non-bank money orders and auto title loans. Another ##.#% have an account but also used AFS (are \"underbanked\") (FDIC ####) . Underbanked individuals use the same types of AFS as unbanked individuals for purposes of convenience preference avoidance of fees and other reasons (FDIC ####) . Unbanked and underbanked rates are higher among lower-income less-educated Black Hispanic American Indian or Alaska Native working-age disabled households and households with volatile income (FDIC ####) . Lacking a bank account at a financial institution or not fully using an account or the banked relationship for other products and services can be problematic in several ways. First without an account consumers spend an average of #.#% of their annual income on fees (Office of the Inspector General United States Postal Service ####) . Second the unbanked and underbanked also suffer the cost and indignities of financial exclusion a lack of \"financial citizenship\" that creates a bifurcated culture of those within and those outside of mainstream financial institutions and must pay more for credit than those fully within mainstream financial institutions (Servon & Castro-Cosio ####) . The challenges of the unbanked and underbanked have structural roots in policy related to the financial system. Mainstream financial institutions (i.e. retail banks and credit unions) provide basic bank accounts for the majority of the US population yet policy falls short of sufficiently incentivizing or requiring them to provide basic accounts for everyone. Policy solutions have long been proposed by scholars and policymakers to reduce or eliminate financial exclusion related to accounts. Yet little research has systematically analyzed Congressional proposals to these problems. This paper examines them and their fate. Results will inform future related policy efforts to reduce these populations. While the remedies for the unbanked and underbanked problem appear at face value to lie at the consumer level several important aspects of these challenges are rooted in policy. These aspects include the type of institution offering accounts the ability or willingness to optimize incentives to create needed account products and physical access challenges. The type of institutions that offers an account and its incentives and rewards may play a role. In the USA only government-chartered financial institutions offer bank accounts with consumer protections (American Banker ####) . The products and services offered by banks and credit unions are influenced by their competitive marketplace their mandate to produce a profit and by government regulations. Within this environment offering affordable basic accounts for the unbanked and underbanked is often not profitable nor attractive (Geffner ####) . Less than half of banks create products and services for underserved consumers (FDIC ####b) . Banks often charge fees to pay for the administrative costs of accounts with small balances such as overdraft fees which make up ##% of all bank fees (Maremont & McGinty ####) . Those consumers who are the least able to afford the fees pay the most to use checking accounts. Ninety percent of the fees are paid by ##% of the customers (Crepeau ####) . Banks earn approximately $## billion annually from overdraft and insufficient funds fees (CFPB ####) . A second policy root lies in bank regulations that do not fully optimize incentives to offer basic accounts. Offering a basic affordable bank account holds the potential to be rewarded within the requirements of the Community Reinvestment Act (CRA) a bank regulation that requires and incentivizes products and services to low-and moderate-income communities. Under the CRA's Service Test banks have the potential to be rewarded for offering low-cost bank accounts (FDIC ####a). However this incentive is weak and few banks nationally offer accounts that meet national standards for affordability and accessibility (CFE ####) . Physical access challenges to banks that consumers face influences their account ownership and usage. As a result of federal policy changes banks are merging and closing branches in underserved communities at a record pace in recent years (Ensign et al. #### February #) which has drastically reduced the number of branches since #### (FDIC n.d.) . Opportunities to access a bank account using face-to-face interaction with bank staff used more by financially vulnerable populations is therefore more difficult (FDIC ####) . At the same time reliable affordable internet service lags in underserved communities making it more difficult to consistently access online accounts . Physical access to a bank can also affect available options for low-cost accounts; account features such as high balance requirements and fee structure are less attractive among banks physically located in black and Latinx communities (Faber et al. ####) . A broad range of policy ideas have been proposed by researchers scholars and government actors. These policy ideas are centered on the type of institution permitted to offer accounts policy and regulations regarding banks their regulations and their environment as well as policies directly relating to bank accounts. Among the most expansive proposals are those that would increase the type of institutions that offer low-cost bank accounts. One example is to allow the US Post Office to offer basic accounts as it did between #### and #### (Baradaran ####; Servon ####) . Another idea is to offer basic accounts for consumers directly from the Federal Reserve Bank bypassing retail banks (Ricks et al. ####) . Expanding the capacity and range of products and services for mission-oriented financial institutions such as community development financial institutions could allow them to offer low-cost accounts (Birkenmaier ####) . Other policies would expand access to banking and financial services in underserved communities through additional branches changing the regulatory emphasis and strengthening the physical infrastructure through which banking is delivered. Policy that promotes bank branch location in underserved communities could allow for easier account access (Friedline et al. ####a b) as would increasing the sheer number of bank branches so that bank branches outnumber more costly non-bank financial institutions offering AFS in underserved communities (Friedline et al. ####a b) . Changing CRA regulation could also have a profound effect on the number of banks offering affordable accounts (FDIC ####a) . Increasing the weight given to low-cost accounts in the CRA Service Test could incentive low-cost accounts . Changing regulations could also add increased consumer pressure on banks to provide affordable account in two ways. First banks could be required to providing account information in easy-to-locate standardized formats for straight-forward comparative shopping of their account offering (Birkenmaier et al. ####) . Second making it easier to change banks could create increased pressure on banks to retain their customers through more attractive account offerings (Bernardo ####; du Toit & Burns ####) . Policy could also address the environment that influences consumers related to bank accounts in several ways. First expanding affordable reliable internet connectivity would allow consumers to securely access more account options particularly in lower-income and marginalized communities . Online and mobile banking holds the potential to expand banking access but strong consistent internet connectivity is needed (FDIC ####). Second supporting and expanding the capacity of the federal Consumer Financial Protection Bureau [CFPB] may affect the supply of affordable accounts (CFPB ####; Evans & Stein ####) . The CFPB offers consumers key government resources to address banking concerns such as unfair deceptive or abusive practices related to accounts that decrease consumer costs and increase consumer trust. Expanding access to a safe and affordable account could also occur through policy change directly related to bank accounts. For example a new law could regulate bank account features costs and fees (CFE ####) . Requiring all retail banks to offer basic accounts at very low cost by law is another option (Government of Canada ####). Likewise regulations could serve to expand the use of municipal identification cards as acceptable identification to open an account (Center for Popular Democracy ####). Our analysis sought to answer the following research questions: (#) What policy goals that may impact the availability of low-cost basic bank accounts have been introduced in Congress as legislation? (#) How far in the legislative process did the legislation advance? (#) What populations did these proposed laws target? and (#) What are the policy goals pursued most ardently over the past ## years related to affordable bank accounts? The researchers did not generate hypothesis related to these questions because there was a lack of related research to consult. These questions are grounded in policy analysis research regarding the promotion of policy goals through legislation. Policy development research suggests that policy actors (such as legislators) can define policy problems and public policy responses in various ways due to different causal attributions and policy interest alignment (Stone ####) . These perspectives and responses impact the degree to which policy goals are pursued in legislation. Policy proposals introduced as legislation can also reflect the author's perception about the weight of the evidence of the problem complexity of the problem ideology and their personal motivations and agendas (McConnell & Hart ####) and the likelihood of successfully passing the proposal. Policy proposals that specify target populations such as the unbanked may provide strategic benefits (Stratmann #### ) yet policy often targets the general populations for reasons of partisan protection expansion and policy maintenance (Balla et al. ####; Holyoke #### ). This study used the method of policy mapping which is a systematic content analysis technique wherein researchers identify and analyze policy content in a topical area (Anderson et al. ####; Esdaile et al. ####; Hare et al. ####) . Policy mapping can identify policy gaps and provide information about trends and status of policy in a given area. This evidence can provide information for future policy advocacy and a foundation on which research on policy implementation and enforcement occurs (Burris et al. ####) . Results can also provide evidence for the magnitude and nature of policy attention to a particular issue (Esdaile et al. ####) . This study focused on bills and resolutions introduced at the US Congressional level rather than the state level. Federal bills are models for legislation at subordinate (e.g. state and municipal) levels (Purtle & Lewis ####) . Banks and credit unions can be chartered at both the federal and state levels but all banks are regulated by the federal government. Using Congress.gov a publicly available database that catalogs all bills amendments and resolutions introduced in the US House and Senate the research team searched for federal legislation related to basic bank accounts. Using the search terms \"bank account \" \"checking account \" and \"transaction account \" the researchers searched for any bill or resolution containing these exact phrases between #### and #### (June) (###th-###th Congress) anywhere in the bill summary. The following options were checked for each of the searches: word variants all legislation public and private legislation any action and any committee. This initial search yielded n = ### unduplicated bills and resolutions. The researchers manually identified and removed legislation that was earlier versions of policies introduced in multiple sessions of Congress (whose time period is included) duplicate polices introduced in both the House and Senate bills primarily focused on lending terrorism FDIC insurance and bills focused on one person. During the coding process bills and resolutions that failed to address bank accounts in a substantive way were identified and excluded (n = ##). From the remaining ## unique legislative items we manually identified and removed legislation that was introduced in more than one Congress without substantive change (n = ##) retaining only the most recent version for coding in the final dataset. Similarly we removed items (n = ##) that were introduced in identical or near-identical versions in both the House and Senate in the same Congress keeping only the House version. The final dataset was n = ## unique bills representing ## total bills. The researchers established categories and codebook prior to beginning coding (Purtle & Lewis ####) and followed the example process of Bowen and Irish (####) in coding. The codebook included basic information as well as four goal categories related to our research questions about the policy goal and focal population in legislation. Basic information included bill number and name whether the bill had a companion bill (introduced in same Congress in same or different chamber) whether the bill had a matching bill (in a different Congress) number of Congress' introduced (###th-###th) the final stage reached (e.g. committee assignment passed one chamber etc.) the sponsor party (Democrat Republican or Independent) and whether the bill had bipartisan support (indicated by the presence of at least one cosponsor with a different political party affiliation than the sponsor). Any target populations mentioned were also coded. For policy goals as seen in Table # the researchers began coding based on six major policy goals: (#) expanding access to basic bank accounts (#) expanding Provide consumer-friendly product information the type of institutions that offer basic accounts (#) expanding account access in minority populations and communities (#) reducing the costs of basic accounts (#) increasing consumer protections and (#) increasing consumer disclosure. As a starting point for coding the goals and illustrative mechanisms were created through extensive literature review of research studies academic scholarship and \"grey\" literature. Some mechanisms have received study and research (e.g. postal banking (Office of the Inspector General United States Postal Service ####; affordable account standards (Covington & Liu ####) ) while others have only been suggested (e.g. expand affordable and reliable internet connectivity (Friedline & Chen ####) ). The codes were not mutually exclusive and the coding scheme did not specify a maximum for the number of goal codes that could apply to a single bill or resolution. New illustrative mechanisms were added during the process of coding. Focal population was coded based on any target population named in the proposed legislation. For ardently pursued legislation the researchers coded for legislation introduced into both chambers in the same Congress (\"companion\") identical (or nearly identical) legislation introduced in subsequent Congresses (\"matching\") and both. The two researchers independently coded the basic information and illustrative mechanisms related to the policy goals. The researchers coded the basic information using the summary provided and coded policy goals using the full text of the bill using the illustrative mechanisms in Table # . Only bill sections related to bank accounts were coded. The researchers met to review codes after independently coding about ##-##% of the bills and developed new codes as needed. The researchers coded independently then met regularly to compare codes and add new codes as needed. Coding discrepancies were resolved through collaboratively reviewing the legislative text and discussion among the researchers to reach a consensus decision (Krippendorff ####) . Many discrepancies involved a coder lack of experience with a particular product or process (e.g. the timing of processing of checks relative to deposits by banks) or misreading or misinterpreting text sections. Inter-coder agreement (Cohen's kappa statistic) was calculated only for illustrative mechanisms of the policy goals because interpretation was unnecessary for the basic information categories. The researchers coded text for provisions that could directly or indirectly support the goal or illustrative mechanism. Table # describes basic characteristics of legislation in the dataset (N = ##). No resolutions were included in the dataset. The bills were fairly evenly distributed among the various Congresses with the largest number in the ###th Congress (####-####). The vast majority was House bills (##.#%) and introduced by Democrats (##.#%). A minority of bills had companion legislation (##%) or similar bills introduced over more than one Congressional session (\"matched\") (##%). A very small minority had both companion legislation and matched legislation (##.#%). Most items (##%) did not progress beyond introduction and assignment to committee. A minority of bills (##%) targeted a specific population such as the unbanked or underbanked. A few bills were well-known bills (e.g. H.R. #### ###th Congress Dodd-Frank Wall Street Reform and Consumer Protection Act) while most were obscure. Table # summarizes coding of goals illustrative mechanisms ardently pursued legislation target populations and illustrative examples of legislation. Cohen's The policy goal of expanding account access in minority populations and communities was not represented in the dataset. Several illustrative mechanisms were also not represented. Related to the goal of expanding access to bank accounts items related to the Community Reinvestment Act (CRA) internet access bank branch location and density identification cards and switching banks were not represented in the dataset. Related to the goal of consumer protection items related to protecting and strengthening the CFPB were not represented. Related to consumer disclosure creating or supporting standards for affordable basic accounts was also not in the dataset. Three goals were approximately equally addressed in the legislation: expanding access to bank accounts (##.#% of legislation) increasing consumer protection (##.#%) and reducing costs of basic accounts (##.#%). Increasing consumer disclosure (##.#%) and expanding the type of institutions that offer basic accounts (#.#%) were addressed infrequently in the legislation. The policy goals that have progressed the furthest in federal legislation are expanding access and increasing consumer protection; #% of bills coded with both policy goals became law. For example for the goal of expanding access H.R. #### the Federal Deposit Insurance Reform Conforming Amendments Act of #### (###th Congress) required FDIC to conduct a bi-annual national study of the unbanked and underbanked. For the policy goal of increasing consumer protection H.R. #### disallows penalties for withdrawing or transferring funds from an account. The goal that achieved the least progress is to expand type of institutions that offer basic accounts. For example H.R. #### the Bridging Bank to Recovery Act of #### (###th Congress) proposed to create a new \"bridging bank\" that would provide basic accounts and access to credit for the unbanked underbanked and consumers with low credit scores. This bill only went through the initial steps and never had a committee hearing. Within the policy goals support for mission-oriented financial services (##.#%) was the most common illustrative mechanism for the expanding access goal. For the goal of reducing the costs of accounts legislation that related to all types of fees was most common (##.#%). Protecting consumers from unfair/deceptive/abusive bank account practices and products and services was the most common mechanism for the goal of increasing consumer protection (##.#%). The illustrative mechanism most common for the goal of increasing consumer disclosure was notifying consumers about other (non-fee) product features (##.#%). The policy that had illustrative mechanisms that achieved the most progress without becoming law were expanding access and reducing costs. Within expanding access two bills related to making it easier to open accounts passed one chamber: H.R. #### ###th Congress the Preventing Sex Trafficking and Improving Opportunities for Youth in Foster Care Act which passed the House would require staff to open accounts for youth prior to discharge from the foster care system and H.R. #### ###th Congress the Tax Administration and Good Government Act which passed the Senate would make it easier to open accounts when filing taxes through government-supported tax filing sites for low-and moderate-income consumers. Regarding reducing costs two bills related to reducing fees on accounts also passed the House: H.R. #### ###th Congress the Preventing Sex Trafficking and Improving Opportunities for Youth in Foster Care Act (discussed earlier) and HR #### ###th Congress the Financial Services Regulatory Relief Act of #### which required a survey of bank fees. The policy goal pursued most ardently through the combination of companion and matching bills is increasing consumer disclosure with ##% of legislation that includes an illustrative mechanism for this goal being pursued with the combination of companion and matching bills. Reducing cost was also ardently pursued through ##% of legislation that includes an illustrative mechanism for this goal featuring both companion and matching bills. Bills related to expanding access (##%) and type of institutions (#%) were pursued the least ardently. This study reports on the first comprehensive analysis of the basic characteristics goals illustrative mechanisms and progress in the US Congress on the goals of reducing the number of unbanked and underbanked Americans between #### and ####. The ## bills in the dataset indicate some legislative attention across the time period to the policy goals and illustrative mechanisms when the topic was emerging as an area of concern at the federal level. The Congressional response particularly occurred in the most recent Congress (###th #### Congress (###th -#### and with bipartisan attention although heavily skewed toward those in the Democratic party. Most of the bills were small scale bills the majority of which did not advance past committee assignment. Although most of the policy goals in our taxonomy were reflected in the dataset and new illustrative mechanisms were located Congressional attention to this topic is noticeably lax in comparison to the attention paid by federal regulatory agencies and related academic literature. This finding of less attention to banking consumer interests is consistent with prior research that Congressional attention to consumer interests has dropped in recent decades relative to business interests (Bykerk & Maney ####) . The progress of the bills in the dataset has been mostly minimal. Only three bills representing two policy goals have become law (expand access to bank accounts and increase consumer protection). This finding is not surprising given that on average only two-six percent of introduced bills passed into law in Congress during the study period (Civic Impulse ####). The most commonly occurring policy goals of expanding access reducing costs and increasing consumer protection are primarily focused on proximal factors for lack of access rather than the root causes of access barriers. For example the policy goal of expanding the type of institutions that offer basic accounts such as a new type of bank have very few bills introduced about them and they failed to progress past the first steps. The illustrative mechanism that was the most expansive in terms of rights (e.g. ensuring the right to a bank account) stalled at committee assignment despite the fact that it would be a prevention measure. These findings are consistent with the concept that incremental rather than structural change is often pursued by legislators (Baumgartner et al. ####) . Increasing consumer disclosure and reducing account cost was pursued most ardently of all of the policy goals while expanding access and type of institutions were pursued the least. The bills included little language about focal populations. Only six bills mentioned any populations at all. This lack of mention is consistent with the idea of legislation benefitting the general population as a strategy that increases the chances of passage (Balla et al. ####; Holyoke ####; Strolovitch ####) . Legislation that benefits the general population including advantaged subgroups can also positively impact financially vulnerable populations even when not specifically mentioned in the legislation (Strolovitch ####) . For example expanding the institutions that can offer basic accounts to the US Postal Service can benefit the general population and offer convenience to all including the unbanked and underbanked populations. Thus the fact that so few bills included any mention of financially vulnerable populations may in fact help the progress of the bills because of a wider beneficiary population. Not all goals and illustrative mechanisms in our taxonomy were reflected in the dataset. The policy goal of expanding account access in minority populations and communities was not represented in the dataset. Thus no introduced legislation has sought to specifically target minority populations and communities that are disproportionally represented among the unbanked and underbanked (FDIC ####). The missing illustrative mechanisms related to the goal of expanding access to bank accounts are notable because all have received attention in the research literature as critical to reducing the number of unbanked and underbanked (Center for Popular Democracy ####; in particular bank branch location and density of banks relative to Alternative Financial Services (Friedline et al. ####a b) . Regarding consumer protection and disclosure there were no items related to protecting and strengthening the CFPB which provides important consumer advocacy for individual consumers related to the banking industry. Also missing was the creation of standards for affordable basic accounts which is a growing movement across the country (Erwitt et al. ####; Wack ####) . To address the challenges of the unbanked and underbanked through federal legislation advocates could focus on the policy goals and illustrative mechanisms that have achieved legislative movement in the past by passing either the House or the Senate yet have not become law. For example under the policy goal of expanding access to bank accounts the illustrative mechanism of making it easier to open accounts had two bills that passed one chamber (H.R. #### ###th Congress and H.R. #### ###th Congress). Under the goal of reducing costs the illustrative mechanism of generally reducing fees (not specifically related to ATM or overdraft fees) has also achieved momentum in the past through H.R. #### ###th Congress and H.R. #### the ###th Congress. Advocates may also want to focus on legislation that directly affects the account fee structure given its prominence in reasons given for unbanked status (CFPB ####; FDIC ####) . Consumer protections related to accounts and those related to a national crisis have also passed one chamber. Legislation that would increase consumer notification about account features that furthers the policy goal of increasing consumer disclosure has achieved passage within one chamber. These results suggest that legislation that is related to fees in general rather than fees tied to specific activities may gain more policy movement. Legislation related to consumer protections may be another likely avenue given these results of substantial legislative movement of related bills. These findings should be considered in light of the study's limitations. First this study omits policy making that occurs in other contexts such as the federal regulatory process (FDIC ####a) the courts and state legislation. Second only bills that specifically mentioned bank accounts were included. Relevant legislation may have been missed that had an indirect effect on bank accounts that did not mention accounts or that benefitted financially vulnerable populations and communities. Third the nature of legislative attention to various goals and illustrative mechanisms related to bank account access deserves a closer examination in future research. For example future studies could analyze the influence of companion and matching bills related to the final status of legislation as well as the nature of legislation within which language about account access was situated for some included bills. Lastly future research should include more contextual factors including dominant political party within the chambers and in the executive branch. The presence of the unbanked and underbanked populations through the study period suggests that additional policy development and legislative attention is needed to meet the needs of these populations. Moving forward policy advocates may wish to focus on impactful areas that shows evidence of movement forward in the legislative process such as making it easier to open accounts reducing fees and increasing consumer protections. Policy advocates may also wish to focus their attention on areas that are under-addressed in the past legislative response (e.g. expanding the type of institutions that offer basic accounts and the basic right to an account). In sum the findings of this study indicate that despite some congressional legislative activity in the past decade the sufficiency and effectiveness of proposed policy solutions remain insufficient to address the problems.\n",
            "response:  BACKGROUND: In recent decades researchers and policy scholars have called attention to the problem of unbanked under-banking in the USA. AIM: To evaluate whether or not an over-regulated company has used alternative financial services (AFSs) for certain purposes such as convenience preference avoidance of fees and other reasons. MATERIAL AND METHODS: We conducted two online surveys using ### anonymously searched databases from February through June #### among non-linear studies across five states that were included with our survey results.\n"
          ]
        }
      ],
      "source": [
        "datasets = [\"bbc\", \"gigaword\", \"nips\", \"cord\"]\n",
        "\n",
        "\n",
        "# TODO: Replace with your own Hugging Face API token\n",
        "huggingface_token = \"YOUR_HUGGINGFACE_TOKEN\"\n",
        "\n",
        "\n",
        "for dataset_name in datasets:\n",
        "    model_checkpoint = f'BRUNOKRISTI/t5_small_fine_tuned_{dataset_name}'\n",
        "    # model_checkpoint = f't5-small'\n",
        "    metrics_df = pipeline(dataset_name, model_checkpoint, output_folder=\"/content/drive/My Drive/Results/T5\", num_samples=10)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c15d377dd51462d93805b07b38414de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec56780d1c9749fdb2c1a695b3a20a74",
              "IPY_MODEL_2bf75273e06344d7af2854b970afe7f1",
              "IPY_MODEL_074f5e661f234f4c82f6da4619019001"
            ],
            "layout": "IPY_MODEL_7aea7fad0c644abd8cf128ea471b407d"
          }
        },
        "ec56780d1c9749fdb2c1a695b3a20a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_509123df7fee453b937d60f84e14d464",
            "placeholder": "​",
            "style": "IPY_MODEL_d90066050e6247ca98e9fc44512aa2aa",
            "value": "Generating train split: "
          }
        },
        "2bf75273e06344d7af2854b970afe7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78c2dc9c6b424b0e963e559c3d987b8a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d36171ff2e643928bd53a12fe08c407",
            "value": 1
          }
        },
        "074f5e661f234f4c82f6da4619019001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd24e78897414bd4b1710bd3f3cf8969",
            "placeholder": "​",
            "style": "IPY_MODEL_bb0d6ba0b5ff4785ac5c52f9c81fd8bc",
            "value": " 6864/0 [00:00&lt;00:00, 84703.50 examples/s]"
          }
        },
        "7aea7fad0c644abd8cf128ea471b407d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "509123df7fee453b937d60f84e14d464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d90066050e6247ca98e9fc44512aa2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78c2dc9c6b424b0e963e559c3d987b8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6d36171ff2e643928bd53a12fe08c407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd24e78897414bd4b1710bd3f3cf8969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb0d6ba0b5ff4785ac5c52f9c81fd8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8193ded5c2d5430dbb9a92a584ab7365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b57032b192ea400abb9604dd432486d3",
              "IPY_MODEL_feb20961e5e5405c89f9da39a15754dd",
              "IPY_MODEL_8f89e24de6ae487aa1a1149cfe9eef59"
            ],
            "layout": "IPY_MODEL_920b244dbb35404bb4cad0d98e014c44"
          }
        },
        "b57032b192ea400abb9604dd432486d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a703c735b648c68909473c83b56c83",
            "placeholder": "​",
            "style": "IPY_MODEL_a8599431e7834444a9b5d70c7d3b2941",
            "value": "Map: 100%"
          }
        },
        "feb20961e5e5405c89f9da39a15754dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_900a15cc696346cdad0e908a0f18ab18",
            "max": 6864,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f97f444fdca413cae0ff997782d91d5",
            "value": 6864
          }
        },
        "8f89e24de6ae487aa1a1149cfe9eef59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f64b0aaaa3674841a6855921ec5cfa33",
            "placeholder": "​",
            "style": "IPY_MODEL_75181905355f480c9e46b22827c19ab0",
            "value": " 6864/6864 [00:00&lt;00:00, 14955.48 examples/s]"
          }
        },
        "920b244dbb35404bb4cad0d98e014c44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a703c735b648c68909473c83b56c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8599431e7834444a9b5d70c7d3b2941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "900a15cc696346cdad0e908a0f18ab18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f97f444fdca413cae0ff997782d91d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f64b0aaaa3674841a6855921ec5cfa33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75181905355f480c9e46b22827c19ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "def061b4f17c433f832db9e571a16139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8030ae3c29ff4f3bb0235ee0d52c68b3",
              "IPY_MODEL_32b5f132a7a24140a7c53f8e6fc3be71",
              "IPY_MODEL_62a49c0c8b98490285cfff6a5afb5171"
            ],
            "layout": "IPY_MODEL_117308ded2de44c79eeaae30ffb08cc4"
          }
        },
        "8030ae3c29ff4f3bb0235ee0d52c68b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48937d2d4e7046fd82b6d73fc5945774",
            "placeholder": "​",
            "style": "IPY_MODEL_7900087760e042f0b56d32d280bf4aa1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "32b5f132a7a24140a7c53f8e6fc3be71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c0d64e28e34741a9d50455680fe4e2",
            "max": 20804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0029bd37144e4047bd83eaf2ded63a6d",
            "value": 20804
          }
        },
        "62a49c0c8b98490285cfff6a5afb5171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dce71be6de34db8929250e86b197d97",
            "placeholder": "​",
            "style": "IPY_MODEL_1402d4f93e1f44b3b4db0cf98d3b4996",
            "value": " 20.8k/20.8k [00:00&lt;00:00, 1.44MB/s]"
          }
        },
        "117308ded2de44c79eeaae30ffb08cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48937d2d4e7046fd82b6d73fc5945774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7900087760e042f0b56d32d280bf4aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32c0d64e28e34741a9d50455680fe4e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0029bd37144e4047bd83eaf2ded63a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dce71be6de34db8929250e86b197d97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1402d4f93e1f44b3b4db0cf98d3b4996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17725729e83f41bc8171f30312594b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3781deb069af4a78ad2ae5c2f7af43a6",
              "IPY_MODEL_31f1fda4634348f6b991efbf7069a1e5",
              "IPY_MODEL_662dea080606487dac69dae37bcff5d6"
            ],
            "layout": "IPY_MODEL_b56f674776824be9a392ac33ee782693"
          }
        },
        "3781deb069af4a78ad2ae5c2f7af43a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d7cb9cb8b34f0cbfdd354e4bd54aee",
            "placeholder": "​",
            "style": "IPY_MODEL_9c27caf7c8a94b3380934a432583d4c3",
            "value": "spiece.model: 100%"
          }
        },
        "31f1fda4634348f6b991efbf7069a1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b88456b3078b46d1b8b61fd3da409ae5",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_554369e081f8409e838acd1c2b5e738b",
            "value": 791656
          }
        },
        "662dea080606487dac69dae37bcff5d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbf177b495f0411f8f60b5954209090a",
            "placeholder": "​",
            "style": "IPY_MODEL_feddb3adebc14ac8b8a7c0918c1c50a4",
            "value": " 792k/792k [00:00&lt;00:00, 14.8MB/s]"
          }
        },
        "b56f674776824be9a392ac33ee782693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d7cb9cb8b34f0cbfdd354e4bd54aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c27caf7c8a94b3380934a432583d4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b88456b3078b46d1b8b61fd3da409ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "554369e081f8409e838acd1c2b5e738b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbf177b495f0411f8f60b5954209090a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feddb3adebc14ac8b8a7c0918c1c50a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b83fceae68a4e5b916b2b5f7fc364a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4510d7d889b4b3abf64cba28cf30873",
              "IPY_MODEL_04ba6eca698c4876a906b7159d7c740d",
              "IPY_MODEL_b7b62c22a124493997231036c1018733"
            ],
            "layout": "IPY_MODEL_a0f9d4ffd2144ff0a8e34cd32841a036"
          }
        },
        "e4510d7d889b4b3abf64cba28cf30873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14e7bfe848094ba4bcf0096ce195d36e",
            "placeholder": "​",
            "style": "IPY_MODEL_6fe0c866e72f4540a5f7b77cd33e63f4",
            "value": "tokenizer.json: 100%"
          }
        },
        "04ba6eca698c4876a906b7159d7c740d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acf5332cced64e749cedfbd89fb28615",
            "max": 2422422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de62bbcd145b4d8fba2d68836574685e",
            "value": 2422422
          }
        },
        "b7b62c22a124493997231036c1018733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e214f3a0a7154776a66ac20d382052d3",
            "placeholder": "​",
            "style": "IPY_MODEL_13b040ce64ae4a0dba28435db5a6e84c",
            "value": " 2.42M/2.42M [00:00&lt;00:00, 7.46MB/s]"
          }
        },
        "a0f9d4ffd2144ff0a8e34cd32841a036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14e7bfe848094ba4bcf0096ce195d36e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fe0c866e72f4540a5f7b77cd33e63f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acf5332cced64e749cedfbd89fb28615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de62bbcd145b4d8fba2d68836574685e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e214f3a0a7154776a66ac20d382052d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13b040ce64ae4a0dba28435db5a6e84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd213ab0d9ef4d46b294129992cf912d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23ae4720ae2c408885aba9dc70c7f117",
              "IPY_MODEL_a495a8f7419347038ddca7071b5bd6dc",
              "IPY_MODEL_89870275efad462b8f0d534ff7671075"
            ],
            "layout": "IPY_MODEL_634846dce23e4112bab02267314bf6b7"
          }
        },
        "23ae4720ae2c408885aba9dc70c7f117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1003c0efe38241b89479f58336efd212",
            "placeholder": "​",
            "style": "IPY_MODEL_3ef1bd158d9c402fb4f82573bcc04ae5",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a495a8f7419347038ddca7071b5bd6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d88bbbdb693f45129d2dcae570c1bddf",
            "max": 2543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44eb2f6afded4c0b99fd980b49738c04",
            "value": 2543
          }
        },
        "89870275efad462b8f0d534ff7671075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0a946bf95024a13bb97dde9105c5f3a",
            "placeholder": "​",
            "style": "IPY_MODEL_d8dff022b8e24158860afb4896a0a2e3",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 253kB/s]"
          }
        },
        "634846dce23e4112bab02267314bf6b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1003c0efe38241b89479f58336efd212": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef1bd158d9c402fb4f82573bcc04ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d88bbbdb693f45129d2dcae570c1bddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44eb2f6afded4c0b99fd980b49738c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0a946bf95024a13bb97dde9105c5f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8dff022b8e24158860afb4896a0a2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bffb7c9910434bcdbd019d2554150749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84469a2835cd48d9a57506ba22f689bd",
              "IPY_MODEL_a4decae302814634a34df7f77f05e62d",
              "IPY_MODEL_b9f1907951094ab39c6b22d932c4ed30"
            ],
            "layout": "IPY_MODEL_a6f53db3c6714df9bcc0e2a9ff6298d7"
          }
        },
        "84469a2835cd48d9a57506ba22f689bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_028e23a997214a0da6c04bcbc617ab08",
            "placeholder": "​",
            "style": "IPY_MODEL_6f0d21e5c3c843ca9bffb5b9a49e5901",
            "value": "config.json: 100%"
          }
        },
        "a4decae302814634a34df7f77f05e62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e8d15b3cef245678e5e0de9af4b90fb",
            "max": 1471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2e7919d8755445a9e2e44bf5738c159",
            "value": 1471
          }
        },
        "b9f1907951094ab39c6b22d932c4ed30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99627cbd6aa9428c94c8ad4d1f1d6a15",
            "placeholder": "​",
            "style": "IPY_MODEL_49adac48a08e47679246ccb6cde07914",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 131kB/s]"
          }
        },
        "a6f53db3c6714df9bcc0e2a9ff6298d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "028e23a997214a0da6c04bcbc617ab08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f0d21e5c3c843ca9bffb5b9a49e5901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e8d15b3cef245678e5e0de9af4b90fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2e7919d8755445a9e2e44bf5738c159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99627cbd6aa9428c94c8ad4d1f1d6a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49adac48a08e47679246ccb6cde07914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2f377c0231f4df684bb4be5f0f16895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3328e6581dbc4663b37c63cbd15a0787",
              "IPY_MODEL_bde0e44422df4bef8e2693b9353f90d9",
              "IPY_MODEL_5f9a1ec5711143bba4919d195ead5f8c"
            ],
            "layout": "IPY_MODEL_061629aa029e4b1faab80e1fa40c9243"
          }
        },
        "3328e6581dbc4663b37c63cbd15a0787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d68e008cac1048d6a62421aedc96e08b",
            "placeholder": "​",
            "style": "IPY_MODEL_f1fa3913b22d40659375d4bf2db010ca",
            "value": "model.safetensors: 100%"
          }
        },
        "bde0e44422df4bef8e2693b9353f90d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a002d90e2664aec9c7b90333e01cb25",
            "max": 242041896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a5ba4b91ad44813bf590fc383dfa150",
            "value": 242041896
          }
        },
        "5f9a1ec5711143bba4919d195ead5f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3de5a59095db4c1789b8d2ab542265dd",
            "placeholder": "​",
            "style": "IPY_MODEL_b83f0b2a1ff348768a7b07e2736f79e7",
            "value": " 242M/242M [00:03&lt;00:00, 83.4MB/s]"
          }
        },
        "061629aa029e4b1faab80e1fa40c9243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d68e008cac1048d6a62421aedc96e08b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1fa3913b22d40659375d4bf2db010ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a002d90e2664aec9c7b90333e01cb25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a5ba4b91ad44813bf590fc383dfa150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3de5a59095db4c1789b8d2ab542265dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b83f0b2a1ff348768a7b07e2736f79e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec94ebb55556459e89047ed12aa9965a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1e8fb4de97245879c2231d30e470710",
              "IPY_MODEL_e3b99af5cccb4f73a264229ff5e41280",
              "IPY_MODEL_f1b2807ba285498dad0a63cd21eed915"
            ],
            "layout": "IPY_MODEL_24e4f0e803084575ad88630d7a3fb975"
          }
        },
        "e1e8fb4de97245879c2231d30e470710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d6705e85a674e9ea19712b5ca258696",
            "placeholder": "​",
            "style": "IPY_MODEL_78421d081a5740bca2e2af76ff2d4065",
            "value": "generation_config.json: 100%"
          }
        },
        "e3b99af5cccb4f73a264229ff5e41280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77aa40828d784149a6608f5a29de7463",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98deffb4a89b4bc0b1afd7385a612a36",
            "value": 142
          }
        },
        "f1b2807ba285498dad0a63cd21eed915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ca548c05092425a87d07944127b2f78",
            "placeholder": "​",
            "style": "IPY_MODEL_03c9a76c414a4d70a95925694d40cd00",
            "value": " 142/142 [00:00&lt;00:00, 12.4kB/s]"
          }
        },
        "24e4f0e803084575ad88630d7a3fb975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d6705e85a674e9ea19712b5ca258696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78421d081a5740bca2e2af76ff2d4065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77aa40828d784149a6608f5a29de7463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98deffb4a89b4bc0b1afd7385a612a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ca548c05092425a87d07944127b2f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03c9a76c414a4d70a95925694d40cd00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06044ea8d4a1487082692d13af984158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01b53f31a4c1472083e46a43cf20de62",
              "IPY_MODEL_2952d54c633c4f22819e381fe92a48ca",
              "IPY_MODEL_fc66b84df7e842fb91ab03332f8f04a8"
            ],
            "layout": "IPY_MODEL_5096b751bca34f28b8067124697278ef"
          }
        },
        "01b53f31a4c1472083e46a43cf20de62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f00952815e2a44f98278bd79cb3f78f7",
            "placeholder": "​",
            "style": "IPY_MODEL_95e051958a6441ab8750bff2f2d6f8d8",
            "value": "Generating train split: "
          }
        },
        "2952d54c633c4f22819e381fe92a48ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aecdaab354b74f70b176bd8132a8071d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33c29ca41d2d4e55bf358a32a9a4a233",
            "value": 1
          }
        },
        "fc66b84df7e842fb91ab03332f8f04a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41ca488ec88f49b9a288f9349f95dd78",
            "placeholder": "​",
            "style": "IPY_MODEL_870fd948575e4cb3b314a362bd936167",
            "value": " 5102/0 [00:04&lt;00:00, 1086.03 examples/s]"
          }
        },
        "5096b751bca34f28b8067124697278ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f00952815e2a44f98278bd79cb3f78f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e051958a6441ab8750bff2f2d6f8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aecdaab354b74f70b176bd8132a8071d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "33c29ca41d2d4e55bf358a32a9a4a233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41ca488ec88f49b9a288f9349f95dd78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "870fd948575e4cb3b314a362bd936167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c26827811d44f6e8109c1d2344e9dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8c06a406ba9455bb54c079626bd3090",
              "IPY_MODEL_99f2d1daa461416382158bfdcd1530c3",
              "IPY_MODEL_755b93908ea247f889ee87ba4879d527"
            ],
            "layout": "IPY_MODEL_5f3bb7ddaf0844929dc1da443e5e2949"
          }
        },
        "a8c06a406ba9455bb54c079626bd3090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6ec3d4fc14948539dbdad9711367aa5",
            "placeholder": "​",
            "style": "IPY_MODEL_ecdaf94e11d548049fc9ba9ba86006ba",
            "value": "Map: 100%"
          }
        },
        "99f2d1daa461416382158bfdcd1530c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaee300bf115459996315c4efbb4f800",
            "max": 5102,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd504c15a6cd4793b0c3198632d3fdcc",
            "value": 5102
          }
        },
        "755b93908ea247f889ee87ba4879d527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04abd9468cd64857a62f1ef7805dcc4a",
            "placeholder": "​",
            "style": "IPY_MODEL_fc13b4b82ab744d69af0cf8483999d15",
            "value": " 5102/5102 [00:05&lt;00:00, 1249.78 examples/s]"
          }
        },
        "5f3bb7ddaf0844929dc1da443e5e2949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ec3d4fc14948539dbdad9711367aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecdaf94e11d548049fc9ba9ba86006ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaee300bf115459996315c4efbb4f800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd504c15a6cd4793b0c3198632d3fdcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04abd9468cd64857a62f1ef7805dcc4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc13b4b82ab744d69af0cf8483999d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "772fd270212446629dbb17ce52968536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_566e2b486b094d1f8f004b6cd1d85885",
              "IPY_MODEL_87eee05c2aea43059060d689cfb0fd2f",
              "IPY_MODEL_b94bd4ca4b8c4bdf8fa4c162a8b5ceab"
            ],
            "layout": "IPY_MODEL_9368889088e7468a8eea11fd8825bde2"
          }
        },
        "566e2b486b094d1f8f004b6cd1d85885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a99698734f4584b79a58bcb515c14d",
            "placeholder": "​",
            "style": "IPY_MODEL_e7402133c74b44eeb00023a79c06ad13",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "87eee05c2aea43059060d689cfb0fd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c14400d1b0b4096a000747d9d136672",
            "max": 20804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd9201cedab549d788b226d1664189d9",
            "value": 20804
          }
        },
        "b94bd4ca4b8c4bdf8fa4c162a8b5ceab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a944cd86b5c490584c8dddb63d0656d",
            "placeholder": "​",
            "style": "IPY_MODEL_ff1b484053b24675a756ca840e678f02",
            "value": " 20.8k/20.8k [00:00&lt;00:00, 1.84MB/s]"
          }
        },
        "9368889088e7468a8eea11fd8825bde2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25a99698734f4584b79a58bcb515c14d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7402133c74b44eeb00023a79c06ad13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c14400d1b0b4096a000747d9d136672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd9201cedab549d788b226d1664189d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a944cd86b5c490584c8dddb63d0656d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1b484053b24675a756ca840e678f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd5fed5e08fa4360953153489d78a7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1fb31da4eb64f1d80cd694a15f8e375",
              "IPY_MODEL_91c76d47ab5245149da7b136d14bbe01",
              "IPY_MODEL_b614699245cd4b60bdf2c744fcebd696"
            ],
            "layout": "IPY_MODEL_89fa20ad628649309c8805a57f848100"
          }
        },
        "b1fb31da4eb64f1d80cd694a15f8e375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13b2f31f422041f1a77c6e78760c9bb5",
            "placeholder": "​",
            "style": "IPY_MODEL_340ebf70fa2e49a6bf28b0bff6f84794",
            "value": "spiece.model: 100%"
          }
        },
        "91c76d47ab5245149da7b136d14bbe01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1076f7acb73a44bd8aba606c27f7934c",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_537aa59abded4bca9067167e019388e8",
            "value": 791656
          }
        },
        "b614699245cd4b60bdf2c744fcebd696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86d0252735a24a269ab9957b5310da0d",
            "placeholder": "​",
            "style": "IPY_MODEL_824c122570a34af9ad21b29d716a7765",
            "value": " 792k/792k [00:00&lt;00:00, 42.4MB/s]"
          }
        },
        "89fa20ad628649309c8805a57f848100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13b2f31f422041f1a77c6e78760c9bb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "340ebf70fa2e49a6bf28b0bff6f84794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1076f7acb73a44bd8aba606c27f7934c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537aa59abded4bca9067167e019388e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86d0252735a24a269ab9957b5310da0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "824c122570a34af9ad21b29d716a7765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85563ccbbbb4475c8e441443658bd98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b99dec78f60f4964a345ce89d9e38c3a",
              "IPY_MODEL_4299173a80e44fc88ce097b809ae5bae",
              "IPY_MODEL_2821a2bf26744a0588b9abbff9981186"
            ],
            "layout": "IPY_MODEL_0611dfba4b4049688624d9a9a64ad0f3"
          }
        },
        "b99dec78f60f4964a345ce89d9e38c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_111beb6d395f45fca0cd7f06f8aea4a2",
            "placeholder": "​",
            "style": "IPY_MODEL_010b7f5c0d56478899213a0438de045f",
            "value": "tokenizer.json: 100%"
          }
        },
        "4299173a80e44fc88ce097b809ae5bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61560a8072c345f29400533235469c85",
            "max": 2422422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4055e79093274dde82195aca992aa46b",
            "value": 2422422
          }
        },
        "2821a2bf26744a0588b9abbff9981186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375f7fecaf6142d88d8a8906eb834353",
            "placeholder": "​",
            "style": "IPY_MODEL_4b2b2777bde74953b0e3af553129ad1f",
            "value": " 2.42M/2.42M [00:00&lt;00:00, 7.59MB/s]"
          }
        },
        "0611dfba4b4049688624d9a9a64ad0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "111beb6d395f45fca0cd7f06f8aea4a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "010b7f5c0d56478899213a0438de045f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61560a8072c345f29400533235469c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4055e79093274dde82195aca992aa46b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "375f7fecaf6142d88d8a8906eb834353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2b2777bde74953b0e3af553129ad1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a64cc5ef24144a6d902ded3c0fe15fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3081ca9a45a64b9895feef8029b174d7",
              "IPY_MODEL_b6155cf86c1f401b9f54d1404faccf5f",
              "IPY_MODEL_7c99082ca80f47efb14fb7bcfee9e0b4"
            ],
            "layout": "IPY_MODEL_5d94e1a06c684474a8aa83bdfc892a26"
          }
        },
        "3081ca9a45a64b9895feef8029b174d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e0dff563dcb49b89b970f52d5935eb7",
            "placeholder": "​",
            "style": "IPY_MODEL_cb88677e88cb448b8a43a5342276f8a6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b6155cf86c1f401b9f54d1404faccf5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_025d76aa71a9413c9f4a45c97df9e24b",
            "max": 2543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_035fab4a87594202886b486adf131e84",
            "value": 2543
          }
        },
        "7c99082ca80f47efb14fb7bcfee9e0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8143b4de3c4a3ab26771d0a90511f2",
            "placeholder": "​",
            "style": "IPY_MODEL_f30df2df5a9548c983305086d595f9bd",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 175kB/s]"
          }
        },
        "5d94e1a06c684474a8aa83bdfc892a26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e0dff563dcb49b89b970f52d5935eb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb88677e88cb448b8a43a5342276f8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "025d76aa71a9413c9f4a45c97df9e24b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "035fab4a87594202886b486adf131e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d8143b4de3c4a3ab26771d0a90511f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f30df2df5a9548c983305086d595f9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4265356a87e43b4bf614d631ec48115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80e7280eca9242908fd88edf79cf1297",
              "IPY_MODEL_ebc2ac680c694cf1a21f52e400aeb37b",
              "IPY_MODEL_39a677f9e398421289c1f9d2c0dca2db"
            ],
            "layout": "IPY_MODEL_dc688c6ee7164e45a19c120ff1688931"
          }
        },
        "80e7280eca9242908fd88edf79cf1297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3873184f9a4f404989c2e8e100e70390",
            "placeholder": "​",
            "style": "IPY_MODEL_1ffaf6d941c54d5987fe044f46621462",
            "value": "config.json: 100%"
          }
        },
        "ebc2ac680c694cf1a21f52e400aeb37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_516494e9ace34f08acb7a28cc7a117a4",
            "max": 1471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2393421b4ae41669717aaf1f7a6bfa5",
            "value": 1471
          }
        },
        "39a677f9e398421289c1f9d2c0dca2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3c5381c6edd41f5afc9dc72f621d716",
            "placeholder": "​",
            "style": "IPY_MODEL_ed7ed724421447f0b01229f2d6c8d08a",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 104kB/s]"
          }
        },
        "dc688c6ee7164e45a19c120ff1688931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3873184f9a4f404989c2e8e100e70390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ffaf6d941c54d5987fe044f46621462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "516494e9ace34f08acb7a28cc7a117a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2393421b4ae41669717aaf1f7a6bfa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3c5381c6edd41f5afc9dc72f621d716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed7ed724421447f0b01229f2d6c8d08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9486c4887dc4269949a34b3bbbdd499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58459e624338496a97adb626f443a050",
              "IPY_MODEL_4d9739d852894fb893a9545b50d825b0",
              "IPY_MODEL_50eca99b79224f2b86b4412125d3fd3e"
            ],
            "layout": "IPY_MODEL_836c237ed39c487a8418a16876d8aa2d"
          }
        },
        "58459e624338496a97adb626f443a050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9b7e317b6554a6e826ed6b06591b603",
            "placeholder": "​",
            "style": "IPY_MODEL_944ed4dd1b2147ccaa44171d224148b0",
            "value": "model.safetensors: 100%"
          }
        },
        "4d9739d852894fb893a9545b50d825b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_329e5178f64b43e0a36d4a6b9b92820c",
            "max": 242041896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34ef59e0d4294ccba4f4975822f7d360",
            "value": 242041896
          }
        },
        "50eca99b79224f2b86b4412125d3fd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77e0033412a7480aad8c3c85d72940ce",
            "placeholder": "​",
            "style": "IPY_MODEL_6dcd4f42f967444997e9dcf1c0d9373b",
            "value": " 242M/242M [00:02&lt;00:00, 83.3MB/s]"
          }
        },
        "836c237ed39c487a8418a16876d8aa2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b7e317b6554a6e826ed6b06591b603": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "944ed4dd1b2147ccaa44171d224148b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "329e5178f64b43e0a36d4a6b9b92820c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34ef59e0d4294ccba4f4975822f7d360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77e0033412a7480aad8c3c85d72940ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dcd4f42f967444997e9dcf1c0d9373b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbae3f52a82c4f12b39d050afb0bb861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15a51422c8e74f75aebbecfc6ff32bbe",
              "IPY_MODEL_d91f542393494669954a658803b1d73b",
              "IPY_MODEL_a4c4c39c4b324e559936131aad3c13f6"
            ],
            "layout": "IPY_MODEL_78fd9638a4cf4e99bb718577bc719662"
          }
        },
        "15a51422c8e74f75aebbecfc6ff32bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0630c6ff8ad7461f9ad8ac423ee815ff",
            "placeholder": "​",
            "style": "IPY_MODEL_cdf2174f0883444aa3391d2cf4e40397",
            "value": "generation_config.json: 100%"
          }
        },
        "d91f542393494669954a658803b1d73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d90b42ef14b04e07b2c3394490965570",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3c4e01d216440898307a6d2787c82f8",
            "value": 142
          }
        },
        "a4c4c39c4b324e559936131aad3c13f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93a9573ea7d644f38640d7661855af8d",
            "placeholder": "​",
            "style": "IPY_MODEL_e0af26f744f5488288de26c5c0b98865",
            "value": " 142/142 [00:00&lt;00:00, 13.4kB/s]"
          }
        },
        "78fd9638a4cf4e99bb718577bc719662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0630c6ff8ad7461f9ad8ac423ee815ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdf2174f0883444aa3391d2cf4e40397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d90b42ef14b04e07b2c3394490965570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c4e01d216440898307a6d2787c82f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93a9573ea7d644f38640d7661855af8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0af26f744f5488288de26c5c0b98865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8676e7bfd0f24f0482a69c1b6fedfaf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_318d65ac17a944919c7e6482cfbe7f45",
              "IPY_MODEL_3298493cadc54b2aad0a5da66a602241",
              "IPY_MODEL_61de28c6e48f4efba6a5071dda0ce30e"
            ],
            "layout": "IPY_MODEL_5c34a7985ed34b8899e86b728ff2ed2d"
          }
        },
        "318d65ac17a944919c7e6482cfbe7f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edeb20751de84f02bf3079bfb13af40e",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed4ba57ed7542ee8e30a6011ce7b4a0",
            "value": "Generating train split: "
          }
        },
        "3298493cadc54b2aad0a5da66a602241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e33f60da891c40e69771da5e790541a4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20c8467ec491410cbbcd7976455da0d5",
            "value": 1
          }
        },
        "61de28c6e48f4efba6a5071dda0ce30e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a5821c8f104e5796f7b2272e389c94",
            "placeholder": "​",
            "style": "IPY_MODEL_ad8b26a5ac104bd18f911676ab195044",
            "value": " 7909/0 [00:04&lt;00:00, 1883.13 examples/s]"
          }
        },
        "5c34a7985ed34b8899e86b728ff2ed2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edeb20751de84f02bf3079bfb13af40e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed4ba57ed7542ee8e30a6011ce7b4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e33f60da891c40e69771da5e790541a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "20c8467ec491410cbbcd7976455da0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25a5821c8f104e5796f7b2272e389c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8b26a5ac104bd18f911676ab195044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1948d6cf1b4f4797bfdcbe2f0e119516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5865bc38ffa84c41bd159d64a03cb4e3",
              "IPY_MODEL_70774acaae7a4ce599ae60df1ff76333",
              "IPY_MODEL_369dd74edc6740bdacc670898bc67c0a"
            ],
            "layout": "IPY_MODEL_0f9c4817a40047d49afc8bf985ff4818"
          }
        },
        "5865bc38ffa84c41bd159d64a03cb4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_479ba1d47aa64eeba4822bcb05f91ccc",
            "placeholder": "​",
            "style": "IPY_MODEL_42a32fb10d134d5c88c86f9834ea4324",
            "value": "Map: 100%"
          }
        },
        "70774acaae7a4ce599ae60df1ff76333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e34d7ab40e3a4418af146f6efcb289cb",
            "max": 7909,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f91db839ac7c4e7b8172e38f276210a7",
            "value": 7909
          }
        },
        "369dd74edc6740bdacc670898bc67c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec546ca01c4549619dbc3e6ec9dc3bc1",
            "placeholder": "​",
            "style": "IPY_MODEL_aeb2d967cacc4af29ef89adf945ae98d",
            "value": " 7909/7909 [00:01&lt;00:00, 3882.28 examples/s]"
          }
        },
        "0f9c4817a40047d49afc8bf985ff4818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "479ba1d47aa64eeba4822bcb05f91ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a32fb10d134d5c88c86f9834ea4324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e34d7ab40e3a4418af146f6efcb289cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f91db839ac7c4e7b8172e38f276210a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec546ca01c4549619dbc3e6ec9dc3bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb2d967cacc4af29ef89adf945ae98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6df6139daee41cba97780d543420c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11276920acfa4dd8a6321008cf3e97bb",
              "IPY_MODEL_b2ce369c0b1d4efe81fde9414f9f609e",
              "IPY_MODEL_4561e6b802554fc5a4f9670e6e33704f"
            ],
            "layout": "IPY_MODEL_9ada9844667441e6b30affcae5a93dd5"
          }
        },
        "11276920acfa4dd8a6321008cf3e97bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b03789a44a44e9097e30926e5577e75",
            "placeholder": "​",
            "style": "IPY_MODEL_ea2f826716b44ffdba0bdee173d90b6e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b2ce369c0b1d4efe81fde9414f9f609e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1df53a7fdf84401086d8b6a03326d7ac",
            "max": 20804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edfc9e9c4e8b42c390e6b23943cf8d8b",
            "value": 20804
          }
        },
        "4561e6b802554fc5a4f9670e6e33704f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccda76881eb34f40b2327c9ffc7a821a",
            "placeholder": "​",
            "style": "IPY_MODEL_55a9d5a5d7d84f6bbaea37b12050bfa7",
            "value": " 20.8k/20.8k [00:00&lt;00:00, 1.97MB/s]"
          }
        },
        "9ada9844667441e6b30affcae5a93dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b03789a44a44e9097e30926e5577e75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea2f826716b44ffdba0bdee173d90b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1df53a7fdf84401086d8b6a03326d7ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edfc9e9c4e8b42c390e6b23943cf8d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccda76881eb34f40b2327c9ffc7a821a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55a9d5a5d7d84f6bbaea37b12050bfa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d8d6d860877484d9341fda449c30dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00b72acf538f4c55b0dee2d4022602a2",
              "IPY_MODEL_3a51b4025ff24718a39281751a5e8fe7",
              "IPY_MODEL_cac56d86f7e34be98fa0fec9e78fed9e"
            ],
            "layout": "IPY_MODEL_9b9e75f609c84e4985f03b9b4eee109d"
          }
        },
        "00b72acf538f4c55b0dee2d4022602a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fee0a80af6914852ae2aabd2baa726c5",
            "placeholder": "​",
            "style": "IPY_MODEL_e12e526a149548298a12f17400ab0aec",
            "value": "spiece.model: 100%"
          }
        },
        "3a51b4025ff24718a39281751a5e8fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a818a608030141889c00f9b42cea2387",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9da1b1ddf529447d97c4930318ed8160",
            "value": 791656
          }
        },
        "cac56d86f7e34be98fa0fec9e78fed9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20db8dc217f147e6b26072897cd12275",
            "placeholder": "​",
            "style": "IPY_MODEL_268534ca03fa4acdbdb580ec1e9eef58",
            "value": " 792k/792k [00:00&lt;00:00, 3.49MB/s]"
          }
        },
        "9b9e75f609c84e4985f03b9b4eee109d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fee0a80af6914852ae2aabd2baa726c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e12e526a149548298a12f17400ab0aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a818a608030141889c00f9b42cea2387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da1b1ddf529447d97c4930318ed8160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20db8dc217f147e6b26072897cd12275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268534ca03fa4acdbdb580ec1e9eef58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a071a80907a3420086bd31ac864fcd03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86e7edaa1a7941cbab0188ca378b6798",
              "IPY_MODEL_43da5a26180d4d57b672c10918a4dd1c",
              "IPY_MODEL_c2b5e90190f44d7d9a2af1584cfc3170"
            ],
            "layout": "IPY_MODEL_8b1fe41bb7094ece8a57217775020f0a"
          }
        },
        "86e7edaa1a7941cbab0188ca378b6798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6a58fcc7c9644f291e5854ed16d5701",
            "placeholder": "​",
            "style": "IPY_MODEL_06d3dd9ba82b460d82a39ecfe8541a42",
            "value": "tokenizer.json: 100%"
          }
        },
        "43da5a26180d4d57b672c10918a4dd1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53bf10394df44a99b85e4b2b79d5981b",
            "max": 2422422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d65527f2454417680158adc121d61e0",
            "value": 2422422
          }
        },
        "c2b5e90190f44d7d9a2af1584cfc3170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05457dcf6546483d8e379e1bac4d21a0",
            "placeholder": "​",
            "style": "IPY_MODEL_a225bfd8428840c1941d585d0ee6e658",
            "value": " 2.42M/2.42M [00:00&lt;00:00, 26.0MB/s]"
          }
        },
        "8b1fe41bb7094ece8a57217775020f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6a58fcc7c9644f291e5854ed16d5701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d3dd9ba82b460d82a39ecfe8541a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53bf10394df44a99b85e4b2b79d5981b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d65527f2454417680158adc121d61e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05457dcf6546483d8e379e1bac4d21a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a225bfd8428840c1941d585d0ee6e658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82e15f6100264c129d89faeeb6b43698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b00f713c382d4192970f87f7778e48ff",
              "IPY_MODEL_f4f1475679f74adf8ee5e1e71531d37f",
              "IPY_MODEL_b53d0c8276f247d5906fbb01eb85a84c"
            ],
            "layout": "IPY_MODEL_a7babedf17d8410391a5afaa7eb0e68c"
          }
        },
        "b00f713c382d4192970f87f7778e48ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5ccd0e13c6c424e954be4a343e2fba5",
            "placeholder": "​",
            "style": "IPY_MODEL_61e2b42840e64b75a7bba4471af05ed2",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f4f1475679f74adf8ee5e1e71531d37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_015b4dad1b2f48f18fa0ba0865d38c44",
            "max": 2543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d755dddad2c14faaacc634d1e427ef0f",
            "value": 2543
          }
        },
        "b53d0c8276f247d5906fbb01eb85a84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c55f97bbaaab4884b2cb88973331b856",
            "placeholder": "​",
            "style": "IPY_MODEL_d880673208be4e78afb189acea0c586e",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 207kB/s]"
          }
        },
        "a7babedf17d8410391a5afaa7eb0e68c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5ccd0e13c6c424e954be4a343e2fba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61e2b42840e64b75a7bba4471af05ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "015b4dad1b2f48f18fa0ba0865d38c44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d755dddad2c14faaacc634d1e427ef0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c55f97bbaaab4884b2cb88973331b856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d880673208be4e78afb189acea0c586e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93e6fa18147e4c7aba223366acee6ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6627f03469748e4b363f2bfa2dc5640",
              "IPY_MODEL_b12e57f76a8345c38e1c14a10b549e7d",
              "IPY_MODEL_d56d0c13ce2a4d13a835c8f56991a827"
            ],
            "layout": "IPY_MODEL_9005ce45fc1f4293a0656e65bb3d6b80"
          }
        },
        "e6627f03469748e4b363f2bfa2dc5640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2490f3e7f95f47718e688c49b94b9ab7",
            "placeholder": "​",
            "style": "IPY_MODEL_2367186ceae4483fafcabe4aea9ca250",
            "value": "config.json: 100%"
          }
        },
        "b12e57f76a8345c38e1c14a10b549e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f9a979a17ff4a5eb02ce8d3b0f6be77",
            "max": 1471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3a56442c3a848898c95b6635ce243e5",
            "value": 1471
          }
        },
        "d56d0c13ce2a4d13a835c8f56991a827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d92c8926d73486bae3b1f4de16884d7",
            "placeholder": "​",
            "style": "IPY_MODEL_e475b75615894a5f8fb3b2b8e84be352",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 136kB/s]"
          }
        },
        "9005ce45fc1f4293a0656e65bb3d6b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2490f3e7f95f47718e688c49b94b9ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2367186ceae4483fafcabe4aea9ca250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f9a979a17ff4a5eb02ce8d3b0f6be77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a56442c3a848898c95b6635ce243e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d92c8926d73486bae3b1f4de16884d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e475b75615894a5f8fb3b2b8e84be352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3200823534f64b92be8d3fb7302dffca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f32e19c672a445887231625e5da4bf9",
              "IPY_MODEL_42f300d17f9b48a9968ac4f344c1096c",
              "IPY_MODEL_e64bf9bdfc5e49ea931ddea59c6981e4"
            ],
            "layout": "IPY_MODEL_3f5b2023b4974f7fa03cddc1e8d64ac1"
          }
        },
        "8f32e19c672a445887231625e5da4bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd295cc9e32c4c88b453648819d58ed3",
            "placeholder": "​",
            "style": "IPY_MODEL_12043c9d084a46879b0cbab058f468dd",
            "value": "model.safetensors: 100%"
          }
        },
        "42f300d17f9b48a9968ac4f344c1096c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f06bd3966164d109a8f1f4a37c901ab",
            "max": 242041896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e91f2cae8f244c0a4e8d2f9b3ad606b",
            "value": 242041896
          }
        },
        "e64bf9bdfc5e49ea931ddea59c6981e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51f943b8c31049ad9ab0bac4edc14e55",
            "placeholder": "​",
            "style": "IPY_MODEL_7bf35621e7ae4d0ea6f2b4f6bf349673",
            "value": " 242M/242M [00:02&lt;00:00, 84.5MB/s]"
          }
        },
        "3f5b2023b4974f7fa03cddc1e8d64ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd295cc9e32c4c88b453648819d58ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12043c9d084a46879b0cbab058f468dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f06bd3966164d109a8f1f4a37c901ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e91f2cae8f244c0a4e8d2f9b3ad606b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51f943b8c31049ad9ab0bac4edc14e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bf35621e7ae4d0ea6f2b4f6bf349673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e296be589d34f558feb697aae81529d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0b88684b7ff4ad2ba8a7e731bb2a5cd",
              "IPY_MODEL_d2aa7bf3c1b44981a5dd44b47db53d41",
              "IPY_MODEL_dc7ed93e1f9b4857b02764003c09f591"
            ],
            "layout": "IPY_MODEL_4a4ddc572ad94fe5b4b43b174c4da5dc"
          }
        },
        "e0b88684b7ff4ad2ba8a7e731bb2a5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d952a82192264e4b8f8ce726946e3c2d",
            "placeholder": "​",
            "style": "IPY_MODEL_465a5f7781df4c4a8c29118b88f844c8",
            "value": "generation_config.json: 100%"
          }
        },
        "d2aa7bf3c1b44981a5dd44b47db53d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38ea6aa19ca64182bc27ec4cfcabd166",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37a366bf95e147fd88d124d2254f6f39",
            "value": 142
          }
        },
        "dc7ed93e1f9b4857b02764003c09f591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd77380f79014db79a2a2b584b51294d",
            "placeholder": "​",
            "style": "IPY_MODEL_739ab0fd5c26446fa0b79872dbdf9153",
            "value": " 142/142 [00:00&lt;00:00, 9.31kB/s]"
          }
        },
        "4a4ddc572ad94fe5b4b43b174c4da5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d952a82192264e4b8f8ce726946e3c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "465a5f7781df4c4a8c29118b88f844c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38ea6aa19ca64182bc27ec4cfcabd166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37a366bf95e147fd88d124d2254f6f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd77380f79014db79a2a2b584b51294d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "739ab0fd5c26446fa0b79872dbdf9153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}